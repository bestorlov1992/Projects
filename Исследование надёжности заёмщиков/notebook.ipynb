{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Исследование надёжности заёмщиков"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "**Автор**: Григорьев Павел   "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "**Описание проекта**: Заказчик — кредитный отдел банка. Нужно разобраться, влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок. Входные данные от банка — статистика о платёжеспособности клиентов.  \n",
            "Результаты исследования будут учтены при построении модели кредитного скоринга — специальной системы, которая оценивает способность потенциального заёмщика вернуть кредит банку.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "**Цель**: Составить рекомендации для кредитного отдела банка, которые будут учтены при построении модели кредитного скоринга.  \n",
            "Определить влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Источники данных**: Данные предоставленны кредитным отделом банка."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Условия проведения анализа днных**: указываем временной интервал выборки  \n",
            "Например, 'для анализ будут использоваться данные за год с 1 июня 2017 по 31 мая 2018 года'"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "**Вывод**: тут помещаем самое главное из общего вывода, примерно до полустраницы, чтобы не было сильно много и при этом указать все главные выводы"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "**Оглавление** \n",
            "* [1. Описание и изучение данных](#1)\n",
            "    * [1.1 Изучение данных](#1-1)\n",
            "    * [1.2 Изучение данных](#1-2)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "\n",
            "(опционально, зависит от того есть ли оглавление по умолчанию, но лучше сделать скрываемое, так как не везде будет автоматическое):  \n",
            "создаем оглавление с гиперссылками  \n",
            "Тут важно давать развернутые названия разделам в работе, но и не сильно большие (пиши - сокращай).  \n",
            "Все таки это название главы и оно должно быть не более 5-7 слов. Некоторые могут быть длиннее, если сильно нужно,  \n",
            "но основная часть названий разделов и глав долны быть достаточно кратикими.   \n",
            "Чтобы понять длинные ли заголовки - смотрим на оглавление и думаем не сильно ли шировкие строчки.  \n",
            "Чтобы в оглавление хорошо читалось и было понятно про что каждый раздел и глава и чтобы  \n",
            "можно было прочитать, понять и перейти к разделу. Нельзя писать сильно кратко, так как люди не знакомы с работой и им нужно более развернутые  \n",
            "названия глав, чтобы понимать о чем там будет идти речь  \n",
            "Оглавление делаем со сворачивающимися списками, то есть каждую главу можно свернуть, можно развернуть и пеерейти на уровень ниже,  \n",
            "как в сводных таблицах экселя, так удобнее, так как места занимает мало, если скрыть все подразделы, а если нужно, то раскроют  \n",
            "В каждом блоке сделать гиперссылку 'к содержанию', чтобы можно было вернуться к содержанию,  \n",
            "но тут важно, чтобы на одной странице не было больше 1 такой ссылки.   \n",
            "Заголовки разделов и глав не нужно писать в стиле 'посчитаем, выясним, исследуем и подобное', так как названия глав и разделов это более официальные  \n",
            "названия. Нужно более формально их называть.  \n",
            "Название главы или раздела должно нести в себе основной смысл этого раздела или главы, так и нужно называть.  \n",
            "1. Описание данных\n",
            "2. Предобработка данных\n",
            "3. Расчет метрик\n",
            "    3.1 Продуктовые метрики\n",
            "        3.1.1 Расчет MAU, DAU, WAU\n",
            "        3.1.2 Рачет ASL\n",
            "4. Подведение итогов и регкомендации       \n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Загрузка библиотек"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "import plotly.express as px\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt\n",
            "from ipywidgets import widgets, Layout\n",
            "from IPython.display import display, display_html, display_markdown\n",
            "import my_module\n",
            "import importlib\n",
            "import re\n",
            "import itertools\n",
            "from pymystem3 import Mystem\n",
            "importlib.reload(my_module)\n",
            "import chart_studio\n",
            "import chart_studio.plotly as py\n",
            "sns.set(style=\"white\")\n",
            "# with httpimport.remote_repo('http://my-codes.example.com/python_packages'):\n",
            "#     import package1\n",
            "\n",
            "# chart_studio.tools.set_credentials_file(username=\"bestorlov1992\", api_key=\"TOnnvREBwfkILt9ABEr5\")\n",
            "# # from jupyter to chart studio\n",
            "# py.plot(fig, filename = \"plot name\", auto_open = True)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 1. Описание и изучение данных <a class=\"anchor\" id=\"1\"></a>"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### 1.1 Описание данных <a class=\"anchor\" id=\"1-1\"></a>\n",
            "- children - количество детей в семье\n",
            "- days_employed - общий трудовой стаж в днях\n",
            "- dob_years - возраст клиента в годах\n",
            "- education - уровень образования клиента\n",
            "- education_id - идентификатор уровня образования\n",
            "- family_status - семейное положение\n",
            "- family_status_id - идентификатор семейного положения\n",
            "- gender - пол клиента\n",
            "- income_type - тип занятости\n",
            "- debt - имел ли задолженность по возврату кредитов\n",
            "- total_income - ежемесячный доход\n",
            "- purpose - цель получения кредита"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### 1.2 Изучение данных <a class=\"anchor\" id=\"1-2\"></a>"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "сначала грузим 5-10 строк (указываем в `pd.read_csv` `nrow`)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Изучаем данные и определяемся с типами, потом их указваем в `pd.read`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Важно привести названия столбцов к нижнему регистру, убрать пробелы (заменить их на _),  \n",
            "так как в том же merge могту быть проблемы, если это не сделать и вообще будет удобнее работать "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если после попытки привести тип к нужному, мы получили ошибку,  \n",
            "то обязательно изучаем эти строки. Именно строки, не только сами занчения, которые не можем преобразовать.  \n",
            "Часто бывает у нас в ругих столбцах есть категория например, которая портит все,  \n",
            "и при этом это выброс может быть.  Поэтому обязательно првоеряем строки, в которых строки не преобразуются в нужный тип.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Очень важно писать код, чтобы не учитывался порядок столбцов. Чтобы если порядок изменится, то наш скрипт будет работать верно.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Все значения в колонках во всех таблицах нужно привести к нижнему регистру и по возможности к одному языку,  \n",
            "для перевода к одному языку можно использовать словарь, с помощью которого изменить неправильный язык  \n",
            "Это нужно, чтобы когда будем соединять таблицы, у нас условие соеденения правильно сравнивало равные значения.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Также важно категориальные столбцы привести к типу `category` и для столбцов, которые имеют малый диапазон значений заменить на меньший тип,  \n",
            "например на `int8`  "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>children</th>\n",
                     "      <th>days_employed</th>\n",
                     "      <th>dob_years</th>\n",
                     "      <th>education</th>\n",
                     "      <th>education_id</th>\n",
                     "      <th>family_status</th>\n",
                     "      <th>family_status_id</th>\n",
                     "      <th>gender</th>\n",
                     "      <th>income_type</th>\n",
                     "      <th>debt</th>\n",
                     "      <th>total_income</th>\n",
                     "      <th>purpose</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>4042</th>\n",
                     "      <td>1</td>\n",
                     "      <td>-2885.142188</td>\n",
                     "      <td>50</td>\n",
                     "      <td>среднее</td>\n",
                     "      <td>1</td>\n",
                     "      <td>женат / замужем</td>\n",
                     "      <td>0</td>\n",
                     "      <td>F</td>\n",
                     "      <td>сотрудник</td>\n",
                     "      <td>0</td>\n",
                     "      <td>80236.028323</td>\n",
                     "      <td>приобретение автомобиля</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>19177</th>\n",
                     "      <td>2</td>\n",
                     "      <td>-1803.080913</td>\n",
                     "      <td>36</td>\n",
                     "      <td>Среднее</td>\n",
                     "      <td>1</td>\n",
                     "      <td>женат / замужем</td>\n",
                     "      <td>0</td>\n",
                     "      <td>F</td>\n",
                     "      <td>сотрудник</td>\n",
                     "      <td>0</td>\n",
                     "      <td>163292.220004</td>\n",
                     "      <td>строительство собственной недвижимости</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>7372</th>\n",
                     "      <td>1</td>\n",
                     "      <td>-305.540665</td>\n",
                     "      <td>27</td>\n",
                     "      <td>СРЕДНЕЕ</td>\n",
                     "      <td>1</td>\n",
                     "      <td>гражданский брак</td>\n",
                     "      <td>1</td>\n",
                     "      <td>F</td>\n",
                     "      <td>сотрудник</td>\n",
                     "      <td>0</td>\n",
                     "      <td>69799.488812</td>\n",
                     "      <td>ремонт жилью</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>16245</th>\n",
                     "      <td>1</td>\n",
                     "      <td>-1593.946336</td>\n",
                     "      <td>50</td>\n",
                     "      <td>среднее</td>\n",
                     "      <td>1</td>\n",
                     "      <td>женат / замужем</td>\n",
                     "      <td>0</td>\n",
                     "      <td>F</td>\n",
                     "      <td>сотрудник</td>\n",
                     "      <td>1</td>\n",
                     "      <td>107486.332934</td>\n",
                     "      <td>на покупку подержанного автомобиля</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>11563</th>\n",
                     "      <td>0</td>\n",
                     "      <td>-1025.402943</td>\n",
                     "      <td>64</td>\n",
                     "      <td>высшее</td>\n",
                     "      <td>0</td>\n",
                     "      <td>женат / замужем</td>\n",
                     "      <td>0</td>\n",
                     "      <td>M</td>\n",
                     "      <td>госслужащий</td>\n",
                     "      <td>0</td>\n",
                     "      <td>706401.475790</td>\n",
                     "      <td>профильное образование</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "       children  days_employed  dob_years education  education_id  \\\n",
                     "4042          1   -2885.142188         50   среднее             1   \n",
                     "19177         2   -1803.080913         36   Среднее             1   \n",
                     "7372          1    -305.540665         27   СРЕДНЕЕ             1   \n",
                     "16245         1   -1593.946336         50   среднее             1   \n",
                     "11563         0   -1025.402943         64    высшее             0   \n",
                     "\n",
                     "          family_status  family_status_id gender  income_type  debt  \\\n",
                     "4042    женат / замужем                 0      F    сотрудник     0   \n",
                     "19177   женат / замужем                 0      F    сотрудник     0   \n",
                     "7372   гражданский брак                 1      F    сотрудник     0   \n",
                     "16245   женат / замужем                 0      F    сотрудник     1   \n",
                     "11563   женат / замужем                 0      M  госслужащий     0   \n",
                     "\n",
                     "        total_income                                 purpose  \n",
                     "4042    80236.028323                 приобретение автомобиля  \n",
                     "19177  163292.220004  строительство собственной недвижимости  \n",
                     "7372    69799.488812                            ремонт жилью  \n",
                     "16245  107486.332934      на покупку подержанного автомобиля  \n",
                     "11563  706401.475790                  профильное образование  "
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "dtype = {'education': 'category', 'family_status': 'category', 'gender': 'category', 'income_type': 'category'}\n",
            "df = pd.read_csv('https://code.s3.yandex.net/datasets/data.csv', dtype=dtype)\n",
            "df.sample(5, random_state=7)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Используем метод `my_info` или `my_info_gen` для вывода информации о датасете и колонках"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Везде где нужно написать свои мысли по результату, пишем слово жирным шрифтом `Наблюдения:`   \n",
            "и с нового абзаца писать рассуждения списком булитами - или *"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "сделать предположения, почему могло так произойти, выдвигаем гипотезы"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "придумать способы проверки выдвинутых гипотез и записать"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "если у нас по оси x время, то проанализировать сезонность"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "подумать а так и должно было получиться, основываясь на понимании физики параметра  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "зафиксировать возможные рекомендации"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Для гистограмм, нужно понять почему именно такое распределение метрики.  \n",
            "Совпадет это с логикой этой метрики. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Также когда строим гистограммы и вайолин плот, то не просто фиксируем, что есть тяжелые хвосты, разброс между квартилями такой-то.  \n",
            "А думаем почему так, пытаемся связать это с физикой параметра. Должно быть физическое объяснение всех аномалий.  \n",
            "Если объяснения нет, то возможно это инсайт.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Важно убедиться, что у нас есть данные на все источники, которые заявлены. Например, мы изучаем источники трафика и у нас они в разных таблицах.  \n",
            "Нужно убедиться, что во всех таблицах есть все источники, и проверить нет ли аномалий, возможно какой-то сильно выбивается или какого-то вообще где-то нет.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "И очень важно сверить, что периоды в разных таблицах (если у нас больше одной таблицы) совпадают.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Важно проверить соответствуют ли временной период данных тому, который заявлен в задании,  \n",
            "определиться что будем делать с неполными периодами.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Вообще, когда у нас несколько таблиц и там есть категориальные переменные или время, то  \n",
            "мы должны взять уникальные значения категориальных переменных из каждой таблицы (одниаковые переменные) и сравнить.  \n",
            "Количество уникальных должно совпадать, иначе нужно разбираться  \n",
            "И с верменем как минимум мин и макс даты должны совпадать до дня, а лушше до минуты часа"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Очень важно, если у нас есть стартовая дата чего-то и конечная, то обязательно нужно проверить,  \n",
            "нет ли у нас записей, где конечная дата меньше стартовой.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Важная проверка, если у нас есть категории и даты, то сгруппировать по категориями и \n",
            "вывести количество занчений, минимальную и максимальную дату  \n",
            "Таким образом мы сразу поймем распределение в категории и  \n",
            "увидем какие временные интервалы у каждой категории  \n",
            "Если у нас все категории должны быть в один день, то мы поймем нет ли багов"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Вообще очень важно смотреть не только на аномалии в значениях, но и аномалии в категориальных переменных.  \n",
            "А тут аномалией будет отстутствие какого-то значения, хотя в описании или поставновке задачи оно есть.  \n",
            "Также совпадение количества значений категориальных переменных в разных таблицах.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Внимательно посмотреть на столбцы, если есть столбцы, в которых могут быть потенциальные анамали, то проверить их.  \n",
            "Например, есть столбец возрасти стаж работы, проверить, что возраст больше стажа.  \n",
            "И подобные случаи.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проверка на нарушения уникальности   \n",
            "Убедить, что столбцы, значения в которых не должны повторяться и должны быть уникальными, такие в действительности.    \n",
            "Смотрим на результат функции `my_info`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проверка на ошибки целостности  \n",
            "Если у нас есть столбцы, в которых значения должны совпдаать попарно, то проверяем на это  \n",
            "`get_non_matching_rows`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проверка условий  \n",
            "Проверьте, что данные в датафрейме удовлетворяют определенным условиям, таким как \"возраст > 18\" или \"страна == 'Россия'\""
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проверяем на дубли  \n",
            "- Важно помнить, что если у нас есть id и название товара, то названия товара все равно нужно проверить на дубли,  \n",
            "возможно у нас 2 ай ди с одним названием. \n",
            "- Также важно в каждой отдельной колонке проверить дубли и если их много, то посмотреть на соседние колонки, что там происходит\n",
            "- Дубликаты часто носят скрытый характер.  \n",
            "То есть это могут быть поля, которые записаны  по разному, но относятся к одному и тому же.  \n",
            "Поэтому важно, если у нас категориальный признак, изучить нет ли повторящихся категорий, которые записаны немного по разному.  \n",
            "Так как это создает шум, мы по сути имеем две разные категории, но на самом деле это одна. Нужно собрать их в одну.  \n",
            "- И очень важно, если мы не подтвердили, что это действительно дубликат (например у нас нет ай ди клиента и мы не смогли выяснить один и тот же ли это человек),  \n",
            "то нужно аккуратно удалять их. Но и оставлять много дублей плохо, так как они вносят шумы и искажения.  \n",
            "- Помним, что наличие дубликата не говорит точно, что это дубль, возможно у нас нет ещё колонок, котоыре бы детализировали и разделили эти дубли.  \n",
            "Поэтому тут могут быть рекомендации, чтобы добавли в фрейм доп колонки, которые помогут убрать дубли (либо сам ищешь ещё поля)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "`check_duplicated`  \n",
            "`check_duplicated_combinations`  \n",
            "`get_duplicates_value_proportion_by_category`  \n",
            "В первую функцию можно передавать весь датафрейм и можно выбирать нужные столбцы для проверки на дубли и передавать их.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Важно на дубли проверить и отдельные строки и целиком таблицу и подумать какие группы столбцов могут дать дубли и на это тоже проверить.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если в дублях у нас есть ай ди клиента, то тут понятно, если нет ай ди, то пишем рекомендацию, чтобы данные приходили с ай ди,  \n",
            "чтобы можно было понять это один человек или нет "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если у нас id пользователя встречается не одни раз в таблице и есть другие поля которые должны быть всегда одни и те же,  \n",
            "напримем пол и прочее, то нужно проверить у всех ли пользователей все значения одинаковые в этом столбце.  \n",
            "Это может быть не только ай ди, любое уникальное поле, которое повторяется и для каждого этого поля есть другое  \n",
            "поле, которое не должно меняться, нужно проверять а действительно ли это поле не меняется.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проверяем на пропуски    \n",
            "Когда мы встречаем пропуски, прежде всего, нужно ответить на вопрос, существует ли закономерность в появлении пропусков.   \n",
            "Иными словами, не случайно ли их возникновение в наборе данных.  \n",
            "Случайно, значит нет закономерности с соседними столбцами, то есть пропуски есть для разных значений.  \n",
            "А могут быть неслучайные, то есть существует явная закономерностЬ, что пропуски есть только у сторок с общими занчениями в другом столбце.    \n",
            "Чтобы это проверить, нужно взять столбец с пропусками, отфильтровать только пропуски (взять их) и  \n",
            "посмотреть как эти пропуски распределены по другой переменной.    "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Первое что нужно сделать, когда мы видим пропуск или выброс, это проверить является ли оно случайным.  \n",
            "То есть посмотреть не относятся ли все выбросы к одной категории. Если это так, то это уже не случайно и мы нашли аномалию, которую можно изучать.  \n",
            "Если у нас случайны разброс пропусков в категориях, то значит тут есть случайность.  \n",
            "Например, у нас возраст 0, и мы видим, что больше всего это у женщин. Следовательно получаем гипотезу, что женщины не хотят сообщать свой возраст.  \n",
            "- В пропусках мы можем определить какие категории, платформы и прочее не собираются данные. Смотрим пропуски, далее смотрим у каких категорий их больше,  \n",
            "и получаем вывод, что нужно обратить внимание на эти категории или системы, почему там пропуски"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "`find_columns_with_missing_values`  \n",
            "`check_na_in_both_columns`  \n",
            "`get_missing_value_proportion_by_category`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Изучаем выбросы"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Выбросы это не только просто сильно большое или сильно маленькое значение.  \n",
            "- Выбросы нужно также смотреть по мультипараметрам, с помощью моделей и искать аномалии.  \n",
            "- Выброс это то, что отделяется от других, что выбивается из общей картины. Следовательно это что-то особенное.  \n",
            "- Тажке выбросы говорят не только о плюсах, но и о минусах. Выбросы могут сказать, что у нас что-то сломалось.  \n",
            "Что-то не записывается, или работает с багами. Все это можно увдитеь по выбрасам и аномалиям.  \n",
            "- Обязательно посмотреть выбросы в разрезе категорий, так как мы сможем сделать выводы об их источнике.  \n",
            "- Если мы работаем со строгой отчетностью, то тут любой выброс это уже инсайт и нужно идти разбираться откуда это взялось.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Смотрим на выбросы используя Z-score  \n",
            "`detect_outliers_Zscore`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Смотрим на выбросы используя Z-score  \n",
            "`detect_outliers_quantile`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Изучить выбросы по категориями  \n",
            "`get_outlier_quantile_proportion_by_category`  \n",
            "`get_outlier_proportion_by_category_modified_z_score`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Сделать функцию определения выбросов на основе машинного обучения"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Дополнительные моменты, которые стоит проверить и изучить \n",
            "- важно проверить на корректность данные, то есть смотрим по отдельности каждый столбец и изучаем мин, макс, и другие параметры, и  \n",
            "думаем, это физически реально. И особенно, когда у нас несколько связаных параметров, нет ли между ними противоречия.  \n",
            "Например, у нас есть дата показа рекламы и есть дата создания рекламы, естественно создание должно быть раньше, это нужно проверить.  \n",
            "- Проверяем данные ошибки  \n",
            "Ошибки которые не являются дублями, пропусками или выбросами.  \n",
            "Это сложно сделать, хотя бы заметить явные ошибки\n",
            "- Проверить на ошибки согласованности  \n",
            "Например, у нас пользователь с одним ай ди имеет разные имена. \n",
            "`display(df.groupby('name')['age'].nunique())`\n",
            "- вообще нужно придумать разные проверки для колонок, особенно связанных. И провести эту проверку. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### 1.2 Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "portable-collect",
         "metadata": {},
         "source": [
            "Принимаем решение, как именно мы будем проводить обработку, почему именно так, *зафиксировать рекомендации.  \n",
            "То есть отвечаем на вопрос, что будем делать с выбросами, что будем делать с null.  \n",
            "Будет идеально если тут зафиксировать рекомендации  \n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Промежуточный вывод**\n",
            "\n",
            "- **children** Присутствует 47 отрицательных значений с \"-1\", а также аномалия в виде 20 детей ...\n",
            "- **days_employed** Большая часть данных стобца со знаком \"-\". Однако, эти данные представляют из себя 84% всей выборки. ... будут заменены на .. исходя из определенного критерия, который будет описан далее. \n",
            "    - Причины пропущенных значений в столбцах **days_employed** и **income**:\n",
            "        - Во-первых, это может быть из-за неправильной выгрузки данных. Оставим это предположение до того момента, пока не убедимся в неверности других предположений.**Наиболее вероятно**\n",
            "        - Во-вторых, одной из гипотез было предположение об отсутствии трудового опыта у данной части выборки. Однако, если распределение по возрасту в данной группе равномерное по всем возрастам выборки. Также большая доля этой части выборки трудоустроена. **Гипотеза не подтверждена**\n",
            "        - В-третьих, возможно, что эта часть выборки не имеет официального трудоустройства. Данная гипотеза вызывает сомнение в связи с тем, что при наличии достаточно большого стажа работы у представителей выборки у ее представителей нет официального трудового стажа. К тому же 18.9% данной выборки являются госслужащими. **Гипотез не подтверждена**\n",
            "- **age** .. 0 возраст у 101 человека.\n",
            "- **education & education_id** Необходимо будет привести данную категорийнуй переменную к общему виду. Избавиться от разного регистра. Но можно не тратить на это время и использовать следующий столбец **education_id**. Это позволит использовать меньше памяти и не повлияет на качество анализа.\n",
            "- ..."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2. Предобработка данных"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### 2.1 Обрезание неполных временных периодов"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если у нас датасет за год, например, и первый или последний месяц неполные, то их лучше выбрасить, если мы будем  \n",
            "расчитывать месячные метрики.  \n",
            "Но сначала конечно нужно проанализировать столбцы без обрезания, чтобы убедиться, что там нет ничего необычного.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### 2.2 Выбор нужных столбцов для дальнейшей работы и нормализация таблицы"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Думаем, какие колонки нам нужны, выбираем только их для дальнейшей работы.  \n",
            "Остальные убираем в другой датасет. \n",
            "- Важно после изученя данных сначала убрать не нужные столбцы, а потом уже заниматься преобразованием (удалением пропусков и выбросов).  \n",
            "Думаем прежде чем удалять строки, так как возможно лучше удалить столбец и строки удалять будет не нужно.  \n",
            "- Пишем почему выбираем определенные столбцы"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Обработка пропусков"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "dried-general",
         "metadata": {},
         "source": [
            "что-то изменили - > посмотрели не изменилось ли количество дублей   \n",
            "`check_duplicated`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Увидели пропуск — подумайте, нормально ли это. Сколько вообще пропусков может быть в этом столбце?   \n",
            "К примеру, в списке с электронными адресами пользователей, согласных на рассылку, будет много пропусков. Далеко не все предоставляют email."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Можно использвоать такой подход\n",
            "- если количество пропусков меньше 5 процентов, то удаляем (лучше меньше 1 процента)\n",
            "- если количество пропусков от 5 до 20 процентов, то подбираем чем заменить, удалять не стоит\n",
            "- если больше 20 процентов, то не трогаем, так как исказим"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Но оставляя пропуски, нам нужно помнить, что мы не можем по этим полям считать корреляцию с другими,   \n",
            "так как пропуски испортят расчет коэффициента корреляции. Аналогично другие метрики могут считаться некорректно.  \n",
            "Поэтому, если мы будем считать показатели по столбцу с пропусками, то их нужно либо убирать, либо этот столбец не использовать для расчетов.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Для категориальных переменных оставлять пропуски нельзя, так как мы скорее всего будем группировать по ним и смотреть разные разрезы.  \n",
            "Поэтому в худшем случае, если не можем ничем заменить, и нет уверености, что пропуск можно заполнить пустой строкой (если значения физически нет),  \n",
            "то создаем категорию например `other` из пропусков.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если у нас пропуски в категориальной переменной и есть разные периоды или просто данные разбиты на части (то есть эта категориальная переменная повторяется),  \n",
            "то мы можем взять ещё какую-нибудь переменную, у которой нет пропусков, где пропуски у первой переменной и далее посмотреть другие периоды  \n",
            "Таким образом у нас будет предыдущий период, где будет занчение второй переменной и первой и если в нескольких периодах они одинаковые, то мы можем  \n",
            "заполнить и пропуски этим значением.   \n",
            "Ещё раз схема такая - берем 2 поля одно с пропусками, другое без, получаем новую таблицу, в этой таблице оставляем только униклаьные значения в поле без пропусков,  \n",
            "по этому полю будем джойнить. Далее в основнйо таблице дропаем описание и создаем новое описание из таблицы справочника.    \n",
            "`fill_missing_values_using_helper_column`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Заполняем пропуски учитвая категории  \n",
            "`fill_na_with_function_by_categories`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Сделать функцию заполнения пропусков с помощью машинного обучения"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Работа с выбросами"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Очень важно понимать, когда выброс можно отбросить и он реально выброс и когда нельзя.  \n",
            "Опираемся на физику параметра, думаем это значение физически возможно.  \n",
            "- Также выброс может казаться выбрасом, но для бизнеса это не выброс.  \n",
            "Например у нас суммы покупок и одна покупка сильно выделяется, а там просто человек купил супе дорогой каньяк, например.  \n",
            "- Когда хотим обрезать выбросы, то думаем, какой порог может быть физически реальным и по нему режем, а не просто так берем какой-то перцентиль.  \n",
            "Всегда нужно думать с точки зрения физического возможного значения параметра и по нему резать (подумать а какое значение может быть максимально реальным и по нему обрезать)\n",
            "- Если мы имеем дело со строгой отчестностью, то выбросы убирать нельзя, нужно разобраться откуда они.  \n",
            "- Если мы не можем с увереностью сказать, что это выброс, то нам не стоит его выкидывать, но работать как то нужно с ними,  \n",
            "тогда, логарифмируем (лучше использовать натуральный логарифм) эту колонку и работаем с такими значениями (тогда выбросы сожмуться).  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Обработка дубликатов"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если есть дубли, и мы считаем, что это не дубли, а просто разделились данные,    \n",
            "то объединеняем записи, которые имеют одинаковые значения ключевых признаков.  \n",
            "`merge_duplicates`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если мы не уверены, что дубль является дублем и не хотим удалять, то можно  использовать  \n",
            "маркировку дублей,  можно добавить новую колонку, которая будет содержать информацию о том,   \n",
            "является ли строка дубликатом или нет.  \n",
            "`df['is_duplicate'] = df.duplicated()`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Подумать, а можем ли мы обогатить данные, что разделит дубли.  \n",
            "То есть возможно в наших данных нет какого-то столбца, и тогда дубли уже не будут дублями. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если уверены, что это дубли, то удаляем их  \n",
            "`df.drop_duplicates()`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Категоризация данных"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Придумываем какие колонки можно дополнительно сделать из имеющихся.  \n",
            "Например у нас есть колонка длительность звонков, и 0 это пропущенный звонок,  \n",
            "мы можем сделать колонку is_missed, в которой будет true или false  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Очень важно, когда мы создаем новые колонки, в которых используем несколько дургих, то нужно проверить распределение этой новой переменной, особенно выбросы.  \n",
            "Например, у нас начальная и конечная дата сессии и мы считаем длительность сессии. Вот тут нужно посмотреть какая минимальная длительность  \n",
            "и какая максимальная. Ну и естественно проверить есть ли длительность 0 и меньше нуля.  \n",
            "Таким образом мы можем найти инсайты уже после создания новых колонок, хотя в изначальных данных этих инсайдов не было видно.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Обычная категоризация данных"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Категоризация помогает избежать проблемы с разреженными данными, когда у нас есть слишком много групп с небольшим количеством элементов.   \n",
            "Это может привести к некорректным выводам и ошибкам в анализе.\n",
            "Категоризация нужна, чтобы образовать группы, в которых достаточно значений для использования статистических методов.  \n",
            "И вообще, если в группе 1-10 элементов, например у нас возраст пользователей и 5 человек с возрастом 22, 3 человека с возрастом 23 и так далее.  \n",
            "Мы не можем разбивать по таким группам, так как их размер небльшой и выводы будут некорректные, поэтому нам нужно собрать их в группы,  \n",
            "чтобы у нас были группы с достаточным размером.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Если у нас категориальная переменная имеет много значений, то мы не можем номрально с ней работать.  \n",
            "Так как мы не можем построить графики по ним, так как их много и они не числовые. Не можем сравнить их все.  \n",
            "Поэтому нам нужно сократить категории.  \n",
            "- Нужно посмотреть на данные и подумать можем ли мы разделить их по сегментам рынка или по другим категориям, которые нам помогут.  \n",
            "- Мы можем категоризировать на основе и числовых и категориальных столбцов. То есть мы можем из категориальной переменной сделать  \n",
            "другую категориальную, уменьшив или увеличив разбиение.   \n",
            "- добавление категорий обогощает данные, при чем категории могут формироваться не из одной колонки, а из серии, то есть чтобы попасть  \n",
            "в определенную категорию значения столбцов должно быть такое то, а не только один столбец определяет категорию.  \n",
            "- категории могут быть да нет, то есть состоять из двух значений, например, у нас есть данные о рекламе и столбец где она показвалась,  \n",
            "и у нас много много разных устройств. Мы можем разбить на да нет, то есть показвалась реклама по телеку или нет"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Мы можем разбить данные на категории двумя способами\n",
            "- разбивать на равные части  \n",
            "подходит, когда \n",
            "    - диапазон значений является равномерным и имеет линейную структуру  \n",
            "    - мы понимаем на какие интервалы хотим разбить данные    \n",
            "    - мы хотим разделить диапазон значений на равные части для удобства анализа.\n",
            "- разбить на основе квантилей  \n",
            "подходит, если   \n",
            "    - диапазон значений имеет неравномерную структуру\n",
            "    - мы не можем понять какие интервалы выбрать\n",
            "    - хотим выделить группы с конкретными характеристиками (например, группы с низким доходом, средним доходом и высоким доходом)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Выбираем нужные способ и используем  \n",
            "`create_category_column`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Категоризация с использованием лемматизации"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если у нас есть столбец и мы хотим его лематизировать, то используем функцию  \n",
            "`lemmatize_column`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "С помощью лематизации мы можем сократить количество категорий.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Например мы можем выделить группы:\n",
            "- операции с автомобилем (ключевое слово - автомобиль)\n",
            "- операции с недвижимостью (ключевые слова: жилье, недвижимость)\n",
            "- проведение свадьбы (ключевое слово: свадьба)\n",
            "- получение образования (ключевое слово: образование)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Используем функцию  \n",
            "`categorize_column_by_lemmatize`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Feature engineering"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если мы хотим преобразовать категории в числа, то мы можем использовать \n",
            "- lable encoding  \n",
            "Заменяем быквы числами. Хорошо работает, когда у нас порядковые категориальные переменные.  \n",
            "Не забываем про порядок, если у нас алфавитный порядок наших категорий соотвествует числовому, то ок,  \n",
            "если нет, то нам нужно самим определить порядок чисел, чтобы они соответствовали категориям в нужном порядке.  \n",
            "- one hot encoding  \n",
            "Если у нас категориальная переменная не упорядочиваемая, то лучше использовать one hot encoding, чтобы разница между числами не вносила шум,  \n",
            "так как черный и белый и красный цвет закодированные 1, 2, 3 вносят смысл количества, но они не имеют этого свойства.  \n",
            "-  target encoding  \n",
            "замена категориальной переменной на каую-то статистику по одной из категорий внутри этой переменной.  \n",
            "Например у нас категориальная переменная это наличие задержки. Значение задержан / незадержан. Мы кодируем их как 0 и 1. Далее мы берем и считаем по каждой группе (для задержан и для незадержан)  \n",
            "статистику, например, среднее и получаем столбец, где вместо каждой буквы будет ее среднее.  \n",
            "Тут важно делать регуляризацию. Так как маленькие группы могут иметь сильно  зашумленные статистики, так как если у нас  \n",
            "группа из 5 значений, то среди них может быть легко экстремальное одно и оно сбивает статистику, поэтому добавляем штраф всем статистикам.  \n",
            "Регуляризация это что-то похожее на сглаживание.  \n",
            "Как это делается \n",
            "    - берем считаем среднее по таргету (целевой переменной, то есть той, по которой мы счтаем статистику) всей таблице (то есть не делим на категории)  \n",
            "    - Далее используем следующую формулу для сглаженного значения среднего по конкретной группе:   \n",
            "      (среднее по группе * количество элементов в группе + среднее по таргету без учета категорий * размер регуляризирующей группы) / (количество элементов в категории + размер регуляризирующей группы)  \n",
            "      Количество элементов в регуляризационнной группе выбирает эмперически. То есть это количество элементов, которым мы сглаживаем.    \n",
            "      Смысл в том, что мы берем сколько-то элементов с занчением для всех категорий и сглаживаем им наши отдельные категории.    \n",
            "    - Размер регуляризирующей группы обычно выбирают с помощью grid search, то есть берут цикл для размера этой группы и считают результат модели для каждого размера,  \n",
            "    и потом выбирают тот размер, для которого результат лучше.    \n",
            "    \n",
            "`target_encoding_linear`  \n",
            "`target_encoding_bayes`      \n",
            "    \n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Использование кластеризации для категоризации"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Можно понизить размерность до 3  \n",
            "и построить 3 д график  \n",
            "По этому графику посмотреть есть ли у нас возможные кластеры  \n",
            "Если есть, то выделить их  \n",
            "Причем для понижения размерности можно брать все столбцы, а можно только часть."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Обогощение таблиц (соединение с другими)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проверка соответствия:   \n",
            "Если у нас в разных таблицах есть значения, которые дожны быть одинакоые,    \n",
            "то нужно проверить, что значения в одном столбце соответствуют значениям в другом столбце. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df['column_name1'].equals(df['column_name2'])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Обоготить данные можно следующими способами\n",
            "- взять поле нашей таблицы и найти дополнительные данные в интернете или ещё где-то и потом связать с нашей колонкой по этому полю  \n",
            "Самое просто это дата, если у нас есть дата, то мы можем много разной доп информации внести в наши данные связывая по дате.  \n",
            "Также, например, у нас есть какие-то коды чего-то, мы ищем информацию по этим кодам и находим табличку с доп инфой по этим кодам и можем обоготить ими   \n",
            "нашу таблицу. Например, у нас города или страны, мы можем по ним также внести доп инфу из какого-то источника, которая нам поможет.  \n",
            "Вообще любое поле нашей таблицы это потенцильная нить для обогощения. Главное понять с чем полезным мы можем соеденить  \n",
            "через конкретное поле, чтобы получить больше полезной информации для анализа, по сути для детализации наших зависимостей или для поиска  \n",
            "новых зависимостей и инсайтов в них.  \n",
            "Процесс следующий - мы берем каждую колонку нашего дата сета и думаем, с чем через нее мы можем связать и если придумываем, то идешь ищем эту информацию и  \n",
            "в итоге соединяем.  \n",
            "- Можно пойти от обратного. Сначал подумтаь какие данные нам могут помочь и поискать их в интернете например, а потом уже думать как их соеденить с нашими   \n",
            "данными. Оба способа лучше делать одновременно.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Каждый раз, когда мы работаем с дата сетом, мы должны понять что является сущностью этого дата сета.  \n",
            "Например событие, человек и прочее.  \n",
            "Далее нам нужно поянть а можем ли мы его идентифицировать по текущим данным (не всегда есть уникальный ай ди).   \n",
            "Если не можем, то нужно думта как обогатить данные, чтобы четко идентифицировать сущности"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Что нужно обязательно првоерить после соединения\n",
            "- если мы соединяем по полю, которое уникально в обеих таблицах\n",
            "    - количество строк в левом датафрейме равно количеству строк в итоговом\n",
            "    - параметры каждого дата сета не изменились (если мы соединили правильно, то итоговые суммы по столбцам не должны измениться)\n",
            "        - используем `df.sum(numeric_only=True)` для каждой таблицы до соединения и для общей таблицы и сравниваем значения\n",
            "        - можно использвоать `df.describe` также до и после объединения и сравнивать параметры\n",
            "- если у нас в одной из колонок для соединения не уникальные значения (то есть для одной строки в левой таблице будет несколько в итоговй)    \n",
            "    - Сначала группируем таблицы, чтобы поле для соединения в обеих таблицах было уникальное\n",
            "    и применяем предыдущий шаг с количеством строк в левой и итоговой и суммой значений в левой и итоговой одинаковой\n",
            "    - Если нам нужно соеденить без группировки (но это редко может быть, поэтому нужно подумать точно ли не моежм сгруппировать)  \n",
            "    тогда нет выбора и остаются только следующие варианты  \n",
            "        - если в левой таблице уникальные записи в колонке, по которйо соединяем    \n",
            "            - тогда считаем сколько было записей в левой таблице в колонке для соединения и сравниваем с количеством **уникальных** записей в итоговой  \n",
            "            они должны совпадать, но тут важно в итоговой брать уникальные записи\n",
            "        - есил и в левой и правой нет уникальных\n",
            "            - тут считаем сколько **уникальных** в левой до и сколько **уникальных** в итоговой, должно совпадать"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если у нас что-то не сходится после соединения таблиц, то нужно внимально изучить это.  \n",
            "Тут может быть инсайт (кто-то не правильно вносит информацию, какие-то значения неверные или кто-то что-то хотел спрятать, не указать и прчоее).  \n",
            "Когда видим нестыковки после соединения таблиц, то должна загораться красная лампочка. Это потенциальный инсайт, баг, который мы можем найти и сообщить, чтобы его починили. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "помним, что метод соединения inner стоит по умолчанию в merge"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "В колонках, по которым будем соеднить, проверяем, нет ли пропусков, пропуски нужно заменить нулями.  \n",
            "Иначе будет либо ошибка, либо пропуски сджойнятся с пропусками"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проблема справочников  \n",
            "При объединение таблиц важно помнить про то, что в разных таблицах не только названия столбцов может быть разное,  \n",
            "но и одно значение может быть записано по разному в разных таблицах, например, названия профессий, названия городов,  \n",
            "имя в одной таблице на русском, а в другой на английском, номер телефона с черточкой или плюсом и без черточки или плюса.  \n",
            "Поэтому не забываем привести все значения таблиц к нижнему регистру, чтобы не было проблем разными регистрами для одного слова"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проблема временных зон  \n",
            "В одной таблице может быть выгрузка по местному времени, а в другом по московскому  \n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Проблема курсов валют  \n",
            "Разыне системы могут брать курс за разные промежутки вермени, например, одна система берет курс в гугле (раз в час обновляется),  \n",
            "а другая система берет курс в ЦБ (обновляется раз в сутки)  \n",
            "И поэтому итоговые резултаты могут не состыковаться, поэтому, когда видим курсы валют, то нужно убедиться. что они взяты из одного испточника  \n",
            "и за один промежуток времени  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Когда мы работаем с данными, нам важно четко идентифицировать клиентов, событие или другую сущность, с которой мы работаем.  \n",
            "Иначе у нас будет шум, так как мы одного и того же клиента учтем более одного  раза."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Как можно обоготить данные, чтобы лучше идентифицировать сущности\n",
            "- Добавить для клиента email, телефон, устройство, 4 цифры карты и другое, что может помочь его идентифицировать  \n",
            "    Это важно так как у клиента могут быть разные телефоны, устройства, карты, но все это вместе поможет его идентифицировать точнее\n",
            "- Добавить для события локацию, погоду, связанные событие, праздники, что поможет нам идентифицировать событие   "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Сравнение метрик между собой"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Чтобы сравнить метрики между собой мы можем\n",
            "- использовать корреляционный анализ\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "`heatmap(df.corr())`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Использование регрессии и случайного леса для определения влияния переменных  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Коэффициенты регрессии позволяют оценить влияние каждой переменной на целевую переменную, учитывая влияние других переменных,  \n",
            "в то время как важные компоненты в случайном лесе позволяют оценить важность каждой переменной для предсказания целевой переменной."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Используем регрессиию "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Чтобы построить регрессию и посмотреть стат значимость и коэффициенты удобно использовать модуль statsmodel"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "VIF означает Variance Inflation Factor (Фактор инфляции дисперсии). Это статистическая метрика,   \n",
            "используемая для обнаружения мультиколлинеарности (сильной корреляции) между предикторами (фичами) в линейной регрессии."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Обычно, VIF интерпретируется следующим образом:\n",
            "\n",
            "- VIF < 5: слабая мультиколлинеарность\n",
            "- 5 ≤ VIF < 10: умеренная мультиколлинеарность\n",
            "- VIF ≥ 10: сильная мультиколлинеарность"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "\n",
            "Смотрим R2 (коэффициент детерминации)\n",
            "- использовать коэффициенты у регресси\n",
            "Мы строим регрессию и смотрим, у каких метрик больше коэффициенты. Таким образом мы поймем какие метрики сильнее зависят с целевой.  \n",
            "Важно, чтобы независимые переменные некоррелировали по отдельности и вместе (мультиколлиниарность).  \n",
            "По отдельности смотрим матрицу корреляции.  \n",
            "Чтобы определить коррелириуют ли вместе, береме независимые переменные,  \n",
            "и перебираем их выбирая одну из них целевой и смотрим R2.  \n",
            "Если R2 большой, то значит эта метрика (которая целевая на этом шаге) хорошо описывается другими и ее можно выбросить.\n",
            "Также не забываем поправки на гетероскедостичность (HC0, HC1, HC2, HC3) в статпакетах.  \n",
            "Нам нужно ответить на следующие вопросы\n",
            "    - Влияет ли метрика на целевую?\n",
            "    Оцениваем коэффициенты в уравнении регресси у каждой метрики.  \n",
            "    - Как влияет метрика на целевую?\n",
            "    Смотрим R2 (коэффициент детерминации). И определяем какая часть целевой переменной определяется независимыми метриками.  \n",
            "    - Коэффициенты при метриках в уравнении статистически значим? При какаом уровне значимости?\n",
            "    Смотрим в стат пакете p value для каждого коэффициента, что нам говорит значим ли этот коэффициент.  \n",
            "    То есть мы не просто смотрим его абсолютное значение, а учитываем p value.   \n",
            "    - Дайте содержательную интерпретацию коэффицентам?\n",
            "    При увеличении метрики k на 1, целевая метрика увеличивается на $b_{k} * 1$\n",
            "    То есть нужно перевести коэффициенты в реальное сравнение, насколько увелчисться целевая метрика при изменении определенной метрики на 1\n",
            "    - Найдите 95 процентный доверительный интервал.\n",
            "    В стат пакете смотрим значение и оно говорит, что если мы многократно повторим ноши вычисления с новыми данными, то 95 процентов наших  \n",
            "    полученных коэффицентов будут лежать в этом диапазоне.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Строим модель и изучаем результат  \n",
            "`linear_regression_with_vif`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Испльзовать коэффициенты у классификацию    \n",
            "Строим случайный лес какие метрики сильнее всего влияют на решения модели.   \n",
            "`plot_feature_importances_classifier`   \n",
            "`plot_feature_importances_regression`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "На основе полученных данных формулируем гипотезы, которые будем проверять в блоке проверки гипотез"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            " используем быблиотеку `shap`, чтобы определить метрики, которые лучше других помогают предсказывать целевую перемменную"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Когортный анализ"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Не забывать про когортный анализ. Если у нас есть параметр, по которому мы можем наши данные разбить на когорты, то  \n",
            "нужно разложить на когорты и посмотреть динамику по когортам.  \n",
            "Когорты это например, пользователи пришедшие в одни день или месяц.  \n",
            "Если мы объеденим пользователей в когорты и посмотрим динамику какого-то параметра по месяцам например, то увидим как изменяется.  \n",
            "Тут также нужно помнить, что если значение например за 3 месяц больше значения за 4 месяц, то это ничего не значит само по себе.  \n",
            "Так как мы имеем дело с выборкой, то нам нужно проверить статистически значимая это разница.  \n",
            "Тут нам понядобятся стат тесты.  \n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 3 Анализ взаимосвязей переменных на графиках"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Сначала раздел графиков  \n",
            "На основе графиков формируются гипотезы (например, у нас у мужчин зп больше)\n",
            "И после раздела графиков идет раздел проверки гипотез. Тут мы првоеряем разные гипотезы новые и те, что увидели на графиках.  \n",
            "Это правильная последовательность сначала изучили графики и потом на основе их сформировали гипоетзы\n",
            "Перед разделом про графики идет раздел с корреляцией и поиском главных компонет случайного леса.  \n",
            "Мы выбиарем переменную, для которой мы далее хотим посмотреть разыне зависимости и указываем ее целевой для сучайного леса  \n",
            "И смотрим какие фичи сильнее влияют.  \n",
            "И теперь можем построить графики с целевой перменно и этими главными фичами и в выводе можно указать про то что это важные компоненты случаного леса"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "На основе полученных данных формулируем гипотезы, которые будем проверять в блоке проверки гипотез"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Изучаем зависимости временем и другими переменными"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Строим когортный анализ, если есть возможность"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Если у нас есть даты, то мы можем посмотреть не просто абсолютные значения на каждую дату какой-то метрики,  \n",
            "а посмотреть относительные значения относительно предыдущего значения.  \n",
            "Для этого нужно составить таблицу, в которой будет изменение в процентах относительно предыдущего значения.  \n",
            "И затем визуализировать для каждой даты динамику этого показателя "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Изучаем зависимости между числовыми переменными"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Изучаем scatter plots"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pairplot = sns.pairplot(df, markers=[\"o\"], \n",
            "                        plot_kws={'color': (128/255, 60/255, 170/255, 0.9)},\n",
            "                        diag_kws={'color': (128/255, 60/255, 170/255, 0.9)})"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import plotly.express as px\n",
            "df = px.data.iris()\n",
            "fig = px.density_contour(df, x=\"sepal_width\", y=\"sepal_length\")\n",
            "fig.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Изучаем зависимости между категориальными переменными"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Строим матрицу тепловой карты для категориальных переменных и изучаем зависимости  \n",
            "`categorical_heatmap_matrix_gen`"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Строим treemap  \n",
            "`treemap`   \n",
            "`treemap_dash`   \n",
            "```\n",
            "app = treemap_dash(df)\n",
            "if __name__ == '__main__':\n",
            "    app.run_server(debug=True)\n",
            "```"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Строим parallel_categories    \n",
            "`parallel_categories `  \n",
            "`parallel_categories_dash `  \n",
            "```\n",
            "app = treemap_dash(df)\n",
            "if __name__ == '__main__':\n",
            "    app.run_server(debug=True)\n",
            "```"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Строим Sankey  \n",
            "`sankey `   \n",
            "`sankey_dash`\n",
            "\n",
            "```\n",
            "app = treemap_dash(df)\n",
            "if __name__ == '__main__':\n",
            "    app.run_server(debug=True)\n",
            "```"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Изучаем зависимости между числовыми и категориальными переменными"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 286,
         "metadata": {},
         "outputs": [],
         "source": [
            "dff = df.copy()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>children</th>\n",
                     "      <th>days_employed</th>\n",
                     "      <th>dob_years</th>\n",
                     "      <th>education</th>\n",
                     "      <th>education_id</th>\n",
                     "      <th>family_status</th>\n",
                     "      <th>family_status_id</th>\n",
                     "      <th>gender</th>\n",
                     "      <th>income_type</th>\n",
                     "      <th>debt</th>\n",
                     "      <th>total_income</th>\n",
                     "      <th>purpose</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>1</td>\n",
                     "      <td>-8437.673028</td>\n",
                     "      <td>42</td>\n",
                     "      <td>высшее</td>\n",
                     "      <td>0</td>\n",
                     "      <td>женат / замужем</td>\n",
                     "      <td>0</td>\n",
                     "      <td>F</td>\n",
                     "      <td>сотрудник</td>\n",
                     "      <td>0</td>\n",
                     "      <td>253875.639453</td>\n",
                     "      <td>покупка жилья</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "   children  days_employed  dob_years education  education_id  \\\n",
                     "0         1   -8437.673028         42    высшее             0   \n",
                     "\n",
                     "     family_status  family_status_id gender income_type  debt   total_income  \\\n",
                     "0  женат / замужем                 0      F   сотрудник     0  253875.639453   \n",
                     "\n",
                     "         purpose  \n",
                     "0  покупка жилья  "
                  ]
               },
               "execution_count": 32,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df.head(1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import plotly.graph_objects as go\n",
            "import pandas as pd\n",
            "\n",
            "# Создаем график Plotly\n",
            "func = 'sum'\n",
            "cat_columns = ['education']\n",
            "num_columns = ['dob_years']\n",
            "df_t = df[cat_columns + num_columns].groupby(cat_columns).agg({num_columns[0]: func}).reset_index().sort_values(num_columns[0], ascending=False)\n",
            "\n",
            "# Создаем графики для каждого типа\n",
            "bar_fig = go.Bar(x=df_t['education'], y=df_t['dob_years'])\n",
            "line_fig = go.Scatter(x=df_t['education'], y=df_t['dob_years'], mode='lines', visible=False)\n",
            "area_fig = go.Scatter(x=df_t['education'], y=df_t['dob_years'], mode='lines', fill='tozeroy', visible=False)\n",
            "\n",
            "# Создаем кнопки для смены типа графика\n",
            "buttons = [\n",
            "    dict(label='Bar', method='update', args=[{'visible': [True, False, False]}]),\n",
            "    dict(label='Line', method='update', args=[{'visible': [False, True, False]}]),\n",
            "    dict(label='Area', method='update', args=[{'visible': [False, False, True]}])\n",
            "]\n",
            "\n",
            "\n",
            "# Создаем layout графика\n",
            "fig = go.Figure(data=[bar_fig, line_fig, area_fig])\n",
            "fig.update_layout(\n",
            "    updatemenus=[\n",
            "        dict(\n",
            "            type=\"buttons\",\n",
            "            direction=\"left\",\n",
            "            buttons=buttons,\n",
            "            pad={\"r\": 10, \"t\": 70},\n",
            "            showactive=True,\n",
            "            x=0.11,\n",
            "            xanchor=\"center\",\n",
            "            y=1,\n",
            "            yanchor=\"bottom\"\n",
            "        ),\n",
            "    ],\n",
            "    margin=dict(t=100)  # добавляем верхний отступ для кнопок\n",
            ")\n",
            "\n",
            "# Показываем график\n",
            "fig.show(config=dict(displayModeBar=True))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 232,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<module 'my_module' from 'c:\\\\Git\\\\Projects\\\\Исследование надёжности заёмщиков\\\\my_module.py'>"
                  ]
               },
               "execution_count": 232,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "importlib.reload(my_module)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 99,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "array([1, 2, 3, 4, 5])"
                  ]
               },
               "execution_count": 99,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "np.union1d(np.array([1,2,3]), np.array([1,2,4,5,]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.head(1)       "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "'col1'"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(px.line([1,2,3], markers=True))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "dtype('O')"
                  ]
               },
               "execution_count": 61,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df.education.astype('object').dtype"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>children</th>\n",
                     "      <th>days_employed</th>\n",
                     "      <th>dob_years</th>\n",
                     "      <th>education</th>\n",
                     "      <th>education_id</th>\n",
                     "      <th>family_status</th>\n",
                     "      <th>family_status_id</th>\n",
                     "      <th>gender</th>\n",
                     "      <th>income_type</th>\n",
                     "      <th>debt</th>\n",
                     "      <th>total_income</th>\n",
                     "      <th>purpose</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>1</td>\n",
                     "      <td>-8437.673028</td>\n",
                     "      <td>42</td>\n",
                     "      <td>высшее</td>\n",
                     "      <td>0</td>\n",
                     "      <td>женат / замужем</td>\n",
                     "      <td>0</td>\n",
                     "      <td>F</td>\n",
                     "      <td>сотрудник</td>\n",
                     "      <td>0</td>\n",
                     "      <td>253875.639453</td>\n",
                     "      <td>покупка жилья</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "   children  days_employed  dob_years education  education_id  \\\n",
                     "0         1   -8437.673028         42    высшее             0   \n",
                     "\n",
                     "     family_status  family_status_id gender income_type  debt   total_income  \\\n",
                     "0  женат / замужем                 0      F   сотрудник     0  253875.639453   \n",
                     "\n",
                     "         purpose  \n",
                     "0  покупка жилья  "
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df.head(1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.nunique"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "cat_columns = ['education', 'gender']\n",
            "num_column = 'dob_years'\n",
            "(df[[*cat_columns, num_column]]\n",
            "            .groupby(cat_columns)\n",
            "            .agg(count = (num_column, 'count'), nunique = (num_column, 'nunique'),modes = (num_column, lambda x: '')) \n",
            ")            "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# , 'text': [[', '.join(map(str,x)) for x in prepare_df(config)['modes'].to_list()]]\n",
            "# , 'hovertemplate': '<br>Value: %{y:.2f}<br>Modes: %{text}'\n",
            "# , 'marker': {'color': ['#049CB3' if len(x) > 1 else 'rgba(128, 60, 170, 0.9)' for x in prepare_df(config)['modes'].to_list()]}\n",
            "\n",
            "\n",
            "# , 'text': ['']\n",
            "# , 'hovertemplate': '<br>Value: %{y:.2f}'\n",
            "# , 'marker': {'color': ['rgba(128, 60, 170, 0.9)' for x in prepare_df(config)['modes'].to_list()]}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 219,
         "metadata": {},
         "outputs": [],
         "source": [
            "def treemap(df, columns, values=None):\n",
            "    \"\"\"\n",
            "    Creates an interactive treemap using Plotly.\n",
            "\n",
            "    Parameters:\n",
            "    df (pandas.DataFrame): dataframe with data for the treemap.\n",
            "    columns (list): list of columns to use for the treemap.\n",
            "    values (str): column for values, if None - values  will be calculated as count.\n",
            "    Returns:\n",
            "    fig (plotly.graph_objs.Figure): interactive treemap figure.\n",
            "    \"\"\"\n",
            "    fig = px.treemap(df, path=[px.Constant('All')] + columns\n",
            "                     , values = values\n",
            "                     , color_discrete_sequence=[\n",
            "                         'rgba(148, 100, 170, 1)',\n",
            "                         'rgba(50, 156, 179, 1)',\n",
            "                         'rgba(99, 113, 156, 1)',\n",
            "                         'rgba(92, 107, 192, 1)',\n",
            "                         'rgba(0, 90, 91, 1)',\n",
            "                         'rgba(3, 169, 244, 1)',\n",
            "                         'rgba(217, 119, 136, 1)',\n",
            "                         'rgba(64, 134, 87, 1)',\n",
            "                         'rgba(134, 96, 147, 1)',\n",
            "                         'rgba(132, 169, 233, 1)'\n",
            "                     ])\n",
            "    fig.update_traces(root_color=\"silver\", hovertemplate=\"<b>%{label}<br>%{value:.2f}</b>\")\n",
            "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
            "    fig.update_traces(hoverlabel=dict(bgcolor=\"white\"))\n",
            "    return fig"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.groupby(['education', 'gender'], as_index=False)[['dob_years']].mean()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import plotly.express as px\n",
            "import plotly.graph_objects as go\n",
            "from plotly.subplots import make_subplots\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "# Create heatmap\n",
            "# Create heatmap\n",
            "# Create heatmap\n",
            "# piv = df.pivot_table(index='gender', columns='education', values='dob_years', aggfunc='sum')\n",
            "pagr = df.groupby(['education', 'gender'], as_index=False)[['dob_years']].mean()\n",
            "fig_treemap = treemap(pagr, ['education', 'gender'], 'dob_years')\n",
            "# fig_treemap.show()\n",
            "def prepare_data_treemap(df, cat_columns, value_column, func='sum'):\n",
            "    df_in = df[cat_columns + [value_column]].copy()\n",
            "    prefix = 'All/'\n",
            "    df_grouped_second_level = df_in[[*cat_columns, value_column]].groupby(cat_columns).agg({value_column: func}).reset_index()\n",
            "    df_grouped_second_level['ids'] = df_grouped_second_level[cat_columns].apply(lambda x: f'{prefix}{x[cat_columns[0]]}/{x[cat_columns[1]]}', axis=1)\n",
            "    df_grouped_second_level['parents'] = df_grouped_second_level[cat_columns].apply(lambda x: f'{prefix}{x[cat_columns[0]]}', axis=1)\n",
            "    df_grouped_second_level = df_grouped_second_level.sort_values(cat_columns[::-1], ascending=False)\n",
            "    # df_grouped = df_grouped.drop(cat_columns[0], axis=1)\n",
            "    df_grouped_first_level = df_grouped_second_level.groupby(cat_columns[0]).sum().reset_index()\n",
            "    df_grouped_first_level['ids'] = df_grouped_first_level[cat_columns[0]].apply(lambda x: f'{prefix}{x}')\n",
            "    df_grouped_first_level['parents'] = 'All'\n",
            "    df_grouped_first_level = df_grouped_first_level.sort_values(cat_columns[0], ascending=False)\n",
            "    all_value = df_grouped_first_level[value_column].sum()\n",
            "    res_df = pd.concat([df_grouped_second_level.rename(columns={cat_columns[1]: 'labels', value_column: 'values'}).drop(cat_columns[0], axis=1)\n",
            "                        , df_grouped_first_level.rename(columns={cat_columns[0]: 'labels', value_column: 'values'})\n",
            "                        , pd.DataFrame({'parents': '', 'labels': 'All',  'values': all_value, 'ids': 'All'}, index=[0])]\n",
            "                        , axis=0)\n",
            "    return res_df\n",
            "# fig_heatmap.update_layout(\n",
            "#     annotations=[\n",
            "#         dict(\n",
            "#             text=f\"{value:.2f}\",\n",
            "#             x=x,\n",
            "#             y=y,\n",
            "#             xref=\"x\",\n",
            "#             yref=\"y\",\n",
            "#             showarrow=False,\n",
            "#         )\n",
            "#         for y, row in enumerate(piv.values)\n",
            "#         for x, value in enumerate(row)\n",
            "#     ]\n",
            "# )\n",
            "# Create bar chart\n",
            "fig_bar = px.histogram(x=df['education'], y=df['dob_years'])\n",
            "\n",
            "# Create a subplot with both graphs\n",
            "fig = go.Figure()\n",
            "fig.add_trace(sankey(df, ['education', 'gender']).data[0])\n",
            "fig.add_trace(fig_bar.data[0])\n",
            "# fig.update_layout(coloraxis=dict(colorscale=[(0, 'rgba(204, 153, 255, 0.1)'), (1, 'rgb(127, 60, 141)')])\n",
            "#                   , hoverlabel=dict(bgcolor='white'),)\n",
            "# Add annotations to the subplot layout\n",
            "# fig.update_layout(annotations=annotations)\n",
            "\n",
            "# Set initial visibility of traces\n",
            "fig.data[0].visible = True\n",
            "# fig.data[1].visible = False\n",
            "# fig.data[0].xgap=3\n",
            "# fig.data[0].ygap=3\n",
            "# fig.data[0].colorscale = [(0, 'rgba(204, 153, 255, 0.1)'), (1, 'rgb(127, 60, 141)')]\n",
            "# fig.data[1].colo color_continuous_scale=[(0, 'rgba(204, 153, 255, 0.1)'), (1, 'rgb(127, 60, 141)')]\n",
            "df_treemap = prepare_data_treemap(df, ['education', 'gender'], 'dob_years', 'mean')\n",
            "treemap_ids = df_treemap['ids'].to_numpy()\n",
            "treemap_parents = df_treemap['parents'].to_numpy()\n",
            "treemap_labels = df_treemap['labels'].to_numpy()\n",
            "treemap_values = df_treemap['values'].to_numpy()\n",
            "# display(treemap_ids)\n",
            "# display(treemap_parents)\n",
            "# display(treemap_labels)\n",
            "# display(treemap_values)\n",
            "# pagr = df.groupby(['education', 'gender'], as_index=False)[['dob_years']].mean()\n",
            "# treemap_trace = treemap(df, ['education', 'gender'], 'dob_years')\n",
            "# treemap_ids = treemap_trace.data[0].ids\n",
            "# treemap_parents = treemap_trace.data[0].parents\n",
            "# treemap_labels = treemap_trace.data[0].labels\n",
            "# treemap_values = treemap_trace.data[0].values\n",
            "# display(treemap_parents)\n",
            "\n",
            "df_bar = df.groupby('education')[['dob_years']].mean().reset_index()\n",
            "x_bar = df_bar['education']\n",
            "y_bar = df_bar['dob_years']\n",
            "\n",
            "df_bar_sum = df.groupby('education')[['dob_years']].sum().reset_index()\n",
            "x_bar_sum = df_bar_sum['education']\n",
            "y_bar_sum = df_bar_sum['dob_years']\n",
            "# display(piv_renew)\n",
            "# display(df_bar)\n",
            "buttons = [\n",
            "    {'label': 'Heatmap', \n",
            "     'method': 'update', \n",
            "     'args': [{'visible': [True, False]\n",
            "            #    , 'xaxis': {'visible': False}\n",
            "            #    , 'yaxis': {'visible': False}\n",
            "    },\n",
            "                                    # {'xaxis': {'visible': False}\n",
            "                                    # , 'yaxis': {'visible': False}}                                                \n",
            "              ]},                \n",
            "\n",
            "    {'label': 'Bar Chart', \n",
            "     'method': 'update', \n",
            "     'args': [{'visible': [False, True]\n",
            "            #    , 'xaxis': {'visible': False}\n",
            "            #    , 'yaxis': {'visible': False}\n",
            "    }, \n",
            "                                    #     {'xaxis': {'visible': True}\n",
            "                                    # , 'yaxis': {'visible': True}}\n",
            "                                    ]},\n",
            "    {'label': 'Mean', \n",
            "     'method': 'update', \n",
            "     'args': [{\n",
            "                'orientation': ['h', 'h']\n",
            "            #    , 'ids': [treemap_ids]\n",
            "            #    , 'parents': [treemap_parents]\n",
            "            #    , 'labels': [treemap_labels]\n",
            "            #    , 'values': [treemap_values]\n",
            "            #    , 'hovertemplate': \n",
            "    }          \n",
            "            #   ,\n",
            "            #                         {\n",
            "            #                             'xaxis': [None, {'visible': True}]\n",
            "            #                         , 'yaxis': [None, {'visible': True}]}                                   \n",
            "              ]},  \n",
            "    # {'label': 'Sum', \n",
            "    #  'method': 'restyle', \n",
            "    #  'args': [{\n",
            "    #              'x': [x_heatmap_sum, x_bar_sum]\n",
            "    #            , 'y': [y_heatmap_sum, y_bar_sum]\n",
            "    #            , 'z': [z_heatmap_sum]\n",
            "    #            , 'hovertemplate': ['heatmap=%{z:.0f}<extra></extra>'\n",
            "    #                                , 'x=%{x}<br>y=%{y}<extra></extra>']\n",
            "    # }]},      \n",
            "]    \n",
            "buttons.append(dict(label='Ver', method='restyle', args=[{'orientation': 'v'}]))\n",
            "buttons.append(dict(label='Hor', method='restyle', args=[{'orientation': 'h'}]))\n",
            "\n",
            "# Update layout with button\n",
            "fig.update_layout(\n",
            "    updatemenus=[\n",
            "        {'type': \"buttons\", 'buttons': buttons, 'direction': 'down', 'showactive': True, 'x': 0.5, 'y': 1.2}\n",
            "    ],\n",
            ")\n",
            "fig.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "def heatmap(df, title='', xtick_text=None, ytick_text=None, xaxis_label=None, yaxis_label=None, width=None, height=None, decimal_places=2, font_size=14):\n",
            "    \"\"\"\n",
            "    Creates a heatmap from a Pandas DataFrame using Plotly.\n",
            "\n",
            "    Parameters:\n",
            "    - `df`: The Pandas DataFrame to create the heatmap from.\n",
            "    - `title`: The title of the heatmap (default is an empty string).\n",
            "    - `xtick_text`: The custom tick labels for the x-axis (default is None).\n",
            "    - `ytick_text`: The custom tick labels for the y-axis (default is None).\n",
            "    - `xaxis_label`: The label for the x-axis (default is None).\n",
            "    - `yaxis_label`: The label for the y-axis (default is None).\n",
            "    - `width`: The width of the heatmap (default is None).\n",
            "    - `height`: The height of the heatmap (default is None).\n",
            "    - `decimal_places`: The number of decimal places to display in the annotations (default is 2).\n",
            "    - `font_size`: The font size for the text in the annotations (default is 14).\n",
            "\n",
            "    Returns:\n",
            "    - A Plotly figure object representing the heatmap.\n",
            "\n",
            "    Notes:\n",
            "    - If `xtick_text` or `ytick_text` is provided, it must have the same length as the number of columns or rows in the DataFrame, respectively.\n",
            "    - The heatmap is created with a custom colorscale and hover labels.\n",
            "    - The function returns a Plotly figure object, which can be displayed using `fig.show()`.\n",
            "    \"\"\"\n",
            "    # Create figure\n",
            "    fig = go.Figure(data=go.Heatmap(\n",
            "        z=df.values,\n",
            "        x=df.columns,\n",
            "        y=df.index,\n",
            "        xgap=3,\n",
            "        ygap=3,\n",
            "        colorscale=[[0, 'rgba(204, 153, 255, 0.1)'], [1, 'rgb(127, 60, 141)']],\n",
            "        hoverongaps=False,\n",
            "        hoverinfo=\"x+y+z\",\n",
            "        hoverlabel=dict(\n",
            "            bgcolor=\"white\",\n",
            "            # Increase font size to font_size\n",
            "            font=dict(color=\"black\", size=font_size)\n",
            "        )\n",
            "    ))\n",
            "\n",
            "    # Create annotations\n",
            "    center_color_bar = (df.max().max() + df.min().min()) * 0.7\n",
            "    annotations = [\n",
            "        dict(\n",
            "            text=f\"{df.values[row, col]:.{decimal_places}f}\",\n",
            "            x=col,\n",
            "            y=row,\n",
            "            showarrow=False,\n",
            "            font=dict(\n",
            "                color=\"black\" if df.values[row, col] <\n",
            "                    center_color_bar else \"white\",\n",
            "                size=font_size\n",
            "            )\n",
            "        )\n",
            "        for row, col in np.ndindex(df.values.shape)\n",
            "    ]\n",
            "\n",
            "    # Update layout\n",
            "    fig.update_layout(\n",
            "        title=title,\n",
            "        annotations=annotations,\n",
            "        xaxis=dict(showgrid=False),\n",
            "        yaxis=dict(showgrid=False)\n",
            "    )\n",
            "\n",
            "    # Update axis labels if custom labels are provided\n",
            "    if xtick_text is not None:\n",
            "        if len(xtick_text) != len(df.columns):\n",
            "            raise ValueError(\n",
            "                \"xtick_text must have the same length as the number of columns in the DataFrame\")\n",
            "        fig.update_layout(xaxis=dict(tickvals=range(\n",
            "            len(xtick_text)), ticktext=xtick_text))\n",
            "\n",
            "    if ytick_text is not None:\n",
            "        if len(ytick_text) != len(df.index):\n",
            "            raise ValueError(\n",
            "                \"ytick_text must have the same length as the number of rows in the DataFrame\")\n",
            "        fig.update_layout(yaxis=dict(tickvals=range(\n",
            "            len(ytick_text)), ticktext=ytick_text))\n",
            "\n",
            "    # Update axis labels if custom labels are provided\n",
            "    if xaxis_label is not None:\n",
            "        fig.update_layout(xaxis=dict(title=xaxis_label))\n",
            "\n",
            "    if yaxis_label is not None:\n",
            "        fig.update_layout(yaxis=dict(title=yaxis_label))\n",
            "\n",
            "    # Update figure size if custom size is provided\n",
            "    if width is not None:\n",
            "        fig.update_layout(width=width)\n",
            "    if height is not None:\n",
            "        fig.update_layout(height=height)\n",
            "\n",
            "    return fig"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "def treemap(df, columns, values=None):\n",
            "    \"\"\"\n",
            "    Creates an interactive treemap using Plotly.\n",
            "\n",
            "    Parameters:\n",
            "    df (pandas.DataFrame): dataframe with data for the treemap.\n",
            "    columns (list): list of columns to use for the treemap.\n",
            "    values (str): column for values\n",
            "    Returns:\n",
            "    fig (plotly.graph_objs.Figure): interactive treemap figure.\n",
            "    \"\"\"\n",
            "    fig = px.treemap(df, path=[px.Constant('All')] + columns\n",
            "                     , values = values\n",
            "                     , color_discrete_sequence=[\n",
            "                         'rgba(148, 100, 170, 1)',\n",
            "                         'rgba(50, 156, 179, 1)',\n",
            "                         'rgba(99, 113, 156, 1)',\n",
            "                         'rgba(92, 107, 192, 1)',\n",
            "                         'rgba(0, 90, 91, 1)',\n",
            "                         'rgba(3, 169, 244, 1)',\n",
            "                         'rgba(217, 119, 136, 1)',\n",
            "                         'rgba(64, 134, 87, 1)',\n",
            "                         'rgba(134, 96, 147, 1)',\n",
            "                         'rgba(132, 169, 233, 1)'\n",
            "                     ]\n",
            "                     , labels={'values': 'Mean Value'})\n",
            "    fig.update_traces(root_color=\"silver\", hovertemplate=\"<b>%{label}<br>%{value}</b>\")\n",
            "    fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
            "    fig.update_traces(hoverlabel=dict(bgcolor=\"white\"))\n",
            "    return fig"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "def sankey(df, columns, values_column=None, func='sum', mode='fig'):\n",
            "    \"\"\"\n",
            "    Создает Sankey-диаграмму\n",
            "\n",
            "    Parameters:\n",
            "    df (pandas.DataFrame): входной DataFrame\n",
            "    columns (list): список столбцов для Sankey-диаграммы\n",
            "\n",
            "    Returns:\n",
            "    fig (plotly.graph_objects.Figure): Sankey-диаграмма\n",
            "    \"\"\"\n",
            "    def prepare_data(df, columns, values_column, func):\n",
            "        \"\"\"\n",
            "        Подготавливает данные для Sankey-диаграммы.\n",
            "\n",
            "        Parameters:\n",
            "        df (pandas.DataFrame): входной DataFrame\n",
            "        columns (list): список столбцов для Sankey-диаграммы\n",
            "\n",
            "        Returns:\n",
            "        sankey_df (pandas.DataFrame): подготовленный DataFrame для Sankey-диаграммы\n",
            "        \"\"\"\n",
            "        df_in = df.fillna(value={values_column: 0}).copy()\n",
            "        columns_len = len(columns)\n",
            "        temp_df = pd.DataFrame()\n",
            "        if func == 'mode':\n",
            "            func = lambda x: x.mode().iloc[0] \n",
            "        if func == 'range':\n",
            "            func = lambda x: x.max() - x.min()\n",
            "        for i in range(columns_len - 1):\n",
            "            current_columns = columns[i:i+2]\n",
            "            if values_column:\n",
            "                df_grouped = df_in[current_columns+[values_column]].groupby(current_columns)[[values_column]].agg(value = (values_column, func)).reset_index()\n",
            "            else:\n",
            "                df_grouped = df_in[current_columns].groupby(current_columns).size().reset_index().rename(columns={0: 'value'})\n",
            "            temp_df = pd.concat([temp_df, df_grouped\n",
            "                                        .rename(columns={columns[i]: 'source_name', columns[i+1]: 'target_name'})], axis=0)\n",
            "        sankey_df = temp_df.reset_index(drop=True)\n",
            "        return sankey_df\n",
            "\n",
            "    def create_sankey_nodes(sankey_df):\n",
            "        \"\"\"\n",
            "        Создает узлы для Sankey-диаграммы.\n",
            "\n",
            "        Parameters:\n",
            "        sankey_df (pandas.DataFrame): подготовленный DataFrame для Sankey-диаграммы\n",
            "        colors (list): список цветов для узлов\n",
            "\n",
            "        Returns:\n",
            "        nodes_with_indexes (dict): словарь узлов с индексами\n",
            "        node_colors (list): список цветов узлов\n",
            "        \"\"\"\n",
            "        nodes = pd.concat([sankey_df['source_name'], sankey_df['target_name']], axis=0).unique().tolist()\n",
            "        nodes_with_indexes = {key: [val] for val, key in enumerate(nodes)}\n",
            "        colors = [\n",
            "            'rgba(148, 100, 170, 1)',\n",
            "            'rgba(50, 156, 179, 1)',\n",
            "            'rgba(99, 113, 156, 1)',\n",
            "            'rgba(92, 107, 192, 1)',\n",
            "            'rgba(0, 90, 91, 1)',\n",
            "            'rgba(3, 169, 244, 1)',\n",
            "            'rgba(217, 119, 136, 1)',\n",
            "            'rgba(64, 134, 87, 1)',\n",
            "            'rgba(134, 96, 147, 1)',\n",
            "                'rgba(132, 169, 233, 1)']\n",
            "        node_colors = []\n",
            "        colors = itertools.cycle(colors)\n",
            "        for node in nodes_with_indexes.keys():\n",
            "            color = next(colors)\n",
            "            nodes_with_indexes[node].append(color)\n",
            "            node_colors.append(color)\n",
            "        return nodes_with_indexes, node_colors\n",
            "\n",
            "    def create_sankey_links(sankey_df, nodes_with_indexes):\n",
            "        \"\"\"\n",
            "        Создает связи для Sankey-диаграммы.\n",
            "\n",
            "        Parameters:\n",
            "        sankey_df (pandas.DataFrame): подготовленный DataFrame для Sankey-диаграммы\n",
            "        nodes_with_indexes (dict): словарь узлов с индексами\n",
            "\n",
            "        Returns:\n",
            "        link_color (list): список цветов связей\n",
            "        \"\"\"\n",
            "        link_color = [nodes_with_indexes[source][1].replace(', 1)', ', 0.2)') for source in sankey_df['source_name']]\n",
            "        return link_color\n",
            "    sankey_df = prepare_data(df, columns, values_column, func)\n",
            "    nodes_with_indexes, node_colors = create_sankey_nodes(sankey_df)\n",
            "    link_color = create_sankey_links(sankey_df, nodes_with_indexes)\n",
            "    sankey_df['source'] = sankey_df['source_name'].apply(lambda x: nodes_with_indexes[x][0])\n",
            "    sankey_df['target'] = sankey_df['target_name'].apply(lambda x: nodes_with_indexes[x][0])\n",
            "    sankey_df['sum_value'] = sankey_df.groupby('source_name')['value'].transform('sum')\n",
            "    sankey_df['value_percent'] = round(sankey_df['value'] * 100 / sankey_df['sum_value'], 2)\n",
            "    sankey_df['value_percent'] = sankey_df['value_percent'].apply(lambda x: f\"{x}%\")\n",
            "    if mode == 'fig':\n",
            "        fig = go.Figure(data=[go.Sankey(\n",
            "            domain = dict(\n",
            "            x =  [0,1],\n",
            "            y =  [0,1]\n",
            "            ),\n",
            "            orientation = \"h\",\n",
            "            valueformat = \".0f\",\n",
            "            node = dict(\n",
            "            pad = 10,\n",
            "            thickness = 15,\n",
            "            line = dict(color = \"black\", width = 0.1),\n",
            "            label =  list(nodes_with_indexes.keys()),\n",
            "            color = node_colors\n",
            "            ),\n",
            "            link = dict(\n",
            "            source = sankey_df['source'],\n",
            "            target = sankey_df['target'],\n",
            "            value  = sankey_df['value'],\n",
            "            label = sankey_df['value_percent'],\n",
            "            color = link_color\n",
            "        )\n",
            "        )])\n",
            "\n",
            "        layout = dict(\n",
            "                title = f\"Sankey Diagram for {', '.join(columns+[values_column])}\" if values_column else\n",
            "                f\"Sankey Diagram for {', '.join(columns)}\",\n",
            "                height = 772,\n",
            "                font = dict(\n",
            "                size = 10),)\n",
            "\n",
            "        fig.update_layout(layout)  \n",
            "        return fig\n",
            "    if mode == 'data':\n",
            "        sankey_dict = {}\n",
            "        sankey_dict['sankey_df'] = sankey_df\n",
            "        sankey_dict['nodes_with_indexes'] = nodes_with_indexes\n",
            "        sankey_dict['node_colors'] = node_colors\n",
            "        sankey_dict['link_color'] = link_color\n",
            "        return sankey_dict\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import plotly.graph_objects as go\n",
            "import pandas as pd\n",
            "colorway_for_bar = ['rgba(128, 60, 170, 0.9)', '#049CB3', '#84a9e9', '#B690C4',\n",
            "                    '#5c6bc0', '#005A5B', '#63719C', '#03A9F4', '#66CCCC', '#a771f2'\n",
            "                    , 'rgba(128, 60, 170, 0.9)', '#049CB3', '#84a9e9', '#B690C4',\n",
            "                    '#5c6bc0', '#005A5B', '#63719C', '#03A9F4', '#66CCCC', '#a771f2'\n",
            "                    , 'rgba(128, 60, 170, 0.9)', '#049CB3', '#84a9e9', '#B690C4',\n",
            "                    '#5c6bc0', '#005A5B', '#63719C', '#03A9F4', '#66CCCC', '#a771f2'\n",
            "                    , 'rgba(128, 60, 170, 0.9)', '#049CB3', '#84a9e9', '#B690C4',\n",
            "                    '#5c6bc0', '#005A5B', '#63719C', '#03A9F4', '#66CCCC', '#a771f2']\n",
            "def prepare_df(config):\n",
            "    df = config['df']\n",
            "    cat_column_color = [config['cat_column_color']] if config['cat_column_color'] else []\n",
            "    cat_columns = [config['cat_column_x']] + cat_column_color  \n",
            "    num_column = config['num_column_y']\n",
            "    # print(config)\n",
            "    # print(cat_columns)\n",
            "    # print(num_column)\n",
            "    func = config.get('func', 'sum')  # default to 'sum' if not provided\n",
            "    if func == 'mode':\n",
            "        func = lambda x: x.mode().iloc[0] \n",
            "        func_for_modes = lambda x: tuple(x.mode().to_list())\n",
            "    else:\n",
            "        func_for_modes = lambda x: ''\n",
            "    if func == 'range':\n",
            "        func = lambda x: x.max() - x.min()\n",
            "    func_df = (df[[*cat_columns, num_column]]\n",
            "        .groupby(cat_columns) \n",
            "        .agg(num = (num_column, func), modes = (num_column, func_for_modes)) \n",
            "        .sort_values('num', ascending=False)\n",
            "        .rename(columns={'num': num_column})\n",
            "    )\n",
            "    if config['cat_column_color']:\n",
            "        func_df = func_df.unstack(level=1)        \n",
            "        func_df['sum'] = func_df.sum(axis=1, numeric_only=True)\n",
            "        func_df = func_df.sort_values('sum', ascending=False).drop('sum', axis=1)\n",
            "        func_df = pd.concat([func_df[num_column], func_df['modes']], keys=['num', 'modes'])\n",
            "        func_df = func_df.sort_values(func_df.index[0], axis=1, ascending=False)\n",
            "        return func_df\n",
            "    else:\n",
            "        return func_df\n",
            "def prepare_data_treemap(df, cat_columns, value_column, func='sum'):\n",
            "    df_in = df[cat_columns + [value_column]].copy()\n",
            "    prefix = 'All/'\n",
            "    if func == 'mode':\n",
            "        func = lambda x: x.mode().iloc[0] \n",
            "    if func == 'range':\n",
            "        func = lambda x: x.max() - x.min()    \n",
            "    df_grouped_second_level = df_in[[*cat_columns, value_column]].groupby(cat_columns).agg({value_column: func}).reset_index()\n",
            "    df_grouped_second_level['ids'] = df_grouped_second_level[cat_columns].apply(lambda x: f'{prefix}{x[cat_columns[0]]}/{x[cat_columns[1]]}', axis=1)\n",
            "    df_grouped_second_level['parents'] = df_grouped_second_level[cat_columns].apply(lambda x: f'{prefix}{x[cat_columns[0]]}', axis=1)\n",
            "    df_grouped_second_level = df_grouped_second_level.sort_values(cat_columns[::-1], ascending=False)\n",
            "    # df_grouped = df_grouped.drop(cat_columns[0], axis=1)\n",
            "    df_grouped_first_level = df_grouped_second_level.groupby(cat_columns[0]).sum().reset_index()\n",
            "    df_grouped_first_level['ids'] = df_grouped_first_level[cat_columns[0]].apply(lambda x: f'{prefix}{x}')\n",
            "    df_grouped_first_level['parents'] = 'All'\n",
            "    df_grouped_first_level = df_grouped_first_level.sort_values(cat_columns[0], ascending=False)\n",
            "    all_value = df_grouped_first_level[value_column].sum()\n",
            "    res_df = pd.concat([df_grouped_second_level.rename(columns={cat_columns[1]: 'labels', value_column: 'values'}).drop(cat_columns[0], axis=1)\n",
            "                        , df_grouped_first_level.rename(columns={cat_columns[0]: 'labels', value_column: 'values'})\n",
            "                        , pd.DataFrame({'parents': '', 'labels': 'All',  'values': all_value, 'ids': 'All'}, index=[0])]\n",
            "                        , axis=0)\n",
            "    return res_df\n",
            "def create_figure(config):\n",
            "    fig = go.Figure()\n",
            "    # 1\n",
            "    config['cat_column_x'] = config['cat_columns'][0]\n",
            "    config['cat_column_color'] = ''    \n",
            "    df_for_fig = prepare_df(config)\n",
            "    x = df_for_fig.index.tolist()\n",
            "    y = df_for_fig[config['num_column_y']].values.tolist()\n",
            "    bar_traces = px.bar(x=x\n",
            "       , y=y\n",
            "       ).data\n",
            "    line_traces = px.line(x=x\n",
            "       , y=y\n",
            "       , markers=True\n",
            "       ).data\n",
            "    area_traces = px.area(x=x\n",
            "       , y=y\n",
            "       , markers=True\n",
            "       ).data    \n",
            "    fig.add_traces(bar_traces + line_traces + area_traces)\n",
            "    # 2\n",
            "    config['cat_column_x'] = config['cat_columns'][1]\n",
            "    config['cat_column_color'] = ''    \n",
            "    df_for_fig = prepare_df(config)\n",
            "    x = df_for_fig.index.tolist()\n",
            "    y = df_for_fig[config['num_column_y']].values.tolist()\n",
            "    bar_traces = px.bar(x=x\n",
            "       , y=y\n",
            "       ).data\n",
            "    line_traces = px.line(x=x\n",
            "       , y=y\n",
            "       , markers=True\n",
            "       ).data\n",
            "    area_traces = px.area(x=x\n",
            "       , y=y\n",
            "       , markers=True\n",
            "       ).data    \n",
            "    fig.add_traces(bar_traces + line_traces + area_traces)\n",
            "    # 12\n",
            "    config['cat_column_x'] = config['cat_columns'][0]\n",
            "    config['cat_column_color'] = config['cat_columns'][1]\n",
            "    df_for_fig = prepare_df(config).loc['num', :].stack().reset_index(name=config['num_column_y'])\n",
            "    x = df_for_fig[config['cat_column_x']].values.tolist()\n",
            "    y = df_for_fig[config['num_column_y']].values.tolist()\n",
            "    color = df_for_fig[config['cat_column_color']].values if config['cat_column_color'] else None    \n",
            "    bar_traces = px.bar(x=x\n",
            "       , y=y\n",
            "       , color=color\n",
            "       , barmode='group'\n",
            "       ).data\n",
            "    config['traces_cnt12'] = len(bar_traces)\n",
            "    line_traces = px.line(x=x\n",
            "       , y=y\n",
            "       , color=color\n",
            "       , markers=True\n",
            "       ).data\n",
            "    area_traces = px.area(x=x\n",
            "       , y=y\n",
            "       , color=color\n",
            "       , markers=True\n",
            "       ).data    \n",
            "    fig.add_traces(bar_traces + line_traces + area_traces)\n",
            "\n",
            "    # 21\n",
            "    config['cat_column_x'] = config['cat_columns'][1]\n",
            "    config['cat_column_color'] = config['cat_columns'][0]\n",
            "    df_for_fig = prepare_df(config).loc['num', :].stack().reset_index(name=config['num_column_y'])\n",
            "    x = df_for_fig[config['cat_column_x']].values.tolist()\n",
            "    y = df_for_fig[config['num_column_y']].values.tolist()\n",
            "    color = df_for_fig[config['cat_column_color']].values if config['cat_column_color'] else None    \n",
            "    bar_traces = px.bar(x=x\n",
            "       , y=y\n",
            "       , color=color\n",
            "       , barmode='group'\n",
            "       ).data\n",
            "    config['traces_cnt21'] = len(bar_traces)\n",
            "    line_traces = px.line(x=x\n",
            "       , y=y\n",
            "       , color=color\n",
            "       , markers=True\n",
            "       ).data\n",
            "    area_traces = px.area(x=x\n",
            "       , y=y\n",
            "       , color=color\n",
            "       , markers=True\n",
            "       ).data    \n",
            "    fig.add_traces(bar_traces + line_traces + area_traces)\n",
            "   \n",
            "    # # heatmap\n",
            "    pivot_for_heatmap = config['df'].pivot_table(index=config['cat_columns'][0], columns=config['cat_columns'][1], values=config['num_column_y'])\n",
            "    heatmap_trace = px.imshow(pivot_for_heatmap, text_auto=\".0f\").data[0]\n",
            "    heatmap_trace.xgap=3\n",
            "    heatmap_trace.ygap=3\n",
            "    fig.add_trace(heatmap_trace)\n",
            "    fig.update_layout(coloraxis=dict(colorscale=[(0, 'rgba(204, 153, 255, 0.1)'), (1, 'rgb(127, 60, 141)')])\n",
            "                                            , hoverlabel=dict(bgcolor='white'))\n",
            "    # treemap\n",
            "    treemap_trace = columns = treemap(config['df'], config['cat_columns'], config['num_column_y']).data[0]\n",
            "    fig.add_trace(treemap_trace)\n",
            "    \n",
            "    # sankey\n",
            "    sankey_trace =  sankey(config['df'], config['cat_columns'], config['num_column_y'], func='sum').data[0]\n",
            "    fig.add_trace(sankey_trace)\n",
            "    \n",
            "    for i, trace in enumerate(fig.data):\n",
            "        # при старте показываем только первый trace\n",
            "        if i:\n",
            "            trace.visible = False\n",
            "        if trace.type == 'scatter':\n",
            "            trace.line.width = 2\n",
            "            # trace.marker.size = 7      \n",
            "    return fig\n",
            "\n",
            "def create_buttons(config):\n",
            "    buttons = []\n",
            "    buttons.append(dict(label='Ver', method='update', args=[{'orientation': 'v'}]))\n",
            "    buttons.append(dict(label='Hor', method='update', args=[{'orientation': 'h'}]))\n",
            "    buttons.append(dict(label='stack', method='relayout', args=[{'barmode': 'stack'}]))\n",
            "    buttons.append(dict(label='group', method='relayout', args=[{'barmode': 'group'}]))\n",
            "    # buttons.append(dict(label='overlay', method='relayout', args=[{'barmode': 'overlay'}]))\n",
            "            \n",
            "#    add range, distinct count\n",
            "    for i, func in enumerate(['sum', 'mean', 'median', 'count', 'nunique', 'mode', 'std', 'min', 'max', 'range']):\n",
            "        config['func'] = func\n",
            "        if func == 'mode':\n",
            "            # 12\n",
            "            config['cat_column_x'] = config['cat_columns'][0]\n",
            "            config['cat_column_color'] = config['cat_columns'][1]\n",
            "            df_for_update = prepare_df(config)\n",
            "            df_num12 = df_for_update.loc['num', :]\n",
            "            x_12 = df_num12.index.tolist()\n",
            "            y_12 = df_num12.values.T.tolist()\n",
            "            name_12 = df_num12.columns.tolist()\n",
            "            modes_array12 = df_for_update.loc['modes', :].fillna('').values.T\n",
            "            text_12 = [[', '.join(map(str, col)) if col else '' for col in row] for row in modes_array12]\n",
            "            colors = [['orange' if len(col) > 1 else colorway_for_bar[i] for col in row] for i, row in enumerate(modes_array12)]\n",
            "            colors12 = [{'color': col_list} for col_list in colors]\n",
            "            # 21\n",
            "            config['cat_column_x'] = config['cat_columns'][1]\n",
            "            config['cat_column_color'] = config['cat_columns'][0]\n",
            "            df_for_update = prepare_df(config)\n",
            "            df_num21 = df_for_update.loc['num', :]\n",
            "            x_21 = df_num21.index.tolist()\n",
            "            y_21 = df_num21.values.T.tolist()\n",
            "            name_21 = df_num21.columns.tolist()\n",
            "            modes_array21 = df_for_update.loc['modes', :].fillna('').values.T\n",
            "            text_21 = [[', '.join(map(str, col)) if col else '' for col in row] for row in modes_array21]\n",
            "            colors = [['orange' if len(col) > 1 else colorway_for_bar[i] for col in row] for i, row in enumerate(modes_array21)]\n",
            "            colors21 = [{'color': col_list} for col_list in colors]            \n",
            "            # 1\n",
            "            config['cat_column_x'] = config['cat_columns'][0]\n",
            "            config['cat_column_color'] = ''    \n",
            "            df_for_update = prepare_df(config)\n",
            "            x_1 = df_for_update.index.tolist()\n",
            "            y_1 = df_for_update[config['num_column_y']].values.tolist()\n",
            "            modes_array1 = df_for_update['modes'].to_list()\n",
            "            text_1 = [[', '.join(map(str,x)) for x in modes_array1]]\n",
            "            colors_1 =[{'color': ['orange' if len(x) > 1 else colorway_for_bar[0] for x in modes_array1]}]\n",
            "\n",
            "            # 2\n",
            "            config['cat_column_x'] = config['cat_columns'][1]\n",
            "            config['cat_column_color'] = ''    \n",
            "            df_for_update = prepare_df(config)\n",
            "            x_2 = df_for_update.index.tolist()\n",
            "            y_2 = df_for_update[config['num_column_y']].values.tolist()  \n",
            "            modes_array2 = df_for_update['modes'].to_list()\n",
            "            text_2 = [[', '.join(map(str,x)) for x in modes_array2]]\n",
            "            colors_2 = [{'color': ['orange' if len(x) > 1 else colorway_for_bar[0] for x in modes_array2]}]   \n",
            "            # heatmap\n",
            "            func_for_heatmap = lambda x: x.mode().iloc[0]          \n",
            "            pivot_for_heatmap = config['df'].pivot_table(index=config['cat_columns'][0], columns=config['cat_columns'][1], values=config['num_column_y'], aggfunc=func_for_heatmap)            \n",
            "            x_heatmap = pivot_for_heatmap.index.tolist()\n",
            "            y_heatmap = pivot_for_heatmap.columns.tolist()\n",
            "            z_heatmap = pivot_for_heatmap.values\n",
            "            # Так как heatmap постоянно меняет ориентацию и 'orientation': 'v' не помогает,  \n",
            "            # то приходится использовать костыль, чтобы при последовательном проходе по функциям транспонирование  \n",
            "            # подстраивало данные для Heatmap            \n",
            "            if i % 2 == 0:\n",
            "                z_heatmap = z_heatmap.T    \n",
            "            # treemap\n",
            "            treemap_ids = []\n",
            "            treemap_parents = []\n",
            "            treemap_labels = []\n",
            "            treemap_values = []\n",
            "\n",
            "            # sankey\n",
            "            sankey_df = []\n",
            "            nodes_with_indexes = {}\n",
            "            node_colors = []\n",
            "            link_color = []    \n",
            "            link = []    \n",
            "            buttons.append(dict(label=f'{func.capitalize()}'\n",
            "                                , method='update'\n",
            "                                , args2=[{'orientation': 'h'}, {'title': f\"{func} &nbsp;&nbsp;&nbsp;&nbsp;num = {config['num_column_y']}&nbsp;&nbsp;&nbsp;&nbsp; cat1 = {config['cat_columns'][0]}&nbsp;&nbsp;&nbsp;&nbsp; cat2 = {config['cat_columns'][1]}\"}]\n",
            "                                , args=[{\n",
            "                                    'orientation': ['v'] * 3 + ['v'] * 3\n",
            "                                            + ['v'] * config['traces_cnt12'] * 3\n",
            "                                            + ['v'] * config['traces_cnt21'] * 3\n",
            "                                            + ['v'] + ['v'] + ['h']\n",
            "                                    # для каждго trace должент быть свой x, поэтому x умножаем на количество trace\n",
            "                                    , 'x': [x_1] * 3 + [x_2] * 3\n",
            "                                            + [x_12] * config['traces_cnt12'] * 3\n",
            "                                            + [x_21] * config['traces_cnt21'] * 3\n",
            "                                            + [x_heatmap] + [] + []\n",
            "                                    # для y1 и y2 нужно обренуть в список\n",
            "                                    , 'y': [y_1] * 3 + [y_2] * 3 + y_12 * 3 +  y_21 * 3  + [y_heatmap] + [] + []\n",
            "                                    # , 'z': [z_heatmap]\n",
            "                                    # , 'orientation': 'v'\n",
            "                                    , 'z': [] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [z_heatmap] + [] + []\n",
            "                                    # treemap\n",
            "                                    , 'ids': [] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [] + [treemap_ids] + []\n",
            "                                    , 'labels': [] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [] + [treemap_labels] + []\n",
            "                                    , 'parents': [] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [] + [treemap_parents] + []\n",
            "                                    , 'values': [] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [] + [treemap_values] + [] \n",
            "                                    # sankey\n",
            "                                    , 'label': [] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [] + [] + [list(nodes_with_indexes.keys())]\n",
            "                                    , 'color':[] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [] + [] + [node_colors]\n",
            "                                    , 'link': [] * 3 + [] * 3 + [] * config['traces_cnt12'] * 3 +  [] * config['traces_cnt21'] * 3  + [] + [] \n",
            "                                                + [link ]    \n",
            "                                    # для 1 и 2 нет цветов, поэтому названия делаем пустыми\n",
            "                                    , 'name': [''] * 3 + [''] * 3 + name_12 * 3 +  name_21 * 3 + ['']\n",
            "                                    , 'hovertemplate': 'color=%{data.name}<br>x=%{x}<br>y=%{y}<br>modes=%{text}<br>heatmap=%{z:.0f}<br>treemap=%{value:.0f}<extra></extra>'\n",
            "                                    , 'hovertemplate': ['x=%{x}<br>y=%{y}<br>modes=%{text}'] * 6\n",
            "                                                        + ['x=%{x}<br>y=%{y}<br>color=%{data.name}<br>modes=%{text}'] * (config['traces_cnt12'] + config['traces_cnt21']) * 3\n",
            "                                                        + ['x=%{x}<br>y=%{y}<br>z=%{z:.0f}']\n",
            "                                                        + ['%{label}<br>%{value}'] + [[]]                                    \n",
            "                                    , 'text': text_1 * 3 + text_2 * 3 + text_12 * 3 + text_21 * 3 + [[]] + [[]] + [[]]\n",
            "                                    , 'marker': colors_1 * 3 + colors_2 * 3 + colors12 * 3 + colors21 * 3 + [[]] + [[]] + [[]]\n",
            "                                    , 'textposition': 'none'\n",
            "                                    , 'textfont': {'color': 'black'}\n",
            "                                }, {'title': f\"num = {config['num_column_y']}&nbsp;&nbsp;&nbsp;&nbsp; cat1 = {config['cat_columns'][0]}&nbsp;&nbsp;&nbsp;&nbsp; cat2 = {config['cat_columns'][1]}\"}\n",
            "                                    # {'xaxis': {'visible': [True, True, True] + [True] * 3\n",
            "                                    #                          + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt12'] + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] * config['traces_cnt21'] + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] + [False]}\n",
            "                                    # , 'yaxis': {'visible': [True, True, True] + [True] * 3\n",
            "                                    #                          + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt12'] + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] * config['traces_cnt21'] + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] + [False]}}                                     \n",
            "                                        ]))\n",
            "        else:\n",
            "            # 12 \n",
            "            config['cat_column_x'] = config['cat_columns'][0]\n",
            "            config['cat_column_color'] = config['cat_columns'][1]\n",
            "            df_for_update = prepare_df(config)\n",
            "            df_num12 = df_for_update.loc['num', :]\n",
            "            # if func == 'sum':\n",
            "            #     display(df_for_update)\n",
            "            x_12 = df_num12.index.tolist()\n",
            "            y_12 = df_num12.values.T.tolist()\n",
            "            name_12 = df_num12.columns.tolist()\n",
            "            modes_array12 = df_for_update.loc['modes', :].fillna('').values.T\n",
            "            text_12 = [['' for col in row] for row in modes_array12]\n",
            "            colors = [[colorway_for_bar[i] for col in row] for i, row in enumerate(modes_array12)]\n",
            "            colors12 = [{'color': col_list} for col_list in colors]\n",
            "            # 21\n",
            "            config['cat_column_x'] = config['cat_columns'][1]\n",
            "            config['cat_column_color'] = config['cat_columns'][0]\n",
            "            df_for_update = prepare_df(config)\n",
            "            df_num21 = df_for_update.loc['num', :]\n",
            "            x_21 = df_num21.index.tolist()\n",
            "            y_21 = df_num21.values.T.tolist()\n",
            "            name_21 = df_num21.columns.tolist()\n",
            "            modes_array21 = df_for_update.loc['modes', :].fillna('').values.T\n",
            "            text_21 = [[''for col in row] for row in modes_array21]\n",
            "            colors = [[colorway_for_bar[i] for col in row] for i, row in enumerate(modes_array21)]\n",
            "            colors21 = [{'color': col_list} for col_list in colors]            \n",
            "            # 1\n",
            "            config['cat_column_x'] = config['cat_columns'][0]\n",
            "            config['cat_column_color'] = ''    \n",
            "            df_for_update = prepare_df(config)\n",
            "            x_1 = df_for_update.index.tolist()\n",
            "            y_1 = df_for_update[config['num_column_y']].values.tolist()\n",
            "            modes_array1 = df_for_update['modes'].to_list()\n",
            "            text_1 = ['']\n",
            "            colors_1 =[{'color': [colorway_for_bar[0] for x in modes_array1]}]\n",
            "\n",
            "\n",
            "            # 2\n",
            "            config['cat_column_x'] = config['cat_columns'][1]\n",
            "            config['cat_column_color'] = ''    \n",
            "            df_for_update = prepare_df(config)\n",
            "            x_2 = df_for_update.index.tolist()\n",
            "            y_2 = df_for_update[config['num_column_y']].values.tolist()  \n",
            "            modes_array2 = df_for_update['modes'].to_list()\n",
            "            text_2 = ['']\n",
            "            colors_2 = [{'color': [colorway_for_bar[0] for x in modes_array2]}]              \n",
            "            # heatmap\n",
            "            if func == 'range':\n",
            "                func_for_heatmap = lambda x: x.max() - x.min()\n",
            "            else:\n",
            "                func_for_heatmap = func         \n",
            "            pivot_for_heatmap = config['df'].pivot_table(index=config['cat_columns'][0], columns=config['cat_columns'][1], values=config['num_column_y'], aggfunc=func_for_heatmap)            \n",
            "            x_heatmap = pivot_for_heatmap.index.tolist()\n",
            "            y_heatmap = pivot_for_heatmap.columns.tolist()\n",
            "            z_heatmap = pivot_for_heatmap.values\n",
            "            \n",
            "            # Так как heatmap постоянно меняет ориентацию и 'orientation': 'v' не помогает,  \n",
            "            # то приходится использовать костыль, чтобы при последовательном проходе по функциям транспонирование  \n",
            "            # подстраивало данные для Heatmap\n",
            "            if i % 2 == 0:\n",
            "                z_heatmap = z_heatmap.T            \n",
            "           \n",
            "            if func in ['sum', 'count', 'nunique']:\n",
            "                 # treemap\n",
            "                df_treemap = prepare_data_treemap(config['df'], config['cat_columns'], config['num_column_y'], func)\n",
            "                treemap_ids = df_treemap['ids'].to_numpy()\n",
            "                treemap_parents = df_treemap['parents'].to_numpy()\n",
            "                treemap_labels = df_treemap['labels'].to_numpy()\n",
            "                treemap_values = df_treemap['values'].to_numpy()\n",
            "                # \"args\": [{\"traces\": [bar_fig.data[0]]}, {\"layout\": fig.layout}],\n",
            "                # if func== 'sum':\n",
            "                #     display(x_heatmap)\n",
            "                #     display(y_heatmap)\n",
            "                #     display(z_heatmap)\n",
            "                # sankey\n",
            "                sankey_dict = sankey(config['df'], config['cat_columns'], config['num_column_y'], func, mode='data')\n",
            "                sankey_df = sankey_dict['sankey_df'] \n",
            "                nodes_with_indexes = sankey_dict['nodes_with_indexes'] \n",
            "                node_colors = sankey_dict['node_colors']\n",
            "                link_color = sankey_dict['link_color']\n",
            "                link = dict(\n",
            "                            source = sankey_df['source'],\n",
            "                            target = sankey_df['target'],\n",
            "                            value  = sankey_df['value'],\n",
            "                            label = sankey_df['value_percent'],\n",
            "                            color = link_color\n",
            "                        )         \n",
            "                sankey_labels = list(nodes_with_indexes.keys())   \n",
            "            else:\n",
            "                 # treemap\n",
            "                treemap_ids = None\n",
            "                treemap_parents = None\n",
            "                treemap_labels = None\n",
            "                treemap_values = None\n",
            "\n",
            "                # sankey\n",
            "                sankey_df = None\n",
            "                nodes_with_indexes = None\n",
            "                node_colors = None\n",
            "                link_color = None    \n",
            "                link = None        \n",
            "            \n",
            "            buttons.append(dict(label=f'{func.capitalize()}'\n",
            "                                , method='update'\n",
            "                                , args2=[{'orientation': 'h'}, {'title': f\"{func} &nbsp;&nbsp;&nbsp;&nbsp;num = {config['num_column_y']}&nbsp;&nbsp;&nbsp;&nbsp; cat1 = {config['cat_columns'][0]}&nbsp;&nbsp;&nbsp;&nbsp; cat2 = {config['cat_columns'][1]}\"}]\n",
            "                                , args=[{\n",
            "                                    'orientation': ['v'] * 3 + ['v'] * 3\n",
            "                                            + ['v'] * config['traces_cnt12'] * 3\n",
            "                                            + ['v'] * config['traces_cnt21'] * 3\n",
            "                                            + ['v'] + ['v'] + ['h']\n",
            "                                    # для каждго trace должент быть свой x, поэтому x умножаем на количество trace\n",
            "                                    , 'x': [x_1] * 3 + [x_2] * 3\n",
            "                                            + [x_12] * config['traces_cnt12'] * 3\n",
            "                                            + [x_21] * config['traces_cnt21'] * 3\n",
            "                                            + [x_heatmap] + [None] + [None]\n",
            "                                    # для y1 и y2 нужно обренуть в список\n",
            "                                    , 'y': [y_1] * 3 + [y_2] * 3 + y_12 * 3 +  y_21 * 3  + [y_heatmap] + [None] + [None]\n",
            "                                    # , 'z': [z_heatmap]\n",
            "                                    # , 'orientation': 'v'\n",
            "                                    , 'z': [None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [z_heatmap] + [None] + [None]\n",
            "                                    # treemap\n",
            "                                    , 'ids': [None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [None] + [treemap_ids] + [None]\n",
            "                                    , 'labels': [None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [None] + [treemap_labels] + [None]\n",
            "                                    , 'parents': [None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [None] + [treemap_parents] + [None]\n",
            "                                    , 'values': [None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [None] + [treemap_values] + [None] \n",
            "                                    # sankey\n",
            "                                    , 'label': [None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [None] + [None] + [sankey_labels]\n",
            "                                    , 'color':[None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [None] + [None] + [node_colors]\n",
            "                                    , 'link': [None] * 3 + [None] * 3 + [None] * config['traces_cnt12'] * 3 +  [None] * config['traces_cnt21'] * 3  + [None] + [None] \n",
            "                                                + [link]                \n",
            "                                    # , 'layout.annotations': annotations\n",
            "                                    # для 1 и 2 нет цветов, поэтому названия делаем пустыми\n",
            "                                    , 'name': [''] * 3 + [''] * 3 + name_12 * 3 +  name_21 * 3 + [''] + [''] + ['']\n",
            "                                    , 'hovertemplate': ['x=%{x}<br>y=%{y}'] * 6\n",
            "                                                        + ['x=%{x}<br>y=%{y}<br>color=%{data.name}'] * (config['traces_cnt12'] + config['traces_cnt21']) * 3\n",
            "                                                        + ['x=%{x}<br>y=%{y}<br>z=%{z:.0f}']\n",
            "                                                        + ['%{label}<br>%{value}'] + [None]\n",
            "                                        # '{config[\"cat_columns\"]}=%{data.name}<br>x=%{x}<br>y=%{y}<br>heatmap=%{z:.0f}<br>treemap=%{value:.0f}<extra></extra>'\n",
            "                                    , 'text': text_1 * 3 + text_2 * 3 + text_12 * 3 + text_21 * 3 + [None] + [None] + [None]\n",
            "                                    , 'marker': colors_1 * 3 + colors_2 * 3 + colors12 * 3 + colors21 * 3 + [None] + [None] + [None]\n",
            "                                    , 'textposition': 'none'\n",
            "                                    , 'textfont': {'color': 'black'}}\n",
            "                                    , {'title': f\"num = {config['num_column_y']}&nbsp;&nbsp;&nbsp;&nbsp; cat1 = {config['cat_columns'][0]}&nbsp;&nbsp;&nbsp;&nbsp; cat2 = {config['cat_columns'][1]}\"}\n",
            "                                    #    , 'annotations': [''] * 3 + [''] * 3 + [''] * config['traces_cnt12'] * 3 +  [''] * config['traces_cnt21'] * 3  + annotations + [''] + ['']}\n",
            "                                    # {'xaxis': {'visible': [True, True, True] + [True] * 3\n",
            "                                    #                          + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt12'] + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] * config['traces_cnt21'] + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] + [False]}\n",
            "                                    # , 'yaxis': {'visible': [True, True, True] + [True] * 3\n",
            "                                    #                          + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt12'] + [True] * config['traces_cnt12']\n",
            "                                    #                          + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] * config['traces_cnt21'] + [True] * config['traces_cnt21']\n",
            "                                    #                          + [True] + [False]}}   \n",
            "                                        ]))     \n",
            "    # For start state \n",
            "    config['func'] = 'sum'\n",
            "    # 12 \n",
            "    config['cat_column_x'] = config['cat_columns'][0]\n",
            "    config['cat_column_color'] = config['cat_columns'][1]\n",
            "    df_for_update = prepare_df(config)\n",
            "    df_num12 = df_for_update.loc['num', :]\n",
            "    # if func == 'sum':\n",
            "    #     display(df_for_update)\n",
            "    x_12 = df_num12.index.tolist()\n",
            "    y_12 = df_num12.values.T.tolist()\n",
            "    name_12 = df_num12.columns.tolist()\n",
            "    modes_array12 = df_for_update.loc['modes', :].fillna('').values.T\n",
            "    text_12 = [['' for col in row] for row in modes_array12]\n",
            "    colors = [[colorway_for_bar[i] for col in row] for i, row in enumerate(modes_array12)]\n",
            "    colors12 = [{'color': col_list} for col_list in colors]\n",
            "    # 21\n",
            "    config['cat_column_x'] = config['cat_columns'][1]\n",
            "    config['cat_column_color'] = config['cat_columns'][0]\n",
            "    df_for_update = prepare_df(config)\n",
            "    df_num21 = df_for_update.loc['num', :]\n",
            "    x_21 = df_num21.index.tolist()\n",
            "    y_21 = df_num21.values.T.tolist()\n",
            "    name_21 = df_num21.columns.tolist()\n",
            "    modes_array21 = df_for_update.loc['modes', :].fillna('').values.T\n",
            "    text_21 = [[''for col in row] for row in modes_array21]\n",
            "    colors = [[colorway_for_bar[i] for col in row] for i, row in enumerate(modes_array21)]\n",
            "    colors21 = [{'color': col_list} for col_list in colors]            \n",
            "    # 1\n",
            "    config['cat_column_x'] = config['cat_columns'][0]\n",
            "    config['cat_column_color'] = ''    \n",
            "    df_for_update = prepare_df(config)\n",
            "    x_1 = df_for_update.index.tolist()\n",
            "    y_1 = df_for_update[config['num_column_y']].values.tolist()\n",
            "    modes_array1 = df_for_update['modes'].to_list()\n",
            "    text_1 = ['']\n",
            "    colors_1 =[{'color': [colorway_for_bar[0] for x in modes_array1]}]\n",
            "\n",
            "\n",
            "    # 2\n",
            "    config['cat_column_x'] = config['cat_columns'][1]\n",
            "    config['cat_column_color'] = ''    \n",
            "    df_for_update = prepare_df(config)\n",
            "    x_2 = df_for_update.index.tolist()\n",
            "    y_2 = df_for_update[config['num_column_y']].values.tolist()  \n",
            "    modes_array2 = df_for_update['modes'].to_list()\n",
            "    text_2 = ['']\n",
            "    colors_2 = [{'color': [colorway_for_bar[0] for x in modes_array2]}]  \n",
            "    traces_visible = {'1b': [[False]], '1l': [[False]], '1a': [[False]], '2b': [[False]], '2l': [[False]], '2a': [[False]]\n",
            "          , '12b': [[False] * config['traces_cnt12']], '12l': [[False] * config['traces_cnt12']], '12a': [[False] * config['traces_cnt12']]\n",
            "          , '21b': [[False] * config['traces_cnt21']], '21l': [[False] * config['traces_cnt21']], '21a': [[False] * config['traces_cnt21']]\n",
            "          ,'heatmap': [[False]], 'treemap': [[False]], 'sankey': [[False]]}\n",
            "    traces_visible_df = pd.DataFrame(traces_visible)\n",
            "    traces_lables_bar = {'1b': '1', '2b': '2', '12b': '12', '21b': '21'}\n",
            "    traces_lables_line = {'1l': '1', '2l': '2', '12l': '12', '21l': '21'}\n",
            "    traces_lables_area = {'1a': '1', '2a': '2', '12a': '12', '21a': '21', 'heatmap': 'heatmap', 'treemap': 'treemap', 'sankey': 'sankey'}\n",
            "    traces_lables = {**traces_lables_bar, **traces_lables_line, **traces_lables_area}\n",
            "    for button_label in traces_lables:\n",
            "        traces_visible_df_copy = traces_visible_df.copy()\n",
            "        traces_visible_df_copy[button_label] = traces_visible_df_copy[button_label].apply(lambda x: [True for _ in x])\n",
            "        visible_mask = [val for l in traces_visible_df_copy.loc[0].values for val in l]\n",
            "        data = {'visible': visible_mask\n",
            "                                    , 'orientation': ['v'] * 3 + ['v'] * 3\n",
            "                                            + ['v'] * config['traces_cnt12'] * 3\n",
            "                                            + ['v'] * config['traces_cnt21'] * 3\n",
            "                                            + ['v'] + ['v'] + ['h']\n",
            "                                    # для каждго trace должент быть свой x, поэтому x умножаем на количество trace\n",
            "                                    , 'x': [x_1] * 3 + [x_2] * 3\n",
            "                                            + [x_12] * config['traces_cnt12'] * 3\n",
            "                                            + [x_21] * config['traces_cnt21'] * 3\n",
            "                                            + [x_heatmap] + [None] + [None]\n",
            "                                    # для y1 и y2 нужно обренуть в список\n",
            "                                    , 'y': [y_1] * 3 + [y_2] * 3 + y_12 * 3 +  y_21 * 3  + [y_heatmap] + [None] + [None]\n",
            "                                    , 'name': [''] * 3 + [''] * 3 + name_12 * 3 +  name_21 * 3 + [''] + [''] + ['']\n",
            "                }\n",
            "        layout = {'xaxis': {'visible': False}, 'yaxis': {'visible': False}} if button_label in ['treemap', 'sankey'] \\\n",
            "            else {'xaxis': {'visible': True}, 'yaxis': {'visible': True}}\n",
            "        layout = {**layout, 'height': 800} if button_label == 'sankey' \\\n",
            "            else {**layout, 'height': 600}\n",
            "        visible = True if button_label in list(traces_lables_bar.keys()) + ['heatmap', 'treemap', 'sankey'] else False\n",
            "        buttons.append(dict(label=traces_lables[button_label], method='update', args=[data, layout], visible=visible))\n",
            "    \n",
            "    buttons.append(dict(\n",
            "        label='Bar',\n",
            "        method='relayout',\n",
            "        args=[{**{f'updatemenus[2].buttons[{i}].visible': True for i in range(4)}, **{f'updatemenus[2].buttons[{i}].visible': False for i in range(4, 12)}}]\n",
            "    ))\n",
            "    buttons.append(dict(\n",
            "        label='Line',\n",
            "        method='relayout',\n",
            "        args=[{**{f'updatemenus[2].buttons[{i}].visible': False for i in list(range(4)) + list(range(8, 12))}, **{f'updatemenus[2].buttons[{i}].visible': True for i in range(4, 8)}}]\n",
            "    )) \n",
            "    buttons.append(dict(\n",
            "        label='Area',\n",
            "        method='relayout',\n",
            "        args=[{**{f'updatemenus[2].buttons[{i}].visible': False for i in range(8)}, **{f'updatemenus[2].buttons[{i}].visible': True for i in range(8, 12)}}]\n",
            "    ))        \n",
            "\n",
            "    \n",
            "    return buttons\n",
            "\n",
            "def update_layout(fig, buttons):\n",
            "    fig.update_layout(\n",
            "        updatemenus=[\n",
            "             dict(\n",
            "                type=\"buttons\",\n",
            "                direction=\"left\",\n",
            "                buttons=buttons[:4],  # first 3 buttons (Bar, Line, Area)\n",
            "                pad={\"r\": 10, \"t\": 70},\n",
            "                showactive=True,\n",
            "                x=0,\n",
            "                xanchor=\"left\",\n",
            "                y=1.05,\n",
            "                yanchor=\"bottom\"\n",
            "            ),        \n",
            "             dict(\n",
            "                type=\"buttons\",\n",
            "                direction=\"left\",\n",
            "                buttons=buttons[4:14],  # first 3 buttons (Bar, Line, Area)\n",
            "                pad={\"l\": 240, \"r\": 10, \"t\": 70},\n",
            "                showactive=True,\n",
            "                x=0,\n",
            "                xanchor=\"left\",\n",
            "                y=1.05,\n",
            "                yanchor=\"bottom\"\n",
            "            ),                 \n",
            "            dict(\n",
            "                type=\"buttons\",\n",
            "                direction=\"left\",\n",
            "                buttons=buttons[14:29],  # first 3 buttons (Bar, Line, Area)\n",
            "                pad={\"r\": 10, \"t\": 70},\n",
            "                showactive=True,\n",
            "                x=0,\n",
            "                xanchor=\"left\",\n",
            "                y=1.2,\n",
            "                yanchor=\"bottom\"\n",
            "            ),   \n",
            "            # dict(\n",
            "            #     type=\"buttons\",\n",
            "            #     direction=\"left\",\n",
            "            #     buttons=buttons[21:25],  # first 3 buttons (Bar, Line, Area)\n",
            "            #     pad={\"r\": 10, \"t\": 70},\n",
            "            #     showactive=True,\n",
            "            #     visible = False,\n",
            "            #     x=0,\n",
            "            #     xanchor=\"left\",\n",
            "            #     y=1.2,\n",
            "            #     yanchor=\"bottom\"\n",
            "            # ),  \n",
            "            # dict(\n",
            "            #     type=\"buttons\",\n",
            "            #     direction=\"left\",\n",
            "            #     buttons=buttons[25:29],  # first 3 buttons (Bar, Line, Area)\n",
            "            #     pad={\"r\": 10, \"t\": 70},\n",
            "            #     showactive=True,\n",
            "            #     visible = False,\n",
            "            #     x=0,\n",
            "            #     xanchor=\"left\",\n",
            "            #     y=1.2,\n",
            "            #     yanchor=\"bottom\"\n",
            "            # ),           \n",
            "            dict(\n",
            "                type=\"buttons\",\n",
            "                direction=\"left\",\n",
            "                buttons=buttons[29:],  # first 3 buttons (Bar, Line, Area)\n",
            "                pad={\"l\": 415, \"r\": 10, \"t\": 70},\n",
            "                showactive=True,\n",
            "                x=0,\n",
            "                xanchor=\"left\",\n",
            "                y=1.2,\n",
            "                yanchor=\"bottom\"\n",
            "            ),                              \n",
            "            # dict(\n",
            "            #     type=\"buttons\",\n",
            "            #     direction=\"left\",\n",
            "            #     buttons=buttons[17:20],  # first 3 buttons (Bar, Line, Area)\n",
            "            #     pad={\"l\": 150, \"r\": 10, \"t\": 70},\n",
            "            #     showactive=True,\n",
            "            #     x=0,\n",
            "            #     xanchor=\"left\",\n",
            "            #     y=1.2,\n",
            "            #     yanchor=\"bottom\"\n",
            "            # ),   \n",
            "            # dict(\n",
            "            #     type=\"buttons\",\n",
            "            #     direction=\"left\",\n",
            "            #     buttons=buttons[20:23],  # first 3 buttons (Bar, Line, Area)\n",
            "            #     pad={\"l\": 300, \"r\": 10, \"t\": 70},\n",
            "            #     showactive=True,\n",
            "            #     x=0,\n",
            "            #     xanchor=\"left\",\n",
            "            #     y=1.2,\n",
            "            #     yanchor=\"bottom\"\n",
            "            # ),   \n",
            "            # dict(\n",
            "            #     type=\"buttons\",\n",
            "            #     direction=\"left\",\n",
            "            #     buttons=buttons[23:],  # first 3 buttons (Bar, Line, Area)\n",
            "            #     pad={\"l\": 480, \"r\": 10, \"t\": 70},\n",
            "            #     showactive=True,\n",
            "            #     x=0,\n",
            "            #     xanchor=\"left\",\n",
            "            #     y=1.2,\n",
            "            #     yanchor=\"bottom\"\n",
            "            # ),                                                                    \n",
            "        ]\n",
            "    )\n",
            "\n",
            "config = {\n",
            "    'df': df,\n",
            "    'num_column_y': 'dob_years',\n",
            "    'cat_columns': ['education', 'gender'],\n",
            "    'cat_column_x': 'gender',\n",
            "    'cat_column_color': 'education',\n",
            "    'func': 'sum'\n",
            "}\n",
            "fig = create_figure(config)\n",
            "buttons = create_buttons(config)\n",
            "update_layout(fig, buttons)\n",
            "fig.update_layout(height = 600\n",
            "                 , title={'text': f\"num = {config['num_column_y']}&nbsp;&nbsp;&nbsp;&nbsp; cat1 = {config['cat_columns'][0]}&nbsp;&nbsp;&nbsp;&nbsp; cat2 = {config['cat_columns'][1]}\", 'y': 0.92}\n",
            "                  , xaxis={'title': None}\n",
            "                  , yaxis={'title': None}\n",
            "                #   , margin=dict(l=50, r=50, b=50, t=70),\n",
            "                  )\n",
            "fig.show()\n",
            "# # print(fig)\n",
            "# chart_studio.tools.set_credentials_file(username=\"bestorlov1992\", api_key=\"TOnnvREBwfkILt9ABEr5\")\n",
            "# # from jupyter to chart studio\n",
            "# py.plot(fig, filename = \"plot name\", auto_open = True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "traces_visible = {'1b': [[False]], '1l': [[False]], '1a': [[False]], '2b': [[False]], '2l': [[False]], '2a': [[False]]\n",
            "        , '12b': [[False] * config['traces_cnt12']], '12l': [[False] * config['traces_cnt12']], '12a': [[False] * config['traces_cnt12']]\n",
            "        , '21b': [[False] * config['traces_cnt21']], '21l': [[False] * config['traces_cnt21']], '21a': [[False] * config['traces_cnt21']]\n",
            "        ,'heatmap': [[False]], 'treemap': [[False]], 'sankey': [[False]]}\n",
            "traces_visible_df = pd.DataFrame(traces_visible)\n",
            "traces_lables = {'1b': '1', '2b': '2', '12b': '12', '21b': '21', 'heatmap': 'heatmap', 'treemap': 'treemap', 'sankey': 'sankey'}\n",
            "traces_visible_df\n",
            "# for button_label in traces_lables:\n",
            "#         traces_visible_df_copy = traces_visible_df.copy()\n",
            "#         traces_visible_df_copy[button_label] = traces_visible_df_copy[button_label].apply(lambda x: [True for _ in x])\n",
            "#         visible_mask = [val for l in traces_visible_df_copy.loc[0].values for val in l]\n",
            "#         print(visible_mask)\n",
            "#         print()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import plotly.graph_objects as go\n",
            "from plotly.offline import iplot\n",
            "\n",
            "# Create a figure with a bar chart\n",
            "fig = px.histogram(x=df['education'], y= df['dob_years'], color=df['gender'])\n",
            "\n",
            "# Add a button to change the orientation\n",
            "fig.update_layout(\n",
            "    updatemenus=[\n",
            "        go.layout.Updatemenu(\n",
            "            active=0,\n",
            "            buttons=list([\n",
            "                dict(label='Vertical',\n",
            "                      method='update',\n",
            "                      args=['barmode', 'group']),\n",
            "                dict(label='Horizontal',\n",
            "                      method='update',\n",
            "                      args=['barmode', 'stack']),\n",
            "            ]),\n",
            "            direction=\"down\",\n",
            "            pad={\"r\": 10, \"t\": 10},\n",
            "            showactive=True,\n",
            "            x=0.5,\n",
            "            xanchor=\"left\",\n",
            "            y=1.1,\n",
            "            yanchor=\"top\"\n",
            "        )\n",
            "    ]\n",
            ")\n",
            "\n",
            "# Display the graph\n",
            "iplot(fig)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "visibles_list_for_traces ={'1': [True, False, False], '2': [True, False, False] * 3\n",
            "                           , '12': [True] + config['traces_cnt12'] + [False] * 2 * config['traces_cnt12']\n",
            "                           , '21': [True] + config['traces_cnt21'] + [False] * 2 * config['traces_cnt21']\n",
            "                           , 'heatmap':  [True], 'treemap':  [True], 'sankey':  [True]}\n",
            "for button_label in visibles_list_for_traces:\n",
            "    mask = [True for _ in visibles_list_for_traces[button_label]]\n",
            "    visible_mask = visibles_list_for_traces.copy()\n",
            "    visible_mask[button_label] = mask\n",
            "    # flat list\n",
            "    visible_mask = [el for l in visible_mask.values() for el in l]\n",
            "    print(visible_mask)\n",
            "    print()\n",
            "    buttons.append(dict(label=button_label, method='restyle', args=[{'visible': visible_mask\n",
            "                                                                    , 'xaxis': {'visible': False}\n",
            "                                                                    , 'yaxis': {'visible': False}\n",
            "                                                                    }]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "buttons = []\n",
            "visibles_list_for_traces = [False] * 3 + [False] * 3 \\\n",
            "                        + [False] * config['traces_cnt12'] \\\n",
            "                        + [False] * config['traces_cnt12'] + [False] * config['traces_cnt12'] \\\n",
            "                        + [False] * config['traces_cnt21'] \\\n",
            "                        + [False] * config['traces_cnt21'] + [False] * config['traces_cnt21'] \\\n",
            "                        + [False] + [False] + [False]\n",
            "button_labels = {'1': 3, '2': 3, '12': 3 * config['traces_cnt12'], '21': 3 * config['traces_cnt21'], 'heatmap': 1, 'treemap': 1, 'sankey': 1}   \n",
            "cnt_vissible = 0    \n",
            "prev_cnt_vissible = 0    \n",
            "for i, (button_label, n_traces) in enumerate(button_labels.items()):\n",
            "    visibles_list_for_traces[prev_cnt_vissible] = False\n",
            "    visibles_list_for_traces[cnt_vissible] = True\n",
            "    prev_cnt_vissible =  cnt_vissible\n",
            "    cnt_vissible = cnt_vissible + n_traces\n",
            "    # print(visibles_list_for_traces)\n",
            "    # print()\n",
            "    # if i >4:\n",
            "    #     break\n",
            "    buttons.append(dict(label=button_label, method='restyle', args=[{'visible': visibles_list_for_traces\n",
            "                                                            , 'xaxis': {'visible': False}\n",
            "                                                            , 'yaxis': {'visible': False}\n",
            "                                                            }]))\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.groupby(['education', 'gender'])[['dob_years']].sum().sort_values('dob_years', ascending=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "treemap(df, ['education', 'gender'], 'dob_years')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(treemap(df, ['education', 'gender'], 'dob_years').data[0])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(treemap(df, ['education', 'gender'], 'dob_years'))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "func = 'sum'\n",
            "cat_column = 'education'\n",
            "num_column = 'dob_years'\n",
            "func = lambda x: x.mode()[0]\n",
            "# df[[cat_column, num_column]].groupby(cat_column).agg({num_column: lambda x: x.mode().iloc[0]}).reset_index().sort_values(num_column, ascending=False) #['dob_years']\n",
            "df[[cat_column, num_column]]\\\n",
            "                .groupby(cat_column) \\\n",
            "                .agg(num = (num_column, func), modes = (num_column, lambda x: '')) \\\n",
            "                .reset_index() \\\n",
            "                .sort_values('num', ascending=False).rename(columns={'num': num_column})\n",
            "                                    \n",
            "                    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "metadata": {},
         "outputs": [],
         "source": [
            "import plotly.io as pio\n",
            "import plotly.graph_objects as go\n",
            "\n",
            "colorway_for_line=['rgb(127, 60, 141)', 'rgb(17, 165, 121)', 'rgb(231, 63, 116)', '#03A9F4', 'rgb(242, 183, 1)'\n",
            "          , '#8B9467', '#FFA07A', '#005A5B', '#66CCCC', '#B690C4']\n",
            "colorway_for_bar = ['rgba(128, 60, 170, 0.9)', '#049CB3', '#84a9e9', '#B690C4',\n",
            "                    '#5c6bc0', '#005A5B', '#63719C', '#03A9F4', '#66CCCC', '#a771f2']\n",
            "# default setting for Plotly\n",
            "# for line plot\n",
            "pio.templates[\"custom_theme_for_line\"] = go.layout.Template(\n",
            "    layout=go.Layout(\n",
            "        colorway=colorway_for_line\n",
            "    )\n",
            ")\n",
            "# pio.templates.default = 'simple_white+custom_theme_for_line'\n",
            "# for bar plot\n",
            "pio.templates[\"custom_theme_for_bar\"] = go.layout.Template(\n",
            "    layout=go.Layout(\n",
            "        colorway=colorway_for_bar\n",
            "    )\n",
            ")\n",
            "pio.templates.default = 'simple_white+custom_theme_for_bar'\n",
            "\n",
            "# default setting for Plotly express\n",
            "px.defaults.template = \"simple_white\"\n",
            "px.defaults.color_continuous_scale = color_continuous_scale = [\n",
            "    [0, 'rgba(0.018, 0.79, 0.703, 1.0)'],\n",
            "    [0.5, 'rgba(64, 120, 200, 0.9)'],\n",
            "    [1, 'rgba(128, 60, 170, 0.9)']\n",
            "]\n",
            "# px.defaults.color_discrete_sequence = colorway_for_line\n",
            "px.defaults.color_discrete_sequence = colorway_for_bar\n",
            "# px.defaults.color_discrete_sequence =  px.colors.qualitative.Bold\n",
            "# px.defaults.width = 500\n",
            "# px.defaults.height = 300\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 100,
         "metadata": {},
         "outputs": [],
         "source": [
            "def plotly_default_settings(fig):\n",
            "    fig.update_layout(\n",
            "        title_font=dict(size=24, color=\"rgba(0, 0, 0, 0.6)\"),\n",
            "        title={'text': f'<b>{fig.layout.title.text}</b>'},\n",
            "        font=dict(size=14, family =\"Lora\", color=\"rgba(0, 0, 0, 1)\"),  # Для подписей и меток\n",
            "        xaxis_title_font=dict(size=18, color=\"rgba(0, 0, 0, 0.5)\"),\n",
            "        yaxis_title_font=dict(size=18, color=\"rgba(0, 0, 0, 0.5)\"),\n",
            "        xaxis_tickfont=dict(size=14, color=\"rgba(0, 0, 0, 0.5)\"),\n",
            "        yaxis_tickfont=dict(size=14, color=\"rgba(0, 0, 0, 0.5)\"),\n",
            "        xaxis_linecolor=\"rgba(0, 0, 0, 0.5)\",\n",
            "        # xaxis_linewidth=2,\n",
            "        yaxis_linecolor=\"rgba(0, 0, 0, 0.5)\",\n",
            "        # yaxis_linewidth=2\n",
            "        margin=dict(l=50, r=50, b=50, t=70), \n",
            "        hoverlabel=dict(bgcolor=\"white\")\n",
            "    )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": 197,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<module 'my_module' from 'c:\\\\Git\\\\Projects\\\\Исследование надёжности заёмщиков\\\\my_module.py'>"
                  ]
               },
               "execution_count": 197,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "importlib.reload(my_module)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 106,
         "metadata": {},
         "outputs": [],
         "source": [
            "import dash\n",
            "from dash import dcc, html\n",
            "from dash.dependencies import Input, Output\n",
            "import plotly.express as px\n",
            "import pandas as pd"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 4 Формулирование и провера гипотез"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Подход следуюищй - мы до раздела проверка гипотез, когда изучаем данные (разделы пропусков, выбросов, дубликатов, зависиместей между перменными и графики),  \n",
            "то мы делаем выводы и формируем наблюдеия.  \n",
            "Вот эти наблюдения и выводы нужно проверить в проверке гипотез.  \n",
            "И потом в основном выводе уже писать не просто, что у нас мужчин больше чем женьшин, а писать, что на уровен значисомти таком то у нас мужчина больше чем  \n",
            "женщин с таким то доверительным интервалом.  \n",
            "Таким образом выводы по вомзожности должны проходить через этап проверки гипотез, тогда эти выводы становятся более существенными.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Гипотезы появляются, когда мы задаем вопросы данным. Мы изучили данные, преобработали и теперь начинаем задавать вопросы.  \n",
            "- Выдвигаем гипотезу (заметили что-то необычное и хотим проверить), далее формулируем ее и далее проверяем.  \n",
            "- Не забываем формулировать гипотезы словами. Пишем что является гипотезой H0, а что гипотезой H1  \n",
            "- Формулируем все гипотезы, которые хотим проверить. Если будет 100 гипотез, то все 100 нужно сформулировать и потом проверить и сделать вывод.  \n",
            "- Гипотезы могут быть и простыми вопросами без гипотез H0 и H1, такие гипотезы мы проверяем графиками или анализируя таблицу.  \n",
            "- Восновном, когда мы собиаремся применить стат аппарат для проверки гипотезы, то мы должны записать ее через H0 и H1.  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Алгоритм проверки статистических гипотез\n",
            "\n",
            "- постановка задачи\n",
            "    - Сформулировать, что мы хотим узнать о выборках с точки зрения бизнес задачи (равны ли средние доходы в группах)\n",
            "- формулировка гипотез\n",
            "    - перевод бизнес-вопроса на язык статистики: средний доход в группах - проверка равенства средних значений\n",
            "    - формулировка нулевой гипотезы - с т.зр. равенства стат прараметров оцениваемых выборок   \n",
            "    (Н0: Средние траты клиентов по группе А равны средним тратам клинентов по группе В)\n",
            "    - формулировка альтернативной гипотезы - с точки зрения неравенства параметров  \n",
            "    (Н1: Средние траты клиентов по группе А не равны средним тратам клинентов по группе В)\n",
            "- выбор критерия alpha (почему 0.05 или 0.01)\n",
            "    - цена ошибки первого рода (при большой цене ошибки - в мед исследованиях, потенциальном ущербе ) - значение может быть больше, например 0.1\n",
            "    - в ежедневных бизнес задачах, обычно - 0.05\n",
            "- анализ распределения\n",
            "    - визуальная оценка\n",
            "    - следим за выбросами\n",
            "    - проверка гипотез о типе распредеделения (например критерий Шапиро-Уилка)\n",
            "    - если распределение не нормальное и размер выборки достаточный (больше 30-50 элементов)  \n",
            "    может быть использован t-test именно для проверки гипотезы о равенстве средних.  \n",
            "    Согласно ЦПТ (центральная предельная теорема) средние этих выборок будут распределены нормально. См. статью Зотова\n",
            "- выбор критерия\n",
            "    - при оценке равенства средних T-test или Welch T-test (если есть сомнения, то лучше Уэлча)\n",
            "        - при рвенстве дисперсий используем обычный т тест\n",
            "        - если дисперсии в выборках разные, то используем т теста Уэлча\n",
            "- получение результата\n",
            "    - расчет p-value\n",
            "- интерпретация p-value\n",
            "    - сравнение p-value и alpha\n",
            "    - если альфа > p-value - отвергаем нулевую гипотезу\n",
            "    - если альфа < p-value - не можем отвергнуть нулевую гипотезу"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Примеры гипотез"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Есть ли зависимость между наличием детей и возвратом кредита в срок?"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Расчеты"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Важно следить за количеством недель в году, если мы создаем столбец месяца.  \n",
            "Проверять чтобы у нас не появлялась неделя дополнительная, из за того, что мы захватили предыдущий год"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Есть ли зависимость между семейным положением и возвратом кредита в срок?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Есть ли зависимость между уровнем дохода и возвратом кредита в срок?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Промежуточный вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Как разные цели кредита влияют на его возврат в срок?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 4. Общий вывод"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Что нужно сообщить в выводе\n",
            "- информацию о том, что удалось подтвердить гипотезы (тут пишем только те, которые удалось подтвердить)\n",
            "- всю информацию о датасете, которые важны. Дубликаты, которые несут практическую пользу и рекомендации по ним, пропуски также с рекомендациями  \n",
            "и остальные моменты по данным и рекомендации. Тут важно указывать именно найденные аномалии, которые имеют практическую пользу, которые нужно исправить и прочее.  \n",
            "Пишем, что были найдены выбросы, они были связаны возможно с тем то и тем то. \n",
            "- и в конце обязательно call to action \n",
            "написать что необходимо сделать с этими результатами"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Советы по оформлению общего выывод\n",
            "- не нужно вставлять таблицы и графики в вывод. \n",
            "В выводе пишем словами самое важное и практически полезное, что мы получили, причем в порядке убывания важности.  \n",
            "И когда мы пишем, что увидели то-то, то приводим гиперссылку на график или результат ячейки, где это получено.  \n",
            "Так будет компактный вывод и при необходимости человек сможет быстро перейти и посмотреть график или таблицу  "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Удалось подтвердить гипотезу** о влиянии различных характеристик клиента на факт погашения кредита в срок. Каждый из рассмотренных параметров оказывает влияние на надёжность заёмщика. Рассмотренные факторы по-разному влияют на надёжность заёмщиков. Например, семейное положение оказалось более значимым фактором, чем уровень дохода.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "ruled-penny",
         "metadata": {},
         "source": [
            "- В ходе анализа исходного набора данных было проведено (были устранены пропуски в двух колонках с числовыми значениями - 'total_income' и 'days_employed').  \n",
            "- После __устранения явных и скрытых дупликатов__ и удаления оставшихся после обогащения пропусков объем датасета сократился на 0.05%\n",
            "- Были устранены __выбросы__ в колонках 'days_employed' и 'children': в первом случае выбросы возникли в результате системной ошибки (данные были внесены в часах, а не в днях); во втором случае ошибка, вероятнее всего была допущена людьми, вносившими данные в систему\n",
            "- ..."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "alleged-strand",
         "metadata": {},
         "source": [
            "**Необходимо**"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "critical-worker",
         "metadata": {},
         "source": [
            "1. Запросить в отделе по работе с клиентами информацию о возможности брать кредит без подтверждения дохода. \n",
            "\n",
            "2. Сообщить коллегам, занимающимся выгрузкой о наличие дубликатов, если вопрос не разрешится, запросить индентификационный номер клиента к датасету.\n",
            "\n",
            "3. Прописать в задаче на поставку данных формат данных (пол только F и M, положительные значения). Приложить информацию о найденных аномалиях."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.7.1"
      },
      "vscode": {
         "interpreter": {
            "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
