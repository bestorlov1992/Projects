{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование надёжности заёмщиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Автор**: Григорьев Павел   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Описание проекта**: Заказчик — кредитный отдел банка. Нужно разобраться, влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок. Входные данные от банка — статистика о платёжеспособности клиентов.  \n",
    "Результаты исследования будут учтены при построении модели кредитного скоринга — специальной системы, которая оценивает способность потенциального заёмщика вернуть кредит банку.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Цель**: Составить рекомендации для кредитного отдела банка, которые будут учтены при построении модели кредитного скоринга.  \n",
    "Определить влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Источники данных**: Данные предоставленны кредитным отделом банка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условия проведения анализа днных**: указываем временной интервал выборки  \n",
    "Например, 'для анализ будут использоваться данные за год с 1 июня 2017 по 31 мая 2018 года'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Вывод**: тут помещаем самое главное из общего вывода, примерно до полустраницы, чтобы не было сильно много и при этом указать все главные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Оглавление** \n",
    "* [1. Описание и изучение данных](#1)\n",
    "    * [1.1 Изучение данных](#1-1)\n",
    "    * [1.2 Изучение данных](#1-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(опционально, зависит от того есть ли оглавление по умолчанию, но лучше сделать скрываемое, так как не везде будет автоматическое):  \n",
    "создаем оглавление с гиперссылками  \n",
    "Тут важно давать развернутые названия разделам в работе, но и не сильно большие (пиши - сокращай).  \n",
    "Все таки это название главы и оно должно быть не более 5-7 слов. Некоторые могут быть длиннее, если сильно нужно,  \n",
    "но основная часть названий разделов и глав долны быть достаточно кратикими.   \n",
    "Чтобы понять длинные ли заголовки - смотрим на оглавление и думаем не сильно ли шировкие строчки.  \n",
    "Чтобы в оглавление хорошо читалось и было понятно про что каждый раздел и глава и чтобы  \n",
    "можно было прочитать, понять и перейти к разделу. Нельзя писать сильно кратко, так как люди не знакомы с работой и им нужно более развернутые  \n",
    "названия глав, чтобы понимать о чем там будет идти речь  \n",
    "Оглавление делаем со сворачивающимися списками, то есть каждую главу можно свернуть, можно развернуть и пеерейти на уровень ниже,  \n",
    "как в сводных таблицах экселя, так удобнее, так как места занимает мало, если скрыть все подразделы, а если нужно, то раскроют  \n",
    "В каждом блоке сделать гиперссылку 'к содержанию', чтобы можно было вернуться к содержанию,  \n",
    "но тут важно, чтобы на одной странице не было больше 1 такой ссылки.   \n",
    "Заголовки разделов и глав не нужно писать в стиле 'посчитаем, выясним, исследуем и подобное', так как названия глав и разделов это более официальные  \n",
    "названия. Нужно более формально их называть.  \n",
    "Название главы или раздела должно нести в себе основной смысл этого раздела или главы, так и нужно называть.  \n",
    "1. Описание данных\n",
    "2. Предобработка данных\n",
    "3. Расчет метрик\n",
    "    3.1 Продуктовые метрики\n",
    "        3.1.1 Расчет MAU, DAU, WAU\n",
    "        3.1.2 Рачет ASL\n",
    "4. Подведение итогов и регкомендации       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, Layout\n",
    "from IPython.display import display, display_html, display_markdown\n",
    "import my_module\n",
    "import importlib\n",
    "import re\n",
    "import itertools\n",
    "# with httpimport.remote_repo('http://my-codes.example.com/python_packages'):\n",
    "#     import package1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Описание и изучение данных <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Описание данных <a class=\"anchor\" id=\"1-1\"></a>\n",
    "- children - количество детей в семье\n",
    "- days_employed - общий трудовой стаж в днях\n",
    "- dob_years - возраст клиента в годах\n",
    "- education - уровень образования клиента\n",
    "- education_id - идентификатор уровня образования\n",
    "- family_status - семейное положение\n",
    "- family_status_id - идентификатор семейного положения\n",
    "- gender - пол клиента\n",
    "- income_type - тип занятости\n",
    "- debt - имел ли задолженность по возврату кредитов\n",
    "- total_income - ежемесячный доход\n",
    "- purpose - цель получения кредита"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Изучение данных <a class=\"anchor\" id=\"1-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>education_id</th>\n",
       "      <th>family_status</th>\n",
       "      <th>family_status_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>1</td>\n",
       "      <td>-2885.142188</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>80236.028323</td>\n",
       "      <td>приобретение автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>2</td>\n",
       "      <td>-1803.080913</td>\n",
       "      <td>36</td>\n",
       "      <td>Среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>163292.220004</td>\n",
       "      <td>строительство собственной недвижимости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>1</td>\n",
       "      <td>-305.540665</td>\n",
       "      <td>27</td>\n",
       "      <td>СРЕДНЕЕ</td>\n",
       "      <td>1</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>69799.488812</td>\n",
       "      <td>ремонт жилью</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>1</td>\n",
       "      <td>-1593.946336</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>1</td>\n",
       "      <td>107486.332934</td>\n",
       "      <td>на покупку подержанного автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>0</td>\n",
       "      <td>-1025.402943</td>\n",
       "      <td>64</td>\n",
       "      <td>высшее</td>\n",
       "      <td>0</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>госслужащий</td>\n",
       "      <td>0</td>\n",
       "      <td>706401.475790</td>\n",
       "      <td>профильное образование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       children  days_employed  dob_years education  education_id  \\\n",
       "4042          1   -2885.142188         50   среднее             1   \n",
       "19177         2   -1803.080913         36   Среднее             1   \n",
       "7372          1    -305.540665         27   СРЕДНЕЕ             1   \n",
       "16245         1   -1593.946336         50   среднее             1   \n",
       "11563         0   -1025.402943         64    высшее             0   \n",
       "\n",
       "          family_status  family_status_id gender  income_type  debt  \\\n",
       "4042    женат / замужем                 0      F    сотрудник     0   \n",
       "19177   женат / замужем                 0      F    сотрудник     0   \n",
       "7372   гражданский брак                 1      F    сотрудник     0   \n",
       "16245   женат / замужем                 0      F    сотрудник     1   \n",
       "11563   женат / замужем                 0      M  госслужащий     0   \n",
       "\n",
       "        total_income                                 purpose  \n",
       "4042    80236.028323                 приобретение автомобиля  \n",
       "19177  163292.220004  строительство собственной недвижимости  \n",
       "7372    69799.488812                            ремонт жилью  \n",
       "16245  107486.332934      на покупку подержанного автомобиля  \n",
       "11563  706401.475790                  профильное образование  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = {'education': 'category', 'family_status': 'category', 'gender': 'category', 'income_type': 'category'}\n",
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/data.csv', dtype=dtype)\n",
    "df.sample(5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "- изучить строки с пропусками\n",
    "data_isnull = data[data['total_income'].isnull()]\n",
    "- проверить пропуски на симметричность\n",
    "data[data['days_employed'].isna() & data['total_income'].isna()].shape[0]\n",
    "- посмотреть как пропуски распределеены по какой-то категориальной пременной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_columns_with_missing_values(df) -> pd.Series:\n",
    "    '''\n",
    "    Фукнция проверяет каждый столбец в таблице,  \n",
    "    если есть пропуски, то помещает строки исходного \n",
    "    дата фрейма с этими пропусками в Series. \n",
    "    Индекс - название колонки. \n",
    "    Если нужно соеденить фреймы в один, то используем \n",
    "    pd.concat(res.to_list())\n",
    "    '''\n",
    "    dfs_na = pd.Series(dtype=int)\n",
    "    for col in df.columns:\n",
    "        is_na = df[col].isna()\n",
    "        if is_na.any():\n",
    "            dfs_na[col] = df[is_na]\n",
    "    return dfs_na\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>education_id</th>\n",
       "      <th>family_status</th>\n",
       "      <th>family_status_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>пенсионер</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>сыграть свадьбу</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>госслужащий</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>образование</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>Не женат / не замужем</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>пенсионер</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>строительство жилой недвижимости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>госслужащий</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>сделка с подержанным автомобилем</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>пенсионер</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>сыграть свадьбу</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21489</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>Среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>компаньон</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>сделка с автомобилем</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21495</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>свадьба</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21497</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>ВЫСШЕЕ</td>\n",
       "      <td>0</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>компаньон</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>строительство недвижимости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21502</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>строительство жилой недвижимости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21510</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>приобретение автомобиля</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4348 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       children  days_employed  dob_years education  education_id  \\\n",
       "12            0            NaN         65   среднее             1   \n",
       "26            0            NaN         41   среднее             1   \n",
       "29            0            NaN         63   среднее             1   \n",
       "41            0            NaN         50   среднее             1   \n",
       "55            0            NaN         54   среднее             1   \n",
       "...         ...            ...        ...       ...           ...   \n",
       "21489         2            NaN         47   Среднее             1   \n",
       "21495         1            NaN         50   среднее             1   \n",
       "21497         0            NaN         48    ВЫСШЕЕ             0   \n",
       "21502         1            NaN         42   среднее             1   \n",
       "21510         2            NaN         28   среднее             1   \n",
       "\n",
       "               family_status  family_status_id gender  income_type  debt  \\\n",
       "12          гражданский брак                 1      M    пенсионер     0   \n",
       "26           женат / замужем                 0      M  госслужащий     0   \n",
       "29     Не женат / не замужем                 4      F    пенсионер     0   \n",
       "41           женат / замужем                 0      F  госслужащий     0   \n",
       "55          гражданский брак                 1      F    пенсионер     1   \n",
       "...                      ...               ...    ...          ...   ...   \n",
       "21489        женат / замужем                 0      M    компаньон     0   \n",
       "21495       гражданский брак                 1      F    сотрудник     0   \n",
       "21497        женат / замужем                 0      F    компаньон     0   \n",
       "21502        женат / замужем                 0      F    сотрудник     0   \n",
       "21510        женат / замужем                 0      F    сотрудник     0   \n",
       "\n",
       "       total_income                           purpose  \n",
       "12              NaN                   сыграть свадьбу  \n",
       "26              NaN                       образование  \n",
       "29              NaN  строительство жилой недвижимости  \n",
       "41              NaN  сделка с подержанным автомобилем  \n",
       "55              NaN                   сыграть свадьбу  \n",
       "...             ...                               ...  \n",
       "21489           NaN              сделка с автомобилем  \n",
       "21495           NaN                           свадьба  \n",
       "21497           NaN        строительство недвижимости  \n",
       "21502           NaN  строительство жилой недвижимости  \n",
       "21510           NaN           приобретение автомобиля  \n",
       "\n",
       "[4348 rows x 12 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(res.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'my_module' from 'c:\\\\Git\\\\Projects\\\\Исследование надёжности заёмщиков\\\\my_module.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(my_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "УЧЕНАЯ СТЕПЕНЬ           1\n",
       "Ученая степень           1\n",
       "ученая степень           4\n",
       "Начальное               15\n",
       "НАЧАЛЬНОЕ               17\n",
       "НЕОКОНЧЕННОЕ ВЫСШЕЕ     29\n",
       "Неоконченное высшее     47\n",
       "начальное              250\n",
       "Высшее                 268\n",
       "ВЫСШЕЕ                 274\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fig = df.education.value_counts(ascending=True)\n",
    "df_fig.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = df.days_employed\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>дом сад стол</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ддм сад стол</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           col1\n",
       "0  дом сад стол\n",
       "1  ддм сад стол"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'дом  \\tСад     стол\\n'\n",
    "b = 'дДм    саД      стол'\n",
    "regex = re.compile(r'\\s+')\n",
    "temp = pd.DataFrame({'col1': [a, b]})\n",
    "temp.applymap(lambda x: regex.sub(' ', x.lower().strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в `describe` можно указать перцентили `percentiles = [0.05, 0,5, 0.95]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После каждой ячейки, где есть использования любой функции и графика для описания данных (то есть есть какой-то результат) нужно рассказать: \n",
    "- Неплохо писать слово жирным шрифтом `Наблюдения:` и с нового абзаца писать рассуждения списком булитами - или *, цифрами не нужно. Так будет и понятно и будет за что зацепиться глазу, выход не пропустят.  \n",
    "- Очень важно помнить, что если мы посчитали какой-то показатель, то лучше сначала его отобразить в виде графика, также привести среднее значение,  \n",
    "и тогда делать выводы.  \n",
    "Например, мы посчитали DAU за год. Будет отлично, если мы выведем измение его во времени, также можно показать график violine и числом вывести  \n",
    "среднее значение. И вот теперь уже делать выводы.  \n",
    "Среднее значение важно, так как его можно использовать в формулах для экономических параметров\n",
    "- что обнаружили, \n",
    "- сделать предположения, почему могло так произойти  \n",
    "- Очень важно помнить, что если у нас распределение метрики не нормальное, то нельзя делать выводы на основе среднего.  \n",
    "Например у нас метрика количество дней до первой покупки и оно имеет экспоненциальное распределение.  \n",
    "Если мы посчитаем среднее, то поулчим значение, например, 15. Но у нас больше всего покупок совершают в первые дни.  \n",
    "И если мы сделаем вывод, что до первой покупки проходит в среднем 15 дней, тоэто будет вводить в заблуждение.  \n",
    "Среднее занчение используем только для симметричных и нормальных распределений. Для других моду или медиану.  \n",
    "И думаем правильно ли мы выбрали, не противоречит ли значение реальности, доносим ли мы тот смысл, который хотим.  \n",
    "- не забывать, если у нас по оси x время, то проанализировать сезонность, почему в одно время есть рост или спад или нет измений  \n",
    "также нужно оценить сильно ли меняется метрика на графике, выявить минимальные и максимальные значения метрики  \n",
    "- подумать а так и должно было получиться, основываясь на понимании физики параметра  \n",
    "даже если прсото посчитали среднее значение в столбце, аналитик задаст вопрос себе а такое среднее и должно было получиться  \n",
    "и это везде, после любого результата и вывода, думаем, а так и должно было быть, если нет, то пишем предположения почему так случилось,  \n",
    "проверяем свои догадки и возможно получаем инсайты\n",
    "- выдвигаем гипотезы (все эти пункты и нужны, чтобы выдвинуть гипотезу, \n",
    "так как самый главный результат любой ячеки с анализом это гипотеза, которую стоит проверить)\n",
    "- *придумать способы проверки, \n",
    "- *если это возможно, реализовать их в следующих шагах\n",
    "Когда мы выдвинули гипотезу, то думаем, а можем ли мы ее проверить по теущим данным.  \n",
    "Например, у нас гипотеза, что пропуски вызваны тем, что безработные писали в доход 0 или оставляли пустым,  \n",
    "но у нас есть поле статус, по которому мы видим, что статус у всех разный с null. Поэтому гипотеза не подтвердилась.  \n",
    "Вот так нужно в этом пункте рассуждать. Выдвигаем гипотезу, думаем можем ее проверить, если не можем, то пишем рекомендации о проверке.  \n",
    "- *зафиксировать возможные рекомендации\n",
    "Булиты со * это то, что делает аналитика аналитиком, именно этим отличается джун от следующего уровня  \n",
    "Например, мы вывели блок describe и пишем по колонку количество детей:\n",
    "Мы видим, что минимальное занчение количества детей отрицательное. Также видим, что максимальное количество детей равно 20.  \n",
    "При чем как мы видим по квартилям, 75 наших данных лежит между 0 и 1.  \n",
    "В колонке количество детей есть все значения. Это хорошо, значит пропусков тут нет.  \n",
    "Подумаем почему могло появиться отрицательное значение количества детей. Возможно это связано с тем, что случайно нажали -.  \n",
    "Максимальное значение 20 может быть связано с тем, что случайно нажали лишний 0.  \n",
    "Следует проверить почему появлись такие необычные значения. Узнать откуда появились эти данные. Кто их заполнял.  \n",
    "Было бы хоршо добавить защиту от ввода таких значений.  \n",
    "- Когда мы считаем размеры групп (когорт) и выводим табличку размера когорт (кстати ее лучше транспонировать, если она длинная в высоту),  \n",
    "то будет отлично дабавить ещё колонку весов каждой когорты. То есть взять размер каждой когорты и разделить ее на общий размер всех когорт.  \n",
    "И тогда когда дальше будет считается не просто среднее значение по когортам, а средневзвешенное, что обязательно нужно считать, то уже будут коэффициенты.  \n",
    "То есть если мы хотим посчитать среднее значение по всем когортам какого-то показателя, то мы не просто суммируем все значения в когортах и делим на  \n",
    "число когорт, мы взвешиваем какждое значение когорты.  \n",
    "Есить 2 способа\n",
    "    - умножать значение каждой когорты на ее размер и потом всю эту сумму разделить на общий размер всех когорт\n",
    "    - сразу дать веса каждой когорты, то есть определить долю каждой когорты в общем.  \n",
    "Берем размер когорты и делим на размер всех когорт. И потом умнажаем значения в когортах на коэффиценты.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда строим гистограмму, нужно понять почему именно такое распределение метрики.  \n",
    "Совпадет это с логикой этой метрики. Если подумать, то можно предположить какое будет распределение у какой-то величины,  \n",
    "и вотэто предполагаемое распределение должно совпадать с полученным.  \n",
    "Если не совпадет, то загорается красная лампоча и думаем, что не так.  \n",
    "Могут быть инсайты.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также когда строим гистограммы и вайолин плот, то не просто фиксируем, что есть тяжелые хвосты, разброс между квартилями такой-то.  \n",
    "А думаем почему так, пытаемся связать это с физикой параметра. Должно быть физическое объяснение всех аномалий.  \n",
    "Если объяснения нет, то возможно это инсайт.  \n",
    "Аналитик тем и отличается от других, что он не просто констатирует, что видит, а пытается понять почему это так,  \n",
    "а должно это так быть, это нормально для данной переменной.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также важно, если мы ничего не обнаружили, то такие ячейки нужно убирать.  \n",
    "Остаются только ячейки, после которых есть вывод, то есть мы что-то получили полезное от этой ячейки.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно убедиться, что у нас есть данные на все источники, которые заявлены. Например, мы изучаем источники трафика и у нас они в разных таблицах.  \n",
    "Нужно убедиться, что во всех таблицах есть все источники, и проверить нет ли аномалий, возможно какой-то сильно выбивается или какого-то вообще где-то нет.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И очень важно сверить, что периоды в разных таблицах (если у нас больше одной таблицы) совпадают.  \n",
    "Так как для анализа мы можем брать данных, только если эти периоды есть во всех датасетах, остальное мы не можем соединять и вынуждены будем отбросить.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще, когда у нас несколько таблиц и там есть категориальные переменные или время, то  \n",
    "мы должны взять уникальные значения категориальных переменных из каждой таблицы (одниаковые переменные) и сравнить.  \n",
    "Количество уникальных должно совпадать, иначе нужно разбираться  \n",
    "И с верменем как минимум мин и макс даты должны совпадать до дня, а лушше до минуты часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно, если у нас есть стартовая дата чего-то и конечная, то обязательно нужно проверить,  \n",
    "нет ли у нас записей, где конечная дата меньше стартовой.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также очень важно проверить все ли периоды в дате присутствуют, не потерялся ли какой-нибудь день.  \n",
    "Иначе мы будем получать неточные занчени.  \n",
    "Смотрим какая детализация даты у нас.  \n",
    "Далее группируем по году, месяцу и дню и смотрим все ли года присутствуют, также можно вывести количество продаж, пользователей для этого года,  \n",
    "чтобы посмотреть нет ли явных просадок \n",
    "Если диапазон большой, то можно по очереди группировать по годам и месяцам, проверить,  \n",
    "а дни потом проверить  отдельно.  \n",
    "Дни (также можно часы, минуты и секунды, если нужно) можно проверить так\n",
    "- сгруппировать по году, месяцу, дню (часу, минуте, секунде, если нужно)\n",
    "- и пройти в apply и поставить 1, где есть разрыв даты (берем генерим все даты через datetime и идем по нашим строкам исмотрим есть все даты  \n",
    "в наших данных)\n",
    "- затем фильтруем по 1 и получаем даты, возле которых есть разрывы, изучаем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важная проверка, если у нас есть категории и даты, то сгруппировать по категориями и \n",
    "вывести количество занчений, минимальную и максимальную дату  \n",
    "Таким образом мы сразу поймем распределение в категории и  \n",
    "увидем какие временные интервалы у каждой категории  \n",
    "Если у нас все категории должны бть в один день, то мы поймем нет ли багов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще очень важно смотреть не только на аномалии в значениях, но и аномалии в категориальных переменных.  \n",
    "А тут аномалией будет отстутствие какого-то значения, хотя в описании или поставновке задачи оно есть.  \n",
    "Также совпадение количества значений категориальных переменных в разных таблицах.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно на дубли проверить и отдельные строки и целиком таблицу и подумать какие группы столбцов могут дать дубли и на это тоже проверить.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в дублях у нас есть ай ди клиента, то тут понятно, если нет ай ди, то пишем рекомендацию, чтобы данные приходили с ай ди,  \n",
    "чтобы можно было понять это один человек или нет "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас id пользователя встречается не одни раз в таблице и есть другие поля которые должны быть всегда одни и те же,  \n",
    "напримем пол и прочее, то нужно проверить у всех ли пользователей все значения одинаковые в этом столбце.  \n",
    "Это может быть не только ай ди, любое уникальное поле, которое повторяется и для каждого этого поля есть другое  \n",
    "поле, которое не должно меняться, нужно проверять а действительно ли это поле не меняется.  \n",
    "Можно сделать так\n",
    "- взять в список униклаьные значения с неизменяемым полем (которое должно быть постоянно одно и то же для всех ай ди)\n",
    "- сгруппировать по ай ди и вязть среднее\n",
    "- и теперь проверить есть ли это среднее в наших уникальных значениях, так как если есть одно не равное всем, то среднее отклонится  \n",
    "Можно улучшить алгоритм, главное обязательно проверять и если нашли аномалии, то изучаем их.  \n",
    "Нужно написать прсото функцию, которая будет это делтаь для любых задач "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = df.col2.unique()\n",
    "df.groupby('col1').nunique().query('col1 > 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# важно оставлять две строки дубля, так как мы по номеру строки (индексу) можем понять а рядом ли были эти дубли,  \n",
    "# если они были рядом, то скорее всего это просто дубль из одного ввода, но если строки далеко, то это явно было в разное время сделано \n",
    "\n",
    "data[data.duplicated(keep=False)].sort_values(['dob_years'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуем null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# исследуем отдельно проблемные строки\n",
    "\n",
    "data_isnull = data[data['total_income'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас в двух колонках есть Null, то стоит проверить на симметричность  \n",
    "Возможно у нас пропущены значения в двух колнках в одних строках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка предположения о симметричности пропусков\n",
    "\n",
    "data[data['days_employed'].isna() & data['total_income'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts() по каждому интересному признаку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно проверить соответствуют ли временной период данных тому, который заявлен в задании,  \n",
    "определиться что будем делать с неполными периодами.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-collect",
   "metadata": {},
   "source": [
    "Принимаем решение, как именно мы будем проводить обработку, почему именно так, *зафиксировать рекомендации.  \n",
    "То есть отвечаем на вопрос, что будем делать с выбросами, что будем делать с null.  \n",
    "Будет идеально если тут зафиксировать рекомендации  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточный вывод**\n",
    "\n",
    "- **children** Присутствует 47 отрицательных значений с \"-1\", а также аномалия в виде 20 детей ...\n",
    "- **days_employed** Большая часть данных стобца со знаком \"-\". Однако, эти данные представляют из себя 84% всей выборки. ... будут заменены на .. исходя из определенного критерия, который будет описан далее. \n",
    "    - Причины пропущенных значений в столбцах **days_employed** и **income**:\n",
    "        - Во-первых, это может быть из-за неправильной выгрузки данных. Оставим это предположение до того момента, пока не убедимся в неверности других предположений.**Наиболее вероятно**\n",
    "        - Во-вторых, одной из гипотез было предположение об отсутствии трудового опыта у данной части выборки. Однако, если распределение по возрасту в данной группе равномерное по всем возрастам выборки. Также большая доля этой части выборки трудоустроена. **Гипотеза не подтверждена**\n",
    "        - В-третьих, возможно, что эта часть выборки не имеет официального трудоустройства. Данная гипотеза вызывает сомнение в связи с тем, что при наличии достаточно большого стажа работы у представителей выборки у ее представителей нет официального трудового стажа. К тому же 18.9% данной выборки являются госслужащими. **Гипотез не подтверждена**\n",
    "- **age** .. 0 возраст у 101 человека.\n",
    "- **education & education_id** Необходимо будет привести данную категорийнуй переменную к общему виду. Избавиться от разного регистра. Но можно не тратить на это время и использовать следующий столбец **education_id**. Это позволит использовать меньше памяти и не повлияет на качество анализа.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Обрезание неполных временных периодов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас датасет за год, например, и первый или последний месяц неполные, то их лучше выбрасить, если мы будем  \n",
    "расчитывать месячные метрики.  \n",
    "Но сначала конечно нужно проанализировать столбцы без обрезания, чтобы убедиться, что там нет ничего необычного.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Выбор нужных столбцов для дальнейшей работы и нормализация таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Думаем, какие колонки нам нужны, выбираем только их для дальнейшей работы.  \n",
    "Остальные убираем в другой датасет. Просто делаем новый датафрейм и в него помещяем не нужные колонки. Так как потом могут пригодиться.  \n",
    "Важно делать это после изучения данных и выдвижения гипотез и рекомендаций.  \n",
    "Так как даже если нам столбец не нужен, там могут быть важные моменты по сбору этих данных или инсайды,  \n",
    "которые помогут улучшить качество сбора данных. И потом если нам нужен будет тот столбец, то мы получим более чистые данные.  \n",
    "- Тут важно сначала убрать не нужные столбцы, а потом уже заниматься удалением пропусков и выбросов.  \n",
    "Так как может получиться так, что мы сначала удалим строки, так как в этой колонке пустые значения, а потом удалим и всю колонку,  \n",
    "в итоге мы зря удалили строки, так как в других колонках не было пропусков.  \n",
    "Поэтому думаем прежде чем удалять строки, так как возможно лучше удалить столбец и строки удалять будет не нужно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замена типа данных и приведение названий столбцов к нижнему регистру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно привести названия столбцов к нижнему регистру, убрать пробелы (заменить их на _),  \n",
    "так как в том же merge могту быть проблемы, если это не сделать и вообще будет удобнее работать "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если после попытки привести тип к нужному, мы получили ошибку,  \n",
    "то обязательно изучаем эти строки. Именно строки, не только сами занчения, которые не можем преобразовать.  \n",
    "Часто бывает у нас в ругих столбцах есть категория например, которая портит все,  \n",
    "и при этом это выброс может быть.  Поэтому обязательно првоеряем строки, в которых строки не преобразуются в нужный тип.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно писать код, чтобы не учитывался порядок столбцов. Чтобы если порядок изменится, то наш скрипт будет работать верно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все значения в колонках во всех таблицах нужно привести к нижнему регистру и по возможности к одному языку,  \n",
    "для перевода к одному языку можно использовать словарь, с помощью которого изменить неправильный язык  \n",
    "Это нужно, чтобы когда будем соединять таблицы, у нас условие соеденения правильно сравнивало равные значения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена типа astype(), приведение к нижнему регистру str.lower(), удаление аномалий\n",
    "dict_types = dict(col1=float\n",
    "                  , co2_id=int)\n",
    "df = df.astype(dict_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также важно категориальные столбцы привести к типу `category` и для столбцов, которые имеют малый диапазон значений заменить на меньший тип,  \n",
    "например на `int8`  \n",
    "`.astype('category')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно следить, чтобы не появлялись дополнтиельные недели, когда мы делаем столбец год-месяц и столбец неделя,  \n",
    "то есть мы берем для каждого лога с временем считаем начало недели и указываем это значение как начало недели  \n",
    "Но если у нас первый и последний день месяца не пн и не вс, то у нас будут лишние недели, так как если  \n",
    "первый день года среда, то наш расчет возмет начало недели с прошлого года.  \n",
    "Чтобы такого не было лучше использовтаь для вычисления недили  \n",
    "`col_with_time.astype('datetime64[W]')`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также важно, когда мы создаем столбцы для расчета `mau / dau` и в этих стобцах недели,  \n",
    "убедиться, что недель столько сколько и должно быть в выбранном году (например 52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увидели пропуск — подумайте, нормально ли это. Сколько вообще пропусков может быть в этом столбце?   \n",
    "К примеру, в списке с электронными адресами пользователей, согласных на рассылку, будет много пропусков. Далеко не все предоставляют email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использвоать такой подход\n",
    "- если количество пропусков меньше 5 процентов, то удаляем (лучше меньше 1 процента)\n",
    "- если количество пропусков от 5 до 20 процентов, то подбираем чем заменить, удалять не стоит\n",
    "- если больше 20 процентов, то не трогаем, так как исказим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но оставляя пропуски, нам нужно помнить, что мы не можем по этим полям считать корреляцию с другими,   \n",
    "так как пропуски испортят расчет коэффициента корреляции. Аналогично другие метрики могут считаться некорректно.  \n",
    "Поэтому, если мы будем считать показатели по столбцу с пропусками, то их нужно либо убирать, либо этот столбец не использовать для расчетов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если пропуск вызван просто отстутствием значения (просто нет категории у чего-то или просто нету чего-то), то можно для каетгориальны перменммых  \n",
    "ставить пустую строку, это будет логично. Нет значения - пустая ячейка.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных переменных оставлять пропуски нельзя, так как мы скорее всего будем группировать по ним и смотреть разные разрезы.  \n",
    "Поэтому в худшем случае, если не можем ничем заменить, и нет уверености, что пропуск можно заполнить пустой строкой (если значения физически нет),  \n",
    "то создаем категорию например `other` из пропусков.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы встречаем пропуски, прежде всего, нужно ответить на вопрос, существует ли закономерность в появлении пропусков.   \n",
    "Иными словами, не случайно ли их возникновение в наборе данных.  \n",
    "Случайно, значит нет закономерности с соседними столбцами, то есть пропуски есть для разных значений.  \n",
    "А могут быть неслучайные, то есть существует явная закономерностЬ, что пропуски есть только у сторок с общими занчениями в другом столбце.    \n",
    "Чтобы это проверить, нужно взять столбец с пропусками, отфильтровать только пропуски (взять их) и  \n",
    "посмотреть как эти пропуски распределены по другой переменной.  \n",
    "Например, у нас пропуски в источнике трафика и пропуски в email. Причем среди источников есть источник email (то есть пришли через почтовую рассылку)\n",
    "Мы фильтруем источники и оставляем только пропуски в них и фильтруем email без пропусков и видим, что все наши пропуски в источнике имеют email.  \n",
    "В итоге можно сделать вывод, что это источники трафика через email. И заменить пропуски на источник email.  \n",
    "Но нужно это проверить и выяснить, почему они так отобразились, почему не отнеслись в источник email.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно сначала посмотреть корреляцию.  И тогда, если у переменной с пропусками есть коррелирующая переменная,  \n",
    "то мы можем взять значение в столбце без пропусков такое же как то, что пропущено и просто заменить на наше.  \n",
    "То есть корреляция позволяет нам заменять пропуски, дополнительно можно испоьзовать группировки, то есть заменять на значение группы.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Первое что нужно сделать, когда мы видим пропуск или выброс, это проверить является ли оно случайным.  \n",
    "То есть посмотреть не относятся ли все выбросы к одной категории. Если это так, то это уже не случайно и мы нашли аномалию, которую можно изучать.  \n",
    "Если у нас случайны разброс пропусков в категориях, то значит тут есть случайность.  \n",
    "Например, у нас возраст 0, и мы видим, что больше всего это у женщин. Следовательно получаем гипотезу, что женщины не хотят сообщать свой возраст.  \n",
    "- Сначала мы изучаем столбцы отдельно в разделе изучение данные, смотрим выбросы, строим гипотезы и строим предпожения.  \n",
    "Только когда мы изучили все столбцы по отдельности, мы можем дропать записи. Почему это важно.  \n",
    "Если мы увидели пустые значения, изучили, выдвинули гипотезы и решили сразу дропунть, то мы параллельно дропним и \n",
    "значение в другом столбце, а это значение возможно нам может что-то сказать о другом столбце.  \n",
    "Поэтому сначала изучили всё отдельно, и только потом дропаем. Даже если пустых значений в этой колонке очень мало.  \n",
    "- Если у нас одна переменная имеет много пропусков, и мы ее не можем выкинуть, то можно попробовать заполнить по другим колонкам.  \n",
    "То есть мы берем и делаем словарь по не пустым значениям. То ключ у нас будет значение из строки без пропусков, а значение из столбца с пропусками  \n",
    "Тут мы испльзуем медиану, моду, или другие статистики и методы, чтобы определить какая категория (знчение) из одного столбца подходит для другого  \n",
    "И потом просто заменяем пропуски используя этот словаь, смотрим строку, берем значение из столбца без пропусков и идем в словарь.  \n",
    "- Также можно заполнять пуропуски не медианной по всему дата сету, а взять колонку коррелирующую с колонкой с пропусками и сгруппировать  \n",
    "по ней и уже внутри этой группы заполнить пропуски медианами.  \n",
    "Например у нас в доходе пропуски. И у нас есть категория стунедт, рабочий, пенсионер, то мы можем заоплнять медианами для каждой категории.  \n",
    "Тогда у нас человек с пропуском из категории студент получить медиану студента, что правильнее.  \n",
    "- В пропусках мы можем определить какие категории, платформы и прочее не собираются данные. Смотрим пропуски, далее смотрим у каких категорий их больше,  \n",
    "и получаем вывод, что нужно обратить внимание на эти категории или системы, почему там пропуски\n",
    "- Также пропуски могут быть аномалиями. Например, кто-то что-то  придумал для обхода системы и его не детектируют и прочее. Поэтому пропуски нужно  \n",
    "внимательно изучить, даже если мы хотим их дропнуть.  \n",
    "- Если у нас пропуски в категориальной переменной и есть разные периоды или просто данные разбиты на части (то есть эта категориальная переменная повторяется),  \n",
    "то мы можем взять ещё какую-нибудь переменную, у которой нет пропусков, где пропуски у первой переменной и далее посмотреть другие периоды  \n",
    "Таким образом у нас будет предыдущий период, где будет занчение второй переменной и первой и если в нескольких периодах они одинаковые, то мы можем  \n",
    "заполнить и пропуски этим значением.   \n",
    "Например, у нас есть продажи по дням и за какой-то месяц много пропусков в описании товара, но есть код товара, мы идем и смотрим другие месяца, где встречаются  \n",
    "коды в строчках с пропусками в описании. И если находим, то можем заменить пропуски на эти значения.  \n",
    "То есть пропуски в данных могут быть вызваны ошибками заоплнения и прочим, но в этой же таблице могут быть верно  заполнениые занчения, тогда имея  \n",
    "другую колонку, по которой мы можем идентифицировать наши пропуски, мы можем заполнить эти пропуски  \n",
    "Можно взять колнку с пропусками и колонку с кодами (только их) и отсортировать по коду, тогда мы увдием для каждого кода описание и пустые поля и сразу будет видно  \n",
    "Ещё раз схема такая - берем 2 поля одно с пропусками, другое без, получаем новую таблицу, в этой таблице оставляем только униклаьные значения в поле без пропусков,  \n",
    "по этому полю будем джойнить. Далее в основнйо таблице дропаем описание и создаем новое описание из таблицы справочника.  \n",
    "- Не забываем про сингулярное разложение (svd) для заполнение пропусков и методы машинного обучения для этого же.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# последовательность действий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "# что-то изменили - > посмотрели не изменилось ли количество дублей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка пустых значений\n",
    "\n",
    "data['total_income'].fillna(data.groupby(['age_group','education','gender'])['total_income'].transform('median'))\n",
    "df.fillna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с выбросами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Очень важно понимать, когда выброс можно отбросить и он реально выброс и когда нельзя.  \n",
    "Напрмер у нас колонка размер чаевых. И у нас будут выбросы большие. Логично, что это реальные большие чаевые, которые  \n",
    "нам важны. Другое дело, когда у нас чаевые например сильно большие и мы понимаем, что такое очень редкое событие и  \n",
    "мы можем для визуального аналаиза их отбросить.  \n",
    "То есть прежде чем отбросить выбросы, нужно подумать, а не потеряем ли мы информацию после этого и что нам даст отбрасывание.  \n",
    "Если мы получим пользу больше, чем потеряем информации, то можно отбросить.  \n",
    "- Также выброс может казаться выбрасом, но для бизнеса это не выброс.  \n",
    "Например у нас суммы покупок и одна покупка сильно выделяется, а там просто человек купил супе дорогой каньяк, например.  \n",
    "Для бизнеса это не выброс. Поэтому нужно всегда сначал поянть может ли в данной ситуации быть такое значение, если да, то это не выброс.  \n",
    "- Когда хотим обрезать выбросы, то думаем, какой порог может быть физически реальным и по нему режем, а не просто так берем какой-то перцентиль.  \n",
    "Всегда нужно думать с точки зрения физического возможного значения параметра и по нему резать (подумать а какое значение может быть максимально реальным и по нему обрезать)\n",
    "Напрмер, мы скачали данные с циана и у нас цена сверху и снизу явно нереальная, то мы думаем какая может быть самая дешевая и самая дорогая цена и по ним режем.  \n",
    "- Выбросы это не только просто сильно большое или сильно маленькое значение.  \n",
    "Выбросы нужно также смотреть по мультипараметрам, с помощью моделей и искать аномалии.  \n",
    "Выбросы нужно изучить отдельно.  \n",
    "Очень часто в выбросах содержаться инсайты иномалии, которые помогут сделать практически полезные выводы.  \n",
    "Выброс это то, что отделяется от других, что выбивается из общей картины. Следовательно это что-то особенное.  \n",
    "Бывает кто-то придумал что-то новое и это естествественно будет выделяться. Поэтому нужно внимательно изучать выбросы.  \n",
    "- Тажке выбросы говорят не только о плюсах, но и о минусах. Выбросы могут сказать, что у нас что-то сломалось.  \n",
    "Что-то не записывается, или работает с багами. Все это можно увдитеь по выбрасам и аномалиям.  \n",
    "- Обязательно посмотреть выбросы в разрезе категорий, так как мы сможем сделать выводы об их источнике.  \n",
    "- Если мы работаем со строгой отчетностью, то тут любой выброс это уже инсайт и нужно идти разбираться откуда это взялось.  \n",
    "- Если мы не можем с увереностью сказать, что это выброс, то нам не стоит его выкидывать, но работать как то нужно с ними,  \n",
    "тогда, логарифмируем (лучше использовать натуральный логарифм) эту колонку и работаем с такими значениями (тогда выбросы сожмуться).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дубликатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Важно помнить, что если у нас есть id и название товара, то названия товара все равно нужно проверить на дубли,  \n",
    "возможно у нас 2 ай ди с одним названием.\n",
    "- Дубли могут быть такие 'Смартфон Redmi' и 'смартфон redmi'  \n",
    "поэтому перед провекой на дубли приводим к нижнему регистру  \n",
    "Также могут быть разыне пробельные символы и другие символы, которые создают 2 элемента, когда на самом деле это дубли  \n",
    "Такое нуно находить, так как иначе у нас будет неверные расчеты, так как у нас либо дубль,  \n",
    "либо может один товар забит в разных местах по разному и у нас половинится расчет на разные названия.   \n",
    "- Дубликаты могут быть не полностью строка датафрейма, а напрмер 2 и более строчек формируют дубликат. В идеале изучить возможные комбинации колонок  \n",
    "на дубли. То есть взять перембрать по 2-3-..-n колонок и фильтрануть фрейм по ним, чтобы посмотреть какие записи во всем датафрейме с такими дублями.  \n",
    "Например, у нас есть описание чего-то и стоимость, они одинаковые у двух строк, но другие поля разные, если мы будем смотреть дубли всех колонок, то мы  \n",
    "этот дубль не заметим. А возможно тут явный дубль. \n",
    "- Также важно в каждой отдельной колонке проверить дубли и если их много, то посмотреть на соседние колонки, что там происходит\n",
    "- Дубликаты часто носят скрытый характер.  \n",
    "То есть это могут быть поля, которые записаны  по разному, но относятся к одному и тому же.  \n",
    "Поэтому важно, если у нас категориальный признак, изучить нет ли повторящихся категорий, которые записаны немного по разному.  \n",
    "Так как это создает шум, мы по сути имеем две разные категории, но на самом деле это одна. Нужно собрать их в одну.  \n",
    "- Дубликаты обязательно сначала изучаем, делаем гипотезы, проверяем их, если есть практическая польза то формируем рекомендации и записиываем в вывод для шага  \n",
    "и потом возможно в общий вывод.  \n",
    "И только после этого удалеяем. Сначала нужно обязательно изучаем.  \n",
    "- И очень важно, если мы не подтвердили, что это действительно дубликат (например у нас нет ай ди клиента и мы не смогли выяснить один и тот же ли это человек),  \n",
    "то нужно аккуратно удалять их. Но и оставлять много дублей плохо, так как они вносят шумы и искажения.  \n",
    "- Помним, что наличие дубликата не говорит точно, что это дубль, возможно у нас нет ещё колонок, котоыре бы детализировали и разделили эти дубли.  \n",
    "Поэтому тут могут быть рекомендации, чтобы добавли в фрейм доп колонки, которые помогут убрать дубли (либо сам ищешь ещё поля)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас дубли в какой-то колонке и нам их нужно не удалять, а соеденить в один,  \n",
    "то можно сгруппировать колонку с дублями и суммировать поле, которое нужно объеденить  \n",
    "Потом дропнуть дубли и заменить поле в котором нужно объеденить занчения на занчение из слваря  \n",
    "```\n",
    "dict_cnt = stock.groupby('item')['count'].sum().to_dict()\n",
    "stock = stock[~stock.item.duplicated()]\n",
    "stock['count'] = stock['item'].map(dict_cnt)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- С помощью лематизации мы можем сократить количество категорий.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# лемматизация\n",
    "\n",
    "unique_purpose = data['purpose'].unique()\n",
    "lemmas_list = []\n",
    "m = Mystem()\n",
    "for purpose in unique_purpose:\n",
    "    lemmas = ''.join(m.lemmatize(purpose)).strip()\n",
    "    lemmas_list.append(lemmas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделяются группы:\n",
    "- операции с автомобилем (ключевое слово - автомобиль)\n",
    "- операции с недвижимостью (ключевые слова: жилье, недвижимость)\n",
    "- проведение свадьбы (ключевое слово: свадьба)\n",
    "- получение образования (ключевое слово: образование)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для назначения категории цели\n",
    "\n",
    "def create_category_purpose(row):\n",
    "    lem_purpose = m.lemmatize(row['purpose'])\n",
    "    try:\n",
    "        if 'автомобиль' in lem_purpose:\n",
    "            return 'операции с автомобилем'\n",
    "        if ('жилье' in lem_purpose) or ('недвижимость' in lem_purpose ):\n",
    "            return 'операции с недвижимостью'\n",
    "        if 'свадьба' in lem_purpose:\n",
    "            return 'проведение свадьбы'\n",
    "        if 'образование' in lem_purpose:\n",
    "            return 'получение образования'\n",
    "    except:\n",
    "        return 'нет категории'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категоризация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категоризация нужна, чтобы образовать группы, в которых достаточно значений для использования статистических методов.  \n",
    "И вообще, если в группе 1-10 элементов, например у нас возраст пользователей и 5 человек с возрастом 22, 3 человека с возрастом 23 и так далее.  \n",
    "Мы не можем разбивать по таким группам, так как их размер небльшой и выводы будут некорректные, поэтому нам нужно собрать их в группы,  \n",
    "чтобы у нас были группы с достаточным размером.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если у нас есть столбцы с ай ди и столбцы, где эти ай ди расписаны словами, то лучше сделать словарь, где ай ди будут клчюами,  \n",
    "а занчениями будут расписаные словами ай ди. И убрать столбец с расшифровкой. Это очень экономит память. И если нам нужно будет,  \n",
    "то мы подтяним описание.  Это можно делать не только с айди. Если у нас есть столбец с описанием и в нем много повторов, то лучше  \n",
    "сделать словарь, так как числа меньше весят и их быстрее обрабатывать.  \n",
    "- Вообще любые столбцы, где у нас текст и много повторов, лучше убрать в словарь, то есть нормализовать.  \n",
    "И когда нам будет нужно, то мы сформируем снова этот столбец. Мы так намного уменьшим память и ускорим процессы работы с таблицей.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# категории: \"на глазок\", value_counts(), функция, пандаметод\n",
    "# вариант разбивки на категории по квартилям\n",
    "\n",
    "pd.qcut(data['total_income'], 4, ['очень низкий доход', 'низкий доход', 'средний доход', 'высокий доход'])\n",
    "\n",
    "# словари\n",
    "\n",
    "educ_dict = data[['education_id', 'education']]\n",
    "educ_dict = educ_dict.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если у нас категориальная переменная имеет много значений, то мы не можем номрально с ней работать.  \n",
    "Так как мы не можем построить графики по ним, так как их много и они не числовые. Не можем сравнить их все.  \n",
    "Поэтому нам нужно сократить категории.  \n",
    "- Нужно посмотреть на данные и подумать можем ли мы разделить их по сегментам рынка или по другим категориям, которые нам помогут.  \n",
    "- Мы можем категоризировать на основе и числовых и категориальных столбцов. То есть мы можем из категориальной переменной сделать  \n",
    "другую категориальную, уменьшив или увеличив разбиение.   \n",
    "- добавление категорий обогощает данные, при чем категории могут формироваться не из одной колонки, а из серии, то есть чтобы попасть  \n",
    "в определенную категорию значения столбцов должно быть такое то, а не только один столбец определяет категорию.  \n",
    "- категории могут быть да нет, то есть состоять из двух значений, например, у нас есть данные о рекламе и столбец где она показвалась,  \n",
    "и у нас много много разных устройств. Мы можем разбить на да нет, то есть показвалась реклама по телеку или нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотим преобразовать категории в числа, то мы можем использовать \n",
    "- lable encoding  \n",
    "Заменяем быквы числами. Хорошо работает, когда у нас порядковые категориальные переменные.  \n",
    "Не забываем про порядок, если у нас алфавитный порядок наших категорий соотвествует числовому, то ок,  \n",
    "если нет, то нам нужно самим определить порядок чисел, чтобы они соответствовали категориям в нужном порядке.  \n",
    "- one hot encoding  \n",
    "Если у нас категориальная переменная не упорядочиваемая, то лучше использовать one hot encoding, чтобы разница между числами не вносила шум,  \n",
    "так как черный и белый и красный цвет закодированные 1, 2, 3 вносят смысл количества, но они не имеют этого свойства.  \n",
    "- замена категориальной переменной на каую-то статистику по одной из категорий внутри этой переменной.  \n",
    "Например у нас категориальная переменная это наличие задержки. Значение задержан / незадержан. Мы кодируем их как 0 и 1. Далее мы берем и считаем по каждой группе (для задержан и для незадержан)  \n",
    "статистику, например, среднее и получаем столбец, где вместо каждой буквы будет ее среднее.  \n",
    "Тут важно делать регуляризацию. Так как маленькие группы могут иметь сильно  зашумленные статистики, так как если у нас  \n",
    "группа из 5 значений, то среди них может быть легко экстремальное одно и оно сбивает статистику, поэтому добавляем штраф всем статистикам.  \n",
    "Регуляризация это что-то похожее на сглаживание.  \n",
    "Как это делается \n",
    "    - берем считаем среднее по таргету (целевой переменной, то есть той, по которой мы счтаем статистику) всей таблице (то есть не делим на категории)  \n",
    "    - Далее используем следующую формулу для сглаженного значения среднего по конкретной группе:   \n",
    "      (среднее по группе * количество элементов в группе + среднее по таргету без учета категорий * размер регуляризирующей группы) / (количество элементов в категории + размер регуляризирующей группы)  \n",
    "      Количество элементов в регуляризационнной группе выбирает эмперически. То есть это количество элементов, которым мы сглаживаем.    \n",
    "      Смысл в том, что мы берем сколько-то элементов с занчением для всех категорий и сглаживаем им наши отдельные категории.    \n",
    "    - Размер регуляризирующей группы обычно выбирают с помощью grid search, то есть берут цикл для размера этой группы и считают результат модели для каждого размера,  \n",
    "    и потом выбирают тот размер, для которого результат лучше.  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придумываем какие колонки можно дополнительно сделать из имеющихся.  \n",
    "Например у нас есть колонка длительность звонков, и 0 это пропущенный звонок,  \n",
    "мы можем сделать колонку is_missed, в которой будет true или false  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно, когда мы создаем новые колонки, в которых используем несколько дургих, то нужно проверить распределение этой новой переменной, особенно  \n",
    "выбросы. Например, у нас начальная и конечная дата сессии и мы считаем длительность сессии. Вот тут нужно посмотреть какая минимальная длительность  \n",
    "и какая максимальная. Ну и естественно проверить есть ли длительность 0 и меньше нуля.  \n",
    "Таким образом мы можем найти инсайты уже после создания новых колонок, хотя в изначальных данных этих инсайдов не было видно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обогощение таблиц (соединение с другими)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обоготить данные можно следующими способами\n",
    "- взять поле нашей таблицы и найти дополнительные данные в интернете или ещё где-то и потом связать с нашей колонкой по этому полю  \n",
    "Самое просто это дата, если у нас есть дата, то мы можем много разной доп информации внести в наши данные связывая по дате.  \n",
    "Также, например, у нас есть какие-то коды чего-то, мы ищем информацию по этим кодам и находим табличку с доп инфой по этим кодам и можем обоготить ими   \n",
    "нашу таблицу. Например, у нас города или страны, мы можем по ним также внести доп инфу из какого-то источника, которая нам поможет.  \n",
    "Вообще любое поле нашей таблицы это потенцильная нить для обогощения. Главное понять с чем полезным мы можем соеденить  \n",
    "через конкретное поле, чтобы получить больше полезной информации для анализа, по сути для детализации наших зависимостей или для поиска  \n",
    "новых зависимостей и инсайтов в них.  \n",
    "Процесс следующий - мы берем каждую колонку нашего дата сета и думаем, с чем через нее мы можем связать и если придумываем, то идешь ищем эту информацию и  \n",
    "в итоге соединяем.  \n",
    "- Можно пойти от обратного. Сначал подумтаь какие данные нам могут помочь и поискать их в интернете например, а потом уже думать как их соеденить с нашими   \n",
    "данными. Оба способа лучше делать одновременно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем соединять 2 таблицы, смотрим есть ли поля, которые уникально описывают строчки в обеих таблицах.  \n",
    "В напрмер, в одной таблице у нас есть ай ди пользователя и месяца (ай ди не уникальны, месяца тоже, но вместе уникальны),  \n",
    "и в другой таблице также, тогда мы соединяем таблицы по составному ключу [айди, месяц]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно соединять таблицы по полям с id,  \n",
    "если мы соединяем поля по текстовым полям, то это будет намного дольше, так как будут сравниваться строки  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нужно обязательно првоерить после соединения\n",
    "- если мы соединяем по полю, которое уникально в обеих таблицах\n",
    "    - количество строк в левом датафрейме равно количеству строк в итоговом\n",
    "    - параметры каждого дата сета не изменились (если мы соединили правильно, то итоговые суммы по столбцам не должны измениться)\n",
    "        - используем `df.sum(numeric_only=True)` для каждой таблицы до соединения и для общей таблицы и сравниваем значения\n",
    "        - можно использвоать `df.describe` также до и после объединения и сравнивать параметры\n",
    "- если у нас в одной из колонок для соединения не уникальные значения (то есть для одной строки в левой таблице будет несколько в итоговй)    \n",
    "    - Сначала группируем таблицы, чтобы поле для соединения в обеих таблицах было уникальное\n",
    "    и применяем предыдущий шаг с количеством строк в левой и итоговой и суммой значений в левой и итоговой одинаковой\n",
    "    - Если нам нужно соеденить без группировки (но это редко может быть, поэтому нужно подумать точно ли не моежм сгруппировать)  \n",
    "    тогда нет выбора и остаются только следующие варианты  \n",
    "        - если в левой таблице уникальные записи в колонке, по которйо соединяем    \n",
    "            - тогда считаем сколько было записей в левой таблице в колонке для соединения и сравниваем с количеством **уникальных** записей в итоговой  \n",
    "            они должны совпадать, но тут важно в итоговой брать уникальные записи\n",
    "        - есил и в левой и правой нет уникальных\n",
    "            - тут считаем сколько **уникальных** в левой до и сколько **уникальных** в итоговой, должно совпадать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас что-то не сходится после соединения таблиц, то нужно внимально изучить это.  \n",
    "Тут может быть инсайт (кто-то не правильно вносит информацию, какие-то значения неверные или кто-то что-то хотел спрятать, не указать и прчоее).  \n",
    "Когда видим нестыковки после соединения таблиц, то должна загораться красная лампочка. Это потенциальный инсайт, баг, который мы можем найти и сообщить, чтобы его починили. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше привыкать везеде соединять таблицы как left join, чтобы наверняка не потерять данные.  \n",
    "А если вылезит не нужный Null, то с ним уже можно будет разобраться, это лучше чем случайно забыть использовать left  \n",
    "и потерять данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также лучше привыкать соединять таблицы, у которых поле для соединения уникальное в обоих таблицах.  \n",
    "Нужно соеденить таблицы, смотрим уникальные ли поля, если нет, то думаем что мы будем делать после соединения,  \n",
    "скорее всего аггрегировать, тогда нужно до соединения аггрегировать таблицу, где поле не уникально, и потом соединять.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используем merge, join, append, concat  \n",
    "но помним, что часто метод соединения inner стоит по умолчанию,  \n",
    "а мы хотим обогатить данные, то есть у нас в правой таблице может не быть того, что в левой,  \n",
    "поэтому правильно использовать left join иногда outer join "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно после каждого соединения проверять, что количество строк в итоговом дата сете равно количеству строк в левом датасете.  \n",
    "Это очень часто забывают проверять, а от этого очень много ошибок, которые потом сложно искать.  \n",
    "Если запомнить и постоянно проверять количество строк после соединения, то избавимся от многих потенциальных проблем.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас поле, по которому мы хотим соеденить не уникальное в однйо из таблиц, то думаем о аггрегации.  \n",
    "Например, у нас в одной таблице клиенты (тут уникальные ай ди), а в другой покупки (тут ай ди могут повторяться),  \n",
    "тогда нам скорее всего из таблицы с покупками нужно будет что-то аггрегированное (например сумма покупок клиента),  \n",
    "поэтому сначал думаем что мы хотим анализировать и аггрегируем по этому параметру до соединения.  \n",
    "Большая ошибка сначала соеденить, а потом аггрегировать.  \n",
    "Если есть такая возможность и это не влияет на результат, то сначал нужно аггрегировать, чтобы не было проблем с памятью   \n",
    "Также фильтруем не нужные колонки до соединения, также чтобы не тащить лишние данные в общую большую таблицу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В колонках, по которым будем соеднить, проверяем, нет ли пропусков, какие разделители. пропуски нужно заменить нулями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый раз, когда мы работаем с дата сетом, мы должны понять что является сущностью этого дата сета.  \n",
    "Например событие, человек и прочее.  \n",
    "Далее нам нужно поянть а можем ли мы его идентифицировать по текущим данным (не всегда есть уникальный ай ди).   \n",
    "Если не можем, то нужно думта как обогатить данные, чтобы четко идентифицировать сущности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема разрастания дубликатов  \n",
    "Если мы соединяем таблицы и используем неправильный способ, то у нас могут появляться дубли и они могут сильно разрастаться  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема потери из-за неиспользования left join, когда важно не потерять данные  \n",
    "Не забываем каждый раз когда хотим соеденить таблицы задавать себе вопрос, могут ли потеряться данные,  \n",
    "если я использую просто join, важно ли мне не потерять даннные. И только после ответа на этот вопрос выбирать вариант соединения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема справочников  \n",
    "При объединение таблиц важно помнить про то, что в разных таблицах не только названия столбцов может быть разное,  \n",
    "но и одно значение может быть записано по разному в разных таблицах, например, названия профессий, названия городов,  \n",
    "имя в одной таблице на русском, а в другой на английском, номер телефона с черточкой или плюсом и без черточки или плюса.  \n",
    "Поэтому не забываем привести все значения таблиц к нижнему регистру, чтобы не было проблем разными регистрами для одного слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема временных зон  \n",
    "В одной таблице может быть выгрузка по местному времени, а в другом по московскому  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема курсов валют  \n",
    "Разыне системы могут брать курс за разные промежутки вермени, например, одна система берет курс в гугле (раз в час обновляется),  \n",
    "а другая система берет курс в ЦБ (обновляется раз в сутки)  \n",
    "И поэтому итоговые резултаты могут не состыковаться, поэтому, когда видим курсы валют, то нужно убедиться. что они взяты из одного испточника  \n",
    "и за один промежуток времени  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы работаем с данными, нам важно четко идентифицировать клиентов, событие или другую сущность, с которой мы работаем.  \n",
    "Иначе у нас будет шум, так как мы одного и того же клиента учтем более одного  раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно обоготить данные, чтобы лучше идентифицировать сущности\n",
    "- Добавить для клиента email, телефон, устройство, 4 цифры карты и другое, что может помочь его идентифицировать  \n",
    "    Это важно так как у клиента могут быть разные телефоны, устройства, карты, но все это вместе поможет его идентифицировать точнее\n",
    "- Добавить для события локацию, погоду, связанные событие, праздники, что поможет нам идентифицировать событие   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение метрик между собой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сравнить метрики между собой мы можем\n",
    "- использовать корреляционный анализ\n",
    "Мы строим матрицу корреляции всего со всем и смотрим на коэффициенты корреляции.  \n",
    "Смотрим R2 (коэффициент детерминации)\n",
    "- использовать коэффициенты у регресси\n",
    "Мы строим регрессию (может быть обычная, а может быть решающий случайный лес и другие варианты) и смотрим,   \n",
    "у каких метрик больше коэффициенты. Таким образом мы поймем какие метрики сильнее зависят с целевой.  \n",
    "Будет правильно выбирать разные целевые метрики и смотреть как на них влияют основные (смотрим R2).  \n",
    "То есть проверять на мультиколлиниарность, чтобы определить не просто поарную корреляцию, а совместную.  \n",
    "Также не забываем поправки на гетероскедостичность (HC0, HC1, HC2, HC3) в статпакетах.  \n",
    "Нам нужно ответить на следующие вопросы\n",
    "    - Влияет ли метрика на целевую?\n",
    "    Оцениваем коэффициенты в уравнении регресси у каждой метрики.  \n",
    "    - Как влияет метрика на целевую?\n",
    "    Смотрим R2 (коэффициент детерминации). И определяем какая часть целевой переменной определяется независимыми метриками.  \n",
    "    - Коэффициенты при метриках в уравнении статистически значим? При какаом уровне значимости?\n",
    "    Смотрим в стат пакете p value для каждого коэффициента, что нам говорит значим ли этот коэффициент.  \n",
    "    То есть мы не просто смотрим его абсолютное значение, а учитываем p value.   \n",
    "    - Дайте содержательную интерпретацию коэффицентам?\n",
    "    При увеличении метрики k на 1, целевая метрика увеличивается на $b_{k} * 1$\n",
    "    То есть нужно перевести коэффициенты в реальное сравнение, насколько увелчисться целевая метрика при изменении определенной метрики на 1\n",
    "    - Найдите 95 процентный доверительный интервал.\n",
    "    В стат пакете смотрим значение и оно говорит, что если мы многократно повторим ноши вычисления с новыми данными, то 95 процентов наших  \n",
    "    полученных коэффицентов будут лежать в этом диапазоне.  \n",
    "- испльзовать коэффициенты у классификацию  \n",
    "Строим логистическую регрессию, случайный лес и другие модели и смотрим какие метрики сильнее всего влияют на решения модели.  \n",
    "- используем быблиотеку `shap`, чтобы определить метрики, которые лучше других помогают предсказывать целевую перемменную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы построить регрессию и посмотреть стат значимость и коэффициенты удобно использовать модуль statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf   \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# формула записывать так \"Целевая переменная ~ метрика1 + метрика2 + ...\"\n",
    "# ols модель линейной регрессии\n",
    "formula = 'Price ~ DEN + polyamid + lykra + cotton + wool'\n",
    "reg = smf.ols(formula, df).fit(cov_type='HC1')\n",
    "reg.summary()\n",
    "var = reg.model.exog\n",
    "VIF = [variance_inflation_factor(var, i) for i in range(var.shape[1])]\n",
    "VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Когортный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забывать про когортный анализ. Если у нас есть параметр, по которому мы можем наши данные разбить на когорты, то  \n",
    "нужно разложить на когорты и посмотреть динамику по когортам.  \n",
    "Когорты это например, пользователи пришедшие в одни день или месяц.  \n",
    "Если мы объеденим пользователей в когорты и посмотрим динамику какого-то параметра по месяцам например, то увидим как изменяется.  \n",
    "Тут также нужно помнить, что если значение например за 3 месяц больше значения за 4 месяц, то это ничего не значит само по себе.  \n",
    "Так как мы имеем дело с выборкой, то нам нужно проверить статистически значимая это разница.  \n",
    "Тут нам понядобятся стат тесты.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные моменты, которые стоит проверить и изучить \n",
    "- привести значения стобцов к одному регистру, если заглваные буквы не несут смысл\n",
    "- привести все к одному языку, если названия, например, на руссом и на английсом  \n",
    "- важно проверить на корректность данные, то есть смотрим по отдельности каждый столбец и изучаем мин, макс, и другие параметры, и  \n",
    "думаем, это физически реально. И особенно, когда у нас несколько связаных параметров, нет ли между ними противоречия.  \n",
    "Например, у нас есть дата показа рекламы и есть дата создания рекламы, естественно создание должно быть раньше, это нужно проверить.  \n",
    "- вообще нужно придумать разные проверки для колонок, особенно связанных. И провести эту проверку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Формулирование и провера гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Гипотезы появляются, когда мы задаем вопросы данным. Мы изучили данные, преобработали и теперь начинаем задавать вопросы.  \n",
    "- Выдвигаем гипотезу (заметили что-то необычное и хотим проверить), далее формулируем ее и далее проверяем.  \n",
    "- Не забываем формулировать гипотезы словами. Пишем что является гипотезой H0, а что гипотезой H1  \n",
    "- Формулируем все гипотезы, которые хотим проверить. Если будет 100 гипотез, то все 100 нужно сформулировать и потом проверить и сделать вывод.  \n",
    "- Гипотезы могут быть и простыми вопросами без гипотез H0 и H1, такие гипотезы мы проверяем графиками или анализируя таблицу.  \n",
    "- Восновном, когда мы собиаремся применить стат аппарат для проверки гипотезы, то мы должны записать ее через H0 и H1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм проверки статистических гипотез\n",
    "\n",
    "- постановка задачи\n",
    "    - Сформулировать, что мы хотим узнать о выборках с точки зрения бизнес задачи (равны ли средние доходы в группах)\n",
    "- формулировка гипотез\n",
    "    - перевод бизнес-вопроса на язык статистики: средний доход в группах - проверка равенства средних значений\n",
    "    - формулировка нулевой гипотезы - с т.зр. равенства стат прараметров оцениваемых выборок   \n",
    "    (Н0: Средние траты клиентов по группе А равны средним тратам клинентов по группе В)\n",
    "    - формулировка альтернативной гипотезы - с точки зрения неравенства параметров  \n",
    "    (Н1: Средние траты клиентов по группе А не равны средним тратам клинентов по группе В)\n",
    "- выбор критерия alpha (почему 0.05 или 0.01)\n",
    "    - цена ошибки первого рода (при большой цене ошибки - в мед исследованиях, потенциальном ущербе ) - значение может быть больше, например 0.1\n",
    "    - в ежедневных бизнес задачах, обычно - 0.05\n",
    "- анализ распределения\n",
    "    - визуальная оценка\n",
    "    - следим за выбросами\n",
    "    - проверка гипотез о типе распредеделения (например критерий Шапиро-Уилка)\n",
    "    - если распределение не нормальное и размер выборки достаточный (больше 30-50 элементов)  \n",
    "    может быть использован t-test именно для проверки гипотезы о равенстве средних.  \n",
    "    Согласно ЦПТ (центральная предельная теорема) средние этих выборок будут распределены нормально. См. статью Зотова\n",
    "- выбор критерия\n",
    "    - при оценке равенства средних T-test или Welch T-test (если есть сомнения, то лучше Уэлча)\n",
    "        - при рвенстве дисперсий используем обычный т тест\n",
    "        - если дисперсии в выборках разные, то используем т теста Уэлча\n",
    "- получение результата\n",
    "    - расчет p-value\n",
    "- интерпретация p-value\n",
    "    - сравнение p-value и alpha\n",
    "    - если альфа > p-value - отвергаем нулевую гипотезу\n",
    "    - если альфа < p-value - не можем отвергнуть нулевую гипотезу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между наличием детей и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между семейным положением и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между уровнем дохода и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как разные цели кредита влияют на его возврат в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нужно сообщить в выводе\n",
    "- информацию о том, что удалось подтвердить гипотезы (тут пишем только те, которые удалось подтвердить)\n",
    "- всю информацию о датасете, которые важны. Дубликаты, которые несут практическую пользу и рекомендации по ним, пропуски также с рекомендациями  \n",
    "и остальные моменты по данным и рекомендации. Тут важно указывать именно найденные аномалии, которые имеют практическую пользу, которые нужно исправить и прочее.  \n",
    "Пишем, что были найдены выбросы, они были связаны возможно с тем то и тем то. \n",
    "- и в конце обязательно call to action \n",
    "написать что необходимо сделать с этими результатами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Советы по оформлению общего выывод\n",
    "- не нужно вставлять таблицы и графики в вывод. \n",
    "В выводе пишем словами самое важное и практически полезное, что мы получили, причем в порядке убывания важности.  \n",
    "И когда мы пишем, что увидели то-то, то приводим гиперссылку на график или результат ячейки, где это получено.  \n",
    "Так будет компактный вывод и при необходимости человек сможет быстро перейти и посмотреть график или таблицу  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удалось подтвердить гипотезу** о влиянии различных характеристик клиента на факт погашения кредита в срок. Каждый из рассмотренных параметров оказывает влияние на надёжность заёмщика. Рассмотренные факторы по-разному влияют на надёжность заёмщиков. Например, семейное положение оказалось более значимым фактором, чем уровень дохода.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-penny",
   "metadata": {},
   "source": [
    "- В ходе анализа исходного набора данных было проведено (были устранены пропуски в двух колонках с числовыми значениями - 'total_income' и 'days_employed').  \n",
    "- После __устранения явных и скрытых дупликатов__ и удаления оставшихся после обогащения пропусков объем датасета сократился на 0.05%\n",
    "- Были устранены __выбросы__ в колонках 'days_employed' и 'children': в первом случае выбросы возникли в результате системной ошибки (данные были внесены в часах, а не в днях); во втором случае ошибка, вероятнее всего была допущена людьми, вносившими данные в систему\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-strand",
   "metadata": {},
   "source": [
    "**Необходимо**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-worker",
   "metadata": {},
   "source": [
    "1. Запросить в отделе по работе с клиентами информацию о возможности брать кредит без подтверждения дохода. \n",
    "\n",
    "2. Сообщить коллегам, занимающимся выгрузкой о наличие дубликатов, если вопрос не разрешится, запросить индентификационный номер клиента к датасету.\n",
    "\n",
    "3. Прописать в задаче на поставку данных формат данных (пол только F и M, положительные значения). Приложить информацию о найденных аномалиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чек-лист готовности проекта\n",
    "\n",
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  открыт файл;\n",
    "- [ ]  файл изучен;\n",
    "- [ ]  определены пропущенные значения;\n",
    "- [ ]  заполнены пропущенные значения;\n",
    "- [ ]  есть пояснение, какие пропущенные значения обнаружены;\n",
    "- [ ]  описаны возможные причины появления пропусков в данных;\n",
    "- [ ]  объяснено, по какому принципу заполнены пропуски;\n",
    "- [ ]  заменен вещественный тип данных на целочисленный;\n",
    "- [ ]  есть пояснение, какой метод используется для изменения типа данных и почему;\n",
    "- [ ]  удалены дубликаты;\n",
    "- [ ]  есть пояснение, какой метод используется для поиска и удаления дубликатов;\n",
    "- [ ]  описаны возможные причины появления дубликатов в данных;\n",
    "- [ ]  выделены леммы в значениях столбца с целями получения кредита;\n",
    "- [ ]  описан процесс лемматизации;\n",
    "- [ ]  данные категоризированы;\n",
    "- [ ]  есть объяснение принципа категоризации данных;\n",
    "- [ ]  есть ответ на вопрос: \"Есть ли зависимость между наличием детей и возвратом кредита в срок?\";\n",
    "- [ ]  есть ответ на вопрос: \"Есть ли зависимость между семейным положением и возвратом кредита в срок?\";\n",
    "- [ ]  есть ответ на вопрос: \"Есть ли зависимость между уровнем дохода и возвратом кредита в срок?\";\n",
    "- [ ]  есть ответ на вопрос: \"Как разные цели кредита влияют на его возврат в срок?\";\n",
    "- [ ]  в каждом этапе есть выводы;\n",
    "- [ ]  есть общий вывод."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
