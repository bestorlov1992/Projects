{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование надёжности заёмщиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Автор**: Григорьев Павел   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Описание проекта**: Заказчик — кредитный отдел банка. Нужно разобраться, влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок. Входные данные от банка — статистика о платёжеспособности клиентов.  \n",
    "Результаты исследования будут учтены при построении модели кредитного скоринга — специальной системы, которая оценивает способность потенциального заёмщика вернуть кредит банку.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Цель**: Составить рекомендации для кредитного отдела банка, которые будут учтены при построении модели кредитного скоринга.  \n",
    "Определить влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Источники данных**: Данные предоставленны кредитным отделом банка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условия проведения анализа днных**: указываем временной интервал выборки  \n",
    "Например, 'для анализ будут использоваться данные за год с 1 июня 2017 по 31 мая 2018 года'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Вывод**: тут помещаем самое главное из общего вывода, примерно до полустраницы, чтобы не было сильно много и при этом указать все главные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Оглавление** \n",
    "* [1. Описание и изучение данных](#1)\n",
    "    * [1.1 Изучение данных](#1-1)\n",
    "    * [1.2 Изучение данных](#1-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(опционально, зависит от того есть ли оглавление по умолчанию, но лучше сделать скрываемое, так как не везде будет автоматическое):  \n",
    "создаем оглавление с гиперссылками  \n",
    "Тут важно давать развернутые названия разделам в работе, но и не сильно большие (пиши - сокращай).  \n",
    "Все таки это название главы и оно должно быть не более 5-7 слов. Некоторые могут быть длиннее, если сильно нужно,  \n",
    "но основная часть названий разделов и глав долны быть достаточно кратикими.   \n",
    "Чтобы понять длинные ли заголовки - смотрим на оглавление и думаем не сильно ли шировкие строчки.  \n",
    "Чтобы в оглавление хорошо читалось и было понятно про что каждый раздел и глава и чтобы  \n",
    "можно было прочитать, понять и перейти к разделу. Нельзя писать сильно кратко, так как люди не знакомы с работой и им нужно более развернутые  \n",
    "названия глав, чтобы понимать о чем там будет идти речь  \n",
    "Оглавление делаем со сворачивающимися списками, то есть каждую главу можно свернуть, можно развернуть и пеерейти на уровень ниже,  \n",
    "как в сводных таблицах экселя, так удобнее, так как места занимает мало, если скрыть все подразделы, а если нужно, то раскроют  \n",
    "В каждом блоке сделать гиперссылку 'к содержанию', чтобы можно было вернуться к содержанию,  \n",
    "но тут важно, чтобы на одной странице не было больше 1 такой ссылки.   \n",
    "Заголовки разделов и глав не нужно писать в стиле 'посчитаем, выясним, исследуем и подобное', так как названия глав и разделов это более официальные  \n",
    "названия. Нужно более формально их называть.  \n",
    "Название главы или раздела должно нести в себе основной смысл этого раздела или главы, так и нужно называть.  \n",
    "1. Описание данных\n",
    "2. Предобработка данных\n",
    "3. Расчет метрик\n",
    "    3.1 Продуктовые метрики\n",
    "        3.1.1 Расчет MAU, DAU, WAU\n",
    "        3.1.2 Рачет ASL\n",
    "4. Подведение итогов и регкомендации       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'my_module' from 'c:\\\\Git\\\\Projects\\\\Исследование надёжности заёмщиков\\\\my_module.py'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, Layout\n",
    "from IPython.display import display, display_html, display_markdown\n",
    "import my_module\n",
    "import importlib\n",
    "import re\n",
    "import itertools\n",
    "from pymystem3 import Mystem\n",
    "importlib.reload(my_module)\n",
    "# with httpimport.remote_repo('http://my-codes.example.com/python_packages'):\n",
    "#     import package1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Описание и изучение данных <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Описание данных <a class=\"anchor\" id=\"1-1\"></a>\n",
    "- children - количество детей в семье\n",
    "- days_employed - общий трудовой стаж в днях\n",
    "- dob_years - возраст клиента в годах\n",
    "- education - уровень образования клиента\n",
    "- education_id - идентификатор уровня образования\n",
    "- family_status - семейное положение\n",
    "- family_status_id - идентификатор семейного положения\n",
    "- gender - пол клиента\n",
    "- income_type - тип занятости\n",
    "- debt - имел ли задолженность по возврату кредитов\n",
    "- total_income - ежемесячный доход\n",
    "- purpose - цель получения кредита"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Изучение данных <a class=\"anchor\" id=\"1-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сначала грузим 5-10 строк (указываем в `pd.read_csv` `nrow`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучаем данные и определяемся с типами, потом их указваем в `pd.read`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно привести названия столбцов к нижнему регистру, убрать пробелы (заменить их на _),  \n",
    "так как в том же merge могту быть проблемы, если это не сделать и вообще будет удобнее работать "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если после попытки привести тип к нужному, мы получили ошибку,  \n",
    "то обязательно изучаем эти строки. Именно строки, не только сами занчения, которые не можем преобразовать.  \n",
    "Часто бывает у нас в ругих столбцах есть категория например, которая портит все,  \n",
    "и при этом это выброс может быть.  Поэтому обязательно првоеряем строки, в которых строки не преобразуются в нужный тип.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно писать код, чтобы не учитывался порядок столбцов. Чтобы если порядок изменится, то наш скрипт будет работать верно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все значения в колонках во всех таблицах нужно привести к нижнему регистру и по возможности к одному языку,  \n",
    "для перевода к одному языку можно использовать словарь, с помощью которого изменить неправильный язык  \n",
    "Это нужно, чтобы когда будем соединять таблицы, у нас условие соеденения правильно сравнивало равные значения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также важно категориальные столбцы привести к типу `category` и для столбцов, которые имеют малый диапазон значений заменить на меньший тип,  \n",
    "например на `int8`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>education_id</th>\n",
       "      <th>family_status</th>\n",
       "      <th>family_status_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>1</td>\n",
       "      <td>-2885.142188</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>80236.028323</td>\n",
       "      <td>приобретение автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>2</td>\n",
       "      <td>-1803.080913</td>\n",
       "      <td>36</td>\n",
       "      <td>Среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>163292.220004</td>\n",
       "      <td>строительство собственной недвижимости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>1</td>\n",
       "      <td>-305.540665</td>\n",
       "      <td>27</td>\n",
       "      <td>СРЕДНЕЕ</td>\n",
       "      <td>1</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>69799.488812</td>\n",
       "      <td>ремонт жилью</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>1</td>\n",
       "      <td>-1593.946336</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>1</td>\n",
       "      <td>107486.332934</td>\n",
       "      <td>на покупку подержанного автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>0</td>\n",
       "      <td>-1025.402943</td>\n",
       "      <td>64</td>\n",
       "      <td>высшее</td>\n",
       "      <td>0</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>госслужащий</td>\n",
       "      <td>0</td>\n",
       "      <td>706401.475790</td>\n",
       "      <td>профильное образование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       children  days_employed  dob_years education  education_id  \\\n",
       "4042          1   -2885.142188         50   среднее             1   \n",
       "19177         2   -1803.080913         36   Среднее             1   \n",
       "7372          1    -305.540665         27   СРЕДНЕЕ             1   \n",
       "16245         1   -1593.946336         50   среднее             1   \n",
       "11563         0   -1025.402943         64    высшее             0   \n",
       "\n",
       "          family_status  family_status_id gender  income_type  debt  \\\n",
       "4042    женат / замужем                 0      F    сотрудник     0   \n",
       "19177   женат / замужем                 0      F    сотрудник     0   \n",
       "7372   гражданский брак                 1      F    сотрудник     0   \n",
       "16245   женат / замужем                 0      F    сотрудник     1   \n",
       "11563   женат / замужем                 0      M  госслужащий     0   \n",
       "\n",
       "        total_income                                 purpose  \n",
       "4042    80236.028323                 приобретение автомобиля  \n",
       "19177  163292.220004  строительство собственной недвижимости  \n",
       "7372    69799.488812                            ремонт жилью  \n",
       "16245  107486.332934      на покупку подержанного автомобиля  \n",
       "11563  706401.475790                  профильное образование  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = {'education': 'category', 'family_status': 'category', 'gender': 'category', 'income_type': 'category'}\n",
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/data.csv', dtype=dtype)\n",
    "df.sample(5, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод `my_info` или `my_info_gen` для вывода информации о датасете и колонках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Везде где нужно написать свои мысли по результату, пишем слово жирным шрифтом `Наблюдения:`   \n",
    "и с нового абзаца писать рассуждения списком булитами - или *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделать предположения, почему могло так произойти, выдвигаем гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "придумать способы проверки выдвинутых гипотез и записать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "если у нас по оси x время, то проанализировать сезонность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подумать а так и должно было получиться, основываясь на понимании физики параметра  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "зафиксировать возможные рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для гистограмм, нужно понять почему именно такое распределение метрики.  \n",
    "Совпадет это с логикой этой метрики. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также когда строим гистограммы и вайолин плот, то не просто фиксируем, что есть тяжелые хвосты, разброс между квартилями такой-то.  \n",
    "А думаем почему так, пытаемся связать это с физикой параметра. Должно быть физическое объяснение всех аномалий.  \n",
    "Если объяснения нет, то возможно это инсайт.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно убедиться, что у нас есть данные на все источники, которые заявлены. Например, мы изучаем источники трафика и у нас они в разных таблицах.  \n",
    "Нужно убедиться, что во всех таблицах есть все источники, и проверить нет ли аномалий, возможно какой-то сильно выбивается или какого-то вообще где-то нет.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И очень важно сверить, что периоды в разных таблицах (если у нас больше одной таблицы) совпадают.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно проверить соответствуют ли временной период данных тому, который заявлен в задании,  \n",
    "определиться что будем делать с неполными периодами.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще, когда у нас несколько таблиц и там есть категориальные переменные или время, то  \n",
    "мы должны взять уникальные значения категориальных переменных из каждой таблицы (одниаковые переменные) и сравнить.  \n",
    "Количество уникальных должно совпадать, иначе нужно разбираться  \n",
    "И с верменем как минимум мин и макс даты должны совпадать до дня, а лушше до минуты часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно, если у нас есть стартовая дата чего-то и конечная, то обязательно нужно проверить,  \n",
    "нет ли у нас записей, где конечная дата меньше стартовой.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важная проверка, если у нас есть категории и даты, то сгруппировать по категориями и \n",
    "вывести количество занчений, минимальную и максимальную дату  \n",
    "Таким образом мы сразу поймем распределение в категории и  \n",
    "увидем какие временные интервалы у каждой категории  \n",
    "Если у нас все категории должны быть в один день, то мы поймем нет ли багов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще очень важно смотреть не только на аномалии в значениях, но и аномалии в категориальных переменных.  \n",
    "А тут аномалией будет отстутствие какого-то значения, хотя в описании или поставновке задачи оно есть.  \n",
    "Также совпадение количества значений категориальных переменных в разных таблицах.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внимательно посмотреть на столбцы, если есть столбцы, в которых могут быть потенциальные анамали, то проверить их.  \n",
    "Например, есть столбец возрасти стаж работы, проверить, что возраст больше стажа.  \n",
    "И подобные случаи.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на нарушения уникальности   \n",
    "Убедить, что столбцы, значения в которых не должны повторяться и должны быть уникальными, такие в действительности.    \n",
    "Смотрим на результат функции `my_info`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на ошибки целостности  \n",
    "Если у нас есть столбцы, в которых значения должны совпдаать попарно, то проверяем на это  \n",
    "`get_non_matching_rows`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка условий  \n",
    "Проверьте, что данные в датафрейме удовлетворяют определенным условиям, таким как \"возраст > 18\" или \"страна == 'Россия'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем на дубли  \n",
    "- Важно помнить, что если у нас есть id и название товара, то названия товара все равно нужно проверить на дубли,  \n",
    "возможно у нас 2 ай ди с одним названием. \n",
    "- Также важно в каждой отдельной колонке проверить дубли и если их много, то посмотреть на соседние колонки, что там происходит\n",
    "- Дубликаты часто носят скрытый характер.  \n",
    "То есть это могут быть поля, которые записаны  по разному, но относятся к одному и тому же.  \n",
    "Поэтому важно, если у нас категориальный признак, изучить нет ли повторящихся категорий, которые записаны немного по разному.  \n",
    "Так как это создает шум, мы по сути имеем две разные категории, но на самом деле это одна. Нужно собрать их в одну.  \n",
    "- И очень важно, если мы не подтвердили, что это действительно дубликат (например у нас нет ай ди клиента и мы не смогли выяснить один и тот же ли это человек),  \n",
    "то нужно аккуратно удалять их. Но и оставлять много дублей плохо, так как они вносят шумы и искажения.  \n",
    "- Помним, что наличие дубликата не говорит точно, что это дубль, возможно у нас нет ещё колонок, котоыре бы детализировали и разделили эти дубли.  \n",
    "Поэтому тут могут быть рекомендации, чтобы добавли в фрейм доп колонки, которые помогут убрать дубли (либо сам ищешь ещё поля)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`check_duplicated`  \n",
    "`check_duplicated_combinations`  \n",
    "`get_duplicates_value_proportion_by_category`  \n",
    "В первую функцию можно передавать весь датафрейм и можно выбирать нужные столбцы для проверки на дубли и передавать их.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно на дубли проверить и отдельные строки и целиком таблицу и подумать какие группы столбцов могут дать дубли и на это тоже проверить.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в дублях у нас есть ай ди клиента, то тут понятно, если нет ай ди, то пишем рекомендацию, чтобы данные приходили с ай ди,  \n",
    "чтобы можно было понять это один человек или нет "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас id пользователя встречается не одни раз в таблице и есть другие поля которые должны быть всегда одни и те же,  \n",
    "напримем пол и прочее, то нужно проверить у всех ли пользователей все значения одинаковые в этом столбце.  \n",
    "Это может быть не только ай ди, любое уникальное поле, которое повторяется и для каждого этого поля есть другое  \n",
    "поле, которое не должно меняться, нужно проверять а действительно ли это поле не меняется.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем на пропуски    \n",
    "Когда мы встречаем пропуски, прежде всего, нужно ответить на вопрос, существует ли закономерность в появлении пропусков.   \n",
    "Иными словами, не случайно ли их возникновение в наборе данных.  \n",
    "Случайно, значит нет закономерности с соседними столбцами, то есть пропуски есть для разных значений.  \n",
    "А могут быть неслучайные, то есть существует явная закономерностЬ, что пропуски есть только у сторок с общими занчениями в другом столбце.    \n",
    "Чтобы это проверить, нужно взять столбец с пропусками, отфильтровать только пропуски (взять их) и  \n",
    "посмотреть как эти пропуски распределены по другой переменной.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Первое что нужно сделать, когда мы видим пропуск или выброс, это проверить является ли оно случайным.  \n",
    "То есть посмотреть не относятся ли все выбросы к одной категории. Если это так, то это уже не случайно и мы нашли аномалию, которую можно изучать.  \n",
    "Если у нас случайны разброс пропусков в категориях, то значит тут есть случайность.  \n",
    "Например, у нас возраст 0, и мы видим, что больше всего это у женщин. Следовательно получаем гипотезу, что женщины не хотят сообщать свой возраст.  \n",
    "- В пропусках мы можем определить какие категории, платформы и прочее не собираются данные. Смотрим пропуски, далее смотрим у каких категорий их больше,  \n",
    "и получаем вывод, что нужно обратить внимание на эти категории или системы, почему там пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_columns_with_missing_values`  \n",
    "`check_na_in_both_columns`  \n",
    "`get_missing_value_proportion_by_category`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучаем выбросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выбросы это не только просто сильно большое или сильно маленькое значение.  \n",
    "- Выбросы нужно также смотреть по мультипараметрам, с помощью моделей и искать аномалии.  \n",
    "- Выброс это то, что отделяется от других, что выбивается из общей картины. Следовательно это что-то особенное.  \n",
    "- Тажке выбросы говорят не только о плюсах, но и о минусах. Выбросы могут сказать, что у нас что-то сломалось.  \n",
    "Что-то не записывается, или работает с багами. Все это можно увдитеь по выбрасам и аномалиям.  \n",
    "- Обязательно посмотреть выбросы в разрезе категорий, так как мы сможем сделать выводы об их источнике.  \n",
    "- Если мы работаем со строгой отчетностью, то тут любой выброс это уже инсайт и нужно идти разбираться откуда это взялось.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на выбросы используя Z-score  \n",
    "`detect_outliers_Zscore`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на выбросы используя Z-score  \n",
    "`detect_outliers_quantile`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучить выбросы по категориями  \n",
    "`get_outlier_quantile_proportion_by_category`  \n",
    "`get_outlier_proportion_by_category_modified_z_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные моменты, которые стоит проверить и изучить \n",
    "- важно проверить на корректность данные, то есть смотрим по отдельности каждый столбец и изучаем мин, макс, и другие параметры, и  \n",
    "думаем, это физически реально. И особенно, когда у нас несколько связаных параметров, нет ли между ними противоречия.  \n",
    "Например, у нас есть дата показа рекламы и есть дата создания рекламы, естественно создание должно быть раньше, это нужно проверить.  \n",
    "- Проверяем данные ошибки  \n",
    "Ошибки которые не являются дублями, пропусками или выбросами.  \n",
    "Это сложно сделать, хотя бы заметить явные ошибки\n",
    "- Проверить на ошибки согласованности  \n",
    "Например, у нас пользователь с одним ай ди имеет разные имена. \n",
    "`display(df.groupby('name')['age'].nunique())`\n",
    "- вообще нужно придумать разные проверки для колонок, особенно связанных. И провести эту проверку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-collect",
   "metadata": {},
   "source": [
    "Принимаем решение, как именно мы будем проводить обработку, почему именно так, *зафиксировать рекомендации.  \n",
    "То есть отвечаем на вопрос, что будем делать с выбросами, что будем делать с null.  \n",
    "Будет идеально если тут зафиксировать рекомендации  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточный вывод**\n",
    "\n",
    "- **children** Присутствует 47 отрицательных значений с \"-1\", а также аномалия в виде 20 детей ...\n",
    "- **days_employed** Большая часть данных стобца со знаком \"-\". Однако, эти данные представляют из себя 84% всей выборки. ... будут заменены на .. исходя из определенного критерия, который будет описан далее. \n",
    "    - Причины пропущенных значений в столбцах **days_employed** и **income**:\n",
    "        - Во-первых, это может быть из-за неправильной выгрузки данных. Оставим это предположение до того момента, пока не убедимся в неверности других предположений.**Наиболее вероятно**\n",
    "        - Во-вторых, одной из гипотез было предположение об отсутствии трудового опыта у данной части выборки. Однако, если распределение по возрасту в данной группе равномерное по всем возрастам выборки. Также большая доля этой части выборки трудоустроена. **Гипотеза не подтверждена**\n",
    "        - В-третьих, возможно, что эта часть выборки не имеет официального трудоустройства. Данная гипотеза вызывает сомнение в связи с тем, что при наличии достаточно большого стажа работы у представителей выборки у ее представителей нет официального трудового стажа. К тому же 18.9% данной выборки являются госслужащими. **Гипотез не подтверждена**\n",
    "- **age** .. 0 возраст у 101 человека.\n",
    "- **education & education_id** Необходимо будет привести данную категорийнуй переменную к общему виду. Избавиться от разного регистра. Но можно не тратить на это время и использовать следующий столбец **education_id**. Это позволит использовать меньше памяти и не повлияет на качество анализа.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Обрезание неполных временных периодов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас датасет за год, например, и первый или последний месяц неполные, то их лучше выбрасить, если мы будем  \n",
    "расчитывать месячные метрики.  \n",
    "Но сначала конечно нужно проанализировать столбцы без обрезания, чтобы убедиться, что там нет ничего необычного.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Выбор нужных столбцов для дальнейшей работы и нормализация таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Думаем, какие колонки нам нужны, выбираем только их для дальнейшей работы.  \n",
    "Остальные убираем в другой датасет. \n",
    "- Важно после изученя данных сначала убрать не нужные столбцы, а потом уже заниматься преобразованием (удалением пропусков и выбросов).  \n",
    "Думаем прежде чем удалять строки, так как возможно лучше удалить столбец и строки удалять будет не нужно.  \n",
    "- Пишем почему выбираем определенные столбцы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-general",
   "metadata": {},
   "source": [
    "что-то изменили - > посмотрели не изменилось ли количество дублей   \n",
    "`check_duplicated`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увидели пропуск — подумайте, нормально ли это. Сколько вообще пропусков может быть в этом столбце?   \n",
    "К примеру, в списке с электронными адресами пользователей, согласных на рассылку, будет много пропусков. Далеко не все предоставляют email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использвоать такой подход\n",
    "- если количество пропусков меньше 5 процентов, то удаляем (лучше меньше 1 процента)\n",
    "- если количество пропусков от 5 до 20 процентов, то подбираем чем заменить, удалять не стоит\n",
    "- если больше 20 процентов, то не трогаем, так как исказим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но оставляя пропуски, нам нужно помнить, что мы не можем по этим полям считать корреляцию с другими,   \n",
    "так как пропуски испортят расчет коэффициента корреляции. Аналогично другие метрики могут считаться некорректно.  \n",
    "Поэтому, если мы будем считать показатели по столбцу с пропусками, то их нужно либо убирать, либо этот столбец не использовать для расчетов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных переменных оставлять пропуски нельзя, так как мы скорее всего будем группировать по ним и смотреть разные разрезы.  \n",
    "Поэтому в худшем случае, если не можем ничем заменить, и нет уверености, что пропуск можно заполнить пустой строкой (если значения физически нет),  \n",
    "то создаем категорию например `other` из пропусков.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас пропуски в категориальной переменной и есть разные периоды или просто данные разбиты на части (то есть эта категориальная переменная повторяется),  \n",
    "то мы можем взять ещё какую-нибудь переменную, у которой нет пропусков, где пропуски у первой переменной и далее посмотреть другие периоды  \n",
    "Таким образом у нас будет предыдущий период, где будет занчение второй переменной и первой и если в нескольких периодах они одинаковые, то мы можем  \n",
    "заполнить и пропуски этим значением.   \n",
    "Ещё раз схема такая - берем 2 поля одно с пропусками, другое без, получаем новую таблицу, в этой таблице оставляем только униклаьные значения в поле без пропусков,  \n",
    "по этому полю будем джойнить. Далее в основнйо таблице дропаем описание и создаем новое описание из таблицы справочника.    \n",
    "`fill_missing_values_using_helper_column`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски учитвая категории  \n",
    "`fill_na_with_function_by_categories`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с выбросами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Очень важно понимать, когда выброс можно отбросить и он реально выброс и когда нельзя.  \n",
    "Опираемся на физику параметра, думаем это значение физически возможно.  \n",
    "- Также выброс может казаться выбрасом, но для бизнеса это не выброс.  \n",
    "Например у нас суммы покупок и одна покупка сильно выделяется, а там просто человек купил супе дорогой каньяк, например.  \n",
    "- Когда хотим обрезать выбросы, то думаем, какой порог может быть физически реальным и по нему режем, а не просто так берем какой-то перцентиль.  \n",
    "Всегда нужно думать с точки зрения физического возможного значения параметра и по нему резать (подумать а какое значение может быть максимально реальным и по нему обрезать)\n",
    "- Если мы имеем дело со строгой отчестностью, то выбросы убирать нельзя, нужно разобраться откуда они.  \n",
    "- Если мы не можем с увереностью сказать, что это выброс, то нам не стоит его выкидывать, но работать как то нужно с ними,  \n",
    "тогда, логарифмируем (лучше использовать натуральный логарифм) эту колонку и работаем с такими значениями (тогда выбросы сожмуться).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дубликатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если есть дубли, и мы считаем, что это не дубли, а просто разделились данные,    \n",
    "то объединеняем записи, которые имеют одинаковые значения ключевых признаков.  \n",
    "`merge_duplicates`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы не уверены, что дубль является дублем и не хотим удалять, то можно  использовать  \n",
    "маркировку дублей,  можно добавить новую колонку, которая будет содержать информацию о том,   \n",
    "является ли строка дубликатом или нет.  \n",
    "`df['is_duplicate'] = df.duplicated()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумать, а можем ли мы обогатить данные, что разделит дубли.  \n",
    "То есть возможно в наших данных нет какого-то столбца, и тогда дубли уже не будут дублями. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если уверены, что это дубли, то удаляем их  \n",
    "`df.drop_duplicates()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категоризация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обычная категоризация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категоризация помогает избежать проблемы с разреженными данными, когда у нас есть слишком много групп с небольшим количеством элементов.   \n",
    "Это может привести к некорректным выводам и ошибкам в анализе.\n",
    "Категоризация нужна, чтобы образовать группы, в которых достаточно значений для использования статистических методов.  \n",
    "И вообще, если в группе 1-10 элементов, например у нас возраст пользователей и 5 человек с возрастом 22, 3 человека с возрастом 23 и так далее.  \n",
    "Мы не можем разбивать по таким группам, так как их размер небльшой и выводы будут некорректные, поэтому нам нужно собрать их в группы,  \n",
    "чтобы у нас были группы с достаточным размером.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если у нас категориальная переменная имеет много значений, то мы не можем номрально с ней работать.  \n",
    "Так как мы не можем построить графики по ним, так как их много и они не числовые. Не можем сравнить их все.  \n",
    "Поэтому нам нужно сократить категории.  \n",
    "- Нужно посмотреть на данные и подумать можем ли мы разделить их по сегментам рынка или по другим категориям, которые нам помогут.  \n",
    "- Мы можем категоризировать на основе и числовых и категориальных столбцов. То есть мы можем из категориальной переменной сделать  \n",
    "другую категориальную, уменьшив или увеличив разбиение.   \n",
    "- добавление категорий обогощает данные, при чем категории могут формироваться не из одной колонки, а из серии, то есть чтобы попасть  \n",
    "в определенную категорию значения столбцов должно быть такое то, а не только один столбец определяет категорию.  \n",
    "- категории могут быть да нет, то есть состоять из двух значений, например, у нас есть данные о рекламе и столбец где она показвалась,  \n",
    "и у нас много много разных устройств. Мы можем разбить на да нет, то есть показвалась реклама по телеку или нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем разбить данные на категории двумя способами\n",
    "- разбивать на равные части  \n",
    "подходит, когда \n",
    "    - диапазон значений является равномерным и имеет линейную структуру  \n",
    "    - мы понимаем на какие интервалы хотим разбить данные    \n",
    "    - мы хотим разделить диапазон значений на равные части для удобства анализа.\n",
    "- разбить на основе квантилей  \n",
    "подходит, если   \n",
    "    - диапазон значений имеет неравномерную структуру\n",
    "    - мы не можем понять какие интервалы выбрать\n",
    "    - хотим выделить группы с конкретными характеристиками (например, группы с низким доходом, средним доходом и высоким доходом)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем нужные способ и используем  \n",
    "`create_category_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Категоризация с использованием лемматизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть столбец и мы хотим его лематизировать, то используем функцию  \n",
    "`lemmatize_column`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью лематизации мы можем сократить количество категорий.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например мы можем выделить группы:\n",
    "- операции с автомобилем (ключевое слово - автомобиль)\n",
    "- операции с недвижимостью (ключевые слова: жилье, недвижимость)\n",
    "- проведение свадьбы (ключевое слово: свадьба)\n",
    "- получение образования (ключевое слово: образование)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем функцию  \n",
    "`categorize_column_by_lemmatize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы хотим преобразовать категории в числа, то мы можем использовать \n",
    "- lable encoding  \n",
    "Заменяем быквы числами. Хорошо работает, когда у нас порядковые категориальные переменные.  \n",
    "Не забываем про порядок, если у нас алфавитный порядок наших категорий соотвествует числовому, то ок,  \n",
    "если нет, то нам нужно самим определить порядок чисел, чтобы они соответствовали категориям в нужном порядке.  \n",
    "- one hot encoding  \n",
    "Если у нас категориальная переменная не упорядочиваемая, то лучше использовать one hot encoding, чтобы разница между числами не вносила шум,  \n",
    "так как черный и белый и красный цвет закодированные 1, 2, 3 вносят смысл количества, но они не имеют этого свойства.  \n",
    "- замена категориальной переменной на каую-то статистику по одной из категорий внутри этой переменной.  \n",
    "Например у нас категориальная переменная это наличие задержки. Значение задержан / незадержан. Мы кодируем их как 0 и 1. Далее мы берем и считаем по каждой группе (для задержан и для незадержан)  \n",
    "статистику, например, среднее и получаем столбец, где вместо каждой буквы будет ее среднее.  \n",
    "Тут важно делать регуляризацию. Так как маленькие группы могут иметь сильно  зашумленные статистики, так как если у нас  \n",
    "группа из 5 значений, то среди них может быть легко экстремальное одно и оно сбивает статистику, поэтому добавляем штраф всем статистикам.  \n",
    "Регуляризация это что-то похожее на сглаживание.  \n",
    "Как это делается \n",
    "    - берем считаем среднее по таргету (целевой переменной, то есть той, по которой мы счтаем статистику) всей таблице (то есть не делим на категории)  \n",
    "    - Далее используем следующую формулу для сглаженного значения среднего по конкретной группе:   \n",
    "      (среднее по группе * количество элементов в группе + среднее по таргету без учета категорий * размер регуляризирующей группы) / (количество элементов в категории + размер регуляризирующей группы)  \n",
    "      Количество элементов в регуляризационнной группе выбирает эмперически. То есть это количество элементов, которым мы сглаживаем.    \n",
    "      Смысл в том, что мы берем сколько-то элементов с занчением для всех категорий и сглаживаем им наши отдельные категории.    \n",
    "    - Размер регуляризирующей группы обычно выбирают с помощью grid search, то есть берут цикл для размера этой группы и считают результат модели для каждого размера,  \n",
    "    и потом выбирают тот размер, для которого результат лучше.  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придумываем какие колонки можно дополнительно сделать из имеющихся.  \n",
    "Например у нас есть колонка длительность звонков, и 0 это пропущенный звонок,  \n",
    "мы можем сделать колонку is_missed, в которой будет true или false  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно, когда мы создаем новые колонки, в которых используем несколько дургих, то нужно проверить распределение этой новой переменной, особенно  \n",
    "выбросы. Например, у нас начальная и конечная дата сессии и мы считаем длительность сессии. Вот тут нужно посмотреть какая минимальная длительность  \n",
    "и какая максимальная. Ну и естественно проверить есть ли длительность 0 и меньше нуля.  \n",
    "Таким образом мы можем найти инсайты уже после создания новых колонок, хотя в изначальных данных этих инсайдов не было видно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обогощение таблиц (соединение с другими)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка соответствия:   \n",
    "Если у нас в разных таблицах есть значения, которые дожны быть одинакоые,    \n",
    "то нужно проверить, что значения в одном столбце соответствуют значениям в другом столбце. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column_name1'].equals(df['column_name2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обоготить данные можно следующими способами\n",
    "- взять поле нашей таблицы и найти дополнительные данные в интернете или ещё где-то и потом связать с нашей колонкой по этому полю  \n",
    "Самое просто это дата, если у нас есть дата, то мы можем много разной доп информации внести в наши данные связывая по дате.  \n",
    "Также, например, у нас есть какие-то коды чего-то, мы ищем информацию по этим кодам и находим табличку с доп инфой по этим кодам и можем обоготить ими   \n",
    "нашу таблицу. Например, у нас города или страны, мы можем по ним также внести доп инфу из какого-то источника, которая нам поможет.  \n",
    "Вообще любое поле нашей таблицы это потенцильная нить для обогощения. Главное понять с чем полезным мы можем соеденить  \n",
    "через конкретное поле, чтобы получить больше полезной информации для анализа, по сути для детализации наших зависимостей или для поиска  \n",
    "новых зависимостей и инсайтов в них.  \n",
    "Процесс следующий - мы берем каждую колонку нашего дата сета и думаем, с чем через нее мы можем связать и если придумываем, то идешь ищем эту информацию и  \n",
    "в итоге соединяем.  \n",
    "- Можно пойти от обратного. Сначал подумтаь какие данные нам могут помочь и поискать их в интернете например, а потом уже думать как их соеденить с нашими   \n",
    "данными. Оба способа лучше делать одновременно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем соединять 2 таблицы, смотрим есть ли поля, которые уникально описывают строчки в обеих таблицах.  \n",
    "В напрмер, в одной таблице у нас есть ай ди пользователя и месяца (ай ди не уникальны, месяца тоже, но вместе уникальны),  \n",
    "и в другой таблице также, тогда мы соединяем таблицы по составному ключу [айди, месяц]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно соединять таблицы по полям с id,  \n",
    "если мы соединяем поля по текстовым полям, то это будет намного дольше, так как будут сравниваться строки  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нужно обязательно првоерить после соединения\n",
    "- если мы соединяем по полю, которое уникально в обеих таблицах\n",
    "    - количество строк в левом датафрейме равно количеству строк в итоговом\n",
    "    - параметры каждого дата сета не изменились (если мы соединили правильно, то итоговые суммы по столбцам не должны измениться)\n",
    "        - используем `df.sum(numeric_only=True)` для каждой таблицы до соединения и для общей таблицы и сравниваем значения\n",
    "        - можно использвоать `df.describe` также до и после объединения и сравнивать параметры\n",
    "- если у нас в одной из колонок для соединения не уникальные значения (то есть для одной строки в левой таблице будет несколько в итоговй)    \n",
    "    - Сначала группируем таблицы, чтобы поле для соединения в обеих таблицах было уникальное\n",
    "    и применяем предыдущий шаг с количеством строк в левой и итоговой и суммой значений в левой и итоговой одинаковой\n",
    "    - Если нам нужно соеденить без группировки (но это редко может быть, поэтому нужно подумать точно ли не моежм сгруппировать)  \n",
    "    тогда нет выбора и остаются только следующие варианты  \n",
    "        - если в левой таблице уникальные записи в колонке, по которйо соединяем    \n",
    "            - тогда считаем сколько было записей в левой таблице в колонке для соединения и сравниваем с количеством **уникальных** записей в итоговой  \n",
    "            они должны совпадать, но тут важно в итоговой брать уникальные записи\n",
    "        - есил и в левой и правой нет уникальных\n",
    "            - тут считаем сколько **уникальных** в левой до и сколько **уникальных** в итоговой, должно совпадать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас что-то не сходится после соединения таблиц, то нужно внимально изучить это.  \n",
    "Тут может быть инсайт (кто-то не правильно вносит информацию, какие-то значения неверные или кто-то что-то хотел спрятать, не указать и прчоее).  \n",
    "Когда видим нестыковки после соединения таблиц, то должна загораться красная лампочка. Это потенциальный инсайт, баг, который мы можем найти и сообщить, чтобы его починили. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше привыкать везеде соединять таблицы как left join, чтобы наверняка не потерять данные.  \n",
    "А если вылезит не нужный Null, то с ним уже можно будет разобраться, это лучше чем случайно забыть использовать left  \n",
    "и потерять данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также лучше привыкать соединять таблицы, у которых поле для соединения уникальное в обоих таблицах.  \n",
    "Нужно соеденить таблицы, смотрим уникальные ли поля, если нет, то думаем что мы будем делать после соединения,  \n",
    "скорее всего аггрегировать, тогда нужно до соединения аггрегировать таблицу, где поле не уникально, и потом соединять.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "используем merge, join, append, concat  \n",
    "но помним, что часто метод соединения inner стоит по умолчанию,  \n",
    "а мы хотим обогатить данные, то есть у нас в правой таблице может не быть того, что в левой,  \n",
    "поэтому правильно использовать left join иногда outer join "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень важно после каждого соединения проверять, что количество строк в итоговом дата сете равно количеству строк в левом датасете.  \n",
    "Это очень часто забывают проверять, а от этого очень много ошибок, которые потом сложно искать.  \n",
    "Если запомнить и постоянно проверять количество строк после соединения, то избавимся от многих потенциальных проблем.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас поле, по которому мы хотим соеденить не уникальное в однйо из таблиц, то думаем о аггрегации.  \n",
    "Например, у нас в одной таблице клиенты (тут уникальные ай ди), а в другой покупки (тут ай ди могут повторяться),  \n",
    "тогда нам скорее всего из таблицы с покупками нужно будет что-то аггрегированное (например сумма покупок клиента),  \n",
    "поэтому сначал думаем что мы хотим анализировать и аггрегируем по этому параметру до соединения.  \n",
    "Большая ошибка сначала соеденить, а потом аггрегировать.  \n",
    "Если есть такая возможность и это не влияет на результат, то сначал нужно аггрегировать, чтобы не было проблем с памятью   \n",
    "Также фильтруем не нужные колонки до соединения, также чтобы не тащить лишние данные в общую большую таблицу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В колонках, по которым будем соеднить, проверяем, нет ли пропусков, какие разделители. пропуски нужно заменить нулями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый раз, когда мы работаем с дата сетом, мы должны понять что является сущностью этого дата сета.  \n",
    "Например событие, человек и прочее.  \n",
    "Далее нам нужно поянть а можем ли мы его идентифицировать по текущим данным (не всегда есть уникальный ай ди).   \n",
    "Если не можем, то нужно думта как обогатить данные, чтобы четко идентифицировать сущности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема разрастания дубликатов  \n",
    "Если мы соединяем таблицы и используем неправильный способ, то у нас могут появляться дубли и они могут сильно разрастаться  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема потери из-за неиспользования left join, когда важно не потерять данные  \n",
    "Не забываем каждый раз когда хотим соеденить таблицы задавать себе вопрос, могут ли потеряться данные,  \n",
    "если я использую просто join, важно ли мне не потерять даннные. И только после ответа на этот вопрос выбирать вариант соединения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема справочников  \n",
    "При объединение таблиц важно помнить про то, что в разных таблицах не только названия столбцов может быть разное,  \n",
    "но и одно значение может быть записано по разному в разных таблицах, например, названия профессий, названия городов,  \n",
    "имя в одной таблице на русском, а в другой на английском, номер телефона с черточкой или плюсом и без черточки или плюса.  \n",
    "Поэтому не забываем привести все значения таблиц к нижнему регистру, чтобы не было проблем разными регистрами для одного слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема временных зон  \n",
    "В одной таблице может быть выгрузка по местному времени, а в другом по московскому  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема курсов валют  \n",
    "Разыне системы могут брать курс за разные промежутки вермени, например, одна система берет курс в гугле (раз в час обновляется),  \n",
    "а другая система берет курс в ЦБ (обновляется раз в сутки)  \n",
    "И поэтому итоговые резултаты могут не состыковаться, поэтому, когда видим курсы валют, то нужно убедиться. что они взяты из одного испточника  \n",
    "и за один промежуток времени  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы работаем с данными, нам важно четко идентифицировать клиентов, событие или другую сущность, с которой мы работаем.  \n",
    "Иначе у нас будет шум, так как мы одного и того же клиента учтем более одного  раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно обоготить данные, чтобы лучше идентифицировать сущности\n",
    "- Добавить для клиента email, телефон, устройство, 4 цифры карты и другое, что может помочь его идентифицировать  \n",
    "    Это важно так как у клиента могут быть разные телефоны, устройства, карты, но все это вместе поможет его идентифицировать точнее\n",
    "- Добавить для события локацию, погоду, связанные событие, праздники, что поможет нам идентифицировать событие   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение метрик между собой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сравнить метрики между собой мы можем\n",
    "- использовать корреляционный анализ\n",
    "Мы строим матрицу корреляции всего со всем и смотрим на коэффициенты корреляции.  \n",
    "Смотрим R2 (коэффициент детерминации)\n",
    "- использовать коэффициенты у регресси\n",
    "Мы строим регрессию (может быть обычная, а может быть решающий случайный лес и другие варианты) и смотрим,   \n",
    "у каких метрик больше коэффициенты. Таким образом мы поймем какие метрики сильнее зависят с целевой.  \n",
    "Будет правильно выбирать разные целевые метрики и смотреть как на них влияют основные (смотрим R2).  \n",
    "То есть проверять на мультиколлиниарность, чтобы определить не просто поарную корреляцию, а совместную.  \n",
    "Также не забываем поправки на гетероскедостичность (HC0, HC1, HC2, HC3) в статпакетах.  \n",
    "Нам нужно ответить на следующие вопросы\n",
    "    - Влияет ли метрика на целевую?\n",
    "    Оцениваем коэффициенты в уравнении регресси у каждой метрики.  \n",
    "    - Как влияет метрика на целевую?\n",
    "    Смотрим R2 (коэффициент детерминации). И определяем какая часть целевой переменной определяется независимыми метриками.  \n",
    "    - Коэффициенты при метриках в уравнении статистически значим? При какаом уровне значимости?\n",
    "    Смотрим в стат пакете p value для каждого коэффициента, что нам говорит значим ли этот коэффициент.  \n",
    "    То есть мы не просто смотрим его абсолютное значение, а учитываем p value.   \n",
    "    - Дайте содержательную интерпретацию коэффицентам?\n",
    "    При увеличении метрики k на 1, целевая метрика увеличивается на $b_{k} * 1$\n",
    "    То есть нужно перевести коэффициенты в реальное сравнение, насколько увелчисться целевая метрика при изменении определенной метрики на 1\n",
    "    - Найдите 95 процентный доверительный интервал.\n",
    "    В стат пакете смотрим значение и оно говорит, что если мы многократно повторим ноши вычисления с новыми данными, то 95 процентов наших  \n",
    "    полученных коэффицентов будут лежать в этом диапазоне.  \n",
    "- испльзовать коэффициенты у классификацию  \n",
    "Строим логистическую регрессию, случайный лес и другие модели и смотрим какие метрики сильнее всего влияют на решения модели.  \n",
    "- используем быблиотеку `shap`, чтобы определить метрики, которые лучше других помогают предсказывать целевую перемменную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы построить регрессию и посмотреть стат значимость и коэффициенты удобно использовать модуль statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf   \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# формула записывать так \"Целевая переменная ~ метрика1 + метрика2 + ...\"\n",
    "# ols модель линейной регрессии\n",
    "formula = 'Price ~ DEN + polyamid + lykra + cotton + wool'\n",
    "reg = smf.ols(formula, df).fit(cov_type='HC1')\n",
    "reg.summary()\n",
    "var = reg.model.exog\n",
    "VIF = [variance_inflation_factor(var, i) for i in range(var.shape[1])]\n",
    "VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Когортный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забывать про когортный анализ. Если у нас есть параметр, по которому мы можем наши данные разбить на когорты, то  \n",
    "нужно разложить на когорты и посмотреть динамику по когортам.  \n",
    "Когорты это например, пользователи пришедшие в одни день или месяц.  \n",
    "Если мы объеденим пользователей в когорты и посмотрим динамику какого-то параметра по месяцам например, то увидим как изменяется.  \n",
    "Тут также нужно помнить, что если значение например за 3 месяц больше значения за 4 месяц, то это ничего не значит само по себе.  \n",
    "Так как мы имеем дело с выборкой, то нам нужно проверить статистически значимая это разница.  \n",
    "Тут нам понядобятся стат тесты.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Формулирование и провера гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Гипотезы появляются, когда мы задаем вопросы данным. Мы изучили данные, преобработали и теперь начинаем задавать вопросы.  \n",
    "- Выдвигаем гипотезу (заметили что-то необычное и хотим проверить), далее формулируем ее и далее проверяем.  \n",
    "- Не забываем формулировать гипотезы словами. Пишем что является гипотезой H0, а что гипотезой H1  \n",
    "- Формулируем все гипотезы, которые хотим проверить. Если будет 100 гипотез, то все 100 нужно сформулировать и потом проверить и сделать вывод.  \n",
    "- Гипотезы могут быть и простыми вопросами без гипотез H0 и H1, такие гипотезы мы проверяем графиками или анализируя таблицу.  \n",
    "- Восновном, когда мы собиаремся применить стат аппарат для проверки гипотезы, то мы должны записать ее через H0 и H1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм проверки статистических гипотез\n",
    "\n",
    "- постановка задачи\n",
    "    - Сформулировать, что мы хотим узнать о выборках с точки зрения бизнес задачи (равны ли средние доходы в группах)\n",
    "- формулировка гипотез\n",
    "    - перевод бизнес-вопроса на язык статистики: средний доход в группах - проверка равенства средних значений\n",
    "    - формулировка нулевой гипотезы - с т.зр. равенства стат прараметров оцениваемых выборок   \n",
    "    (Н0: Средние траты клиентов по группе А равны средним тратам клинентов по группе В)\n",
    "    - формулировка альтернативной гипотезы - с точки зрения неравенства параметров  \n",
    "    (Н1: Средние траты клиентов по группе А не равны средним тратам клинентов по группе В)\n",
    "- выбор критерия alpha (почему 0.05 или 0.01)\n",
    "    - цена ошибки первого рода (при большой цене ошибки - в мед исследованиях, потенциальном ущербе ) - значение может быть больше, например 0.1\n",
    "    - в ежедневных бизнес задачах, обычно - 0.05\n",
    "- анализ распределения\n",
    "    - визуальная оценка\n",
    "    - следим за выбросами\n",
    "    - проверка гипотез о типе распредеделения (например критерий Шапиро-Уилка)\n",
    "    - если распределение не нормальное и размер выборки достаточный (больше 30-50 элементов)  \n",
    "    может быть использован t-test именно для проверки гипотезы о равенстве средних.  \n",
    "    Согласно ЦПТ (центральная предельная теорема) средние этих выборок будут распределены нормально. См. статью Зотова\n",
    "- выбор критерия\n",
    "    - при оценке равенства средних T-test или Welch T-test (если есть сомнения, то лучше Уэлча)\n",
    "        - при рвенстве дисперсий используем обычный т тест\n",
    "        - если дисперсии в выборках разные, то используем т теста Уэлча\n",
    "- получение результата\n",
    "    - расчет p-value\n",
    "- интерпретация p-value\n",
    "    - сравнение p-value и alpha\n",
    "    - если альфа > p-value - отвергаем нулевую гипотезу\n",
    "    - если альфа < p-value - не можем отвергнуть нулевую гипотезу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между наличием детей и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчеты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно следить за количеством недель в году, если мы создаем столбец месяца.  \n",
    "Проверять чтобы у нас не появлялась неделя дополнительная, из за того, что мы захватили предыдущий год"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между семейным положением и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть ли зависимость между уровнем дохода и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как разные цели кредита влияют на его возврат в срок?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нужно сообщить в выводе\n",
    "- информацию о том, что удалось подтвердить гипотезы (тут пишем только те, которые удалось подтвердить)\n",
    "- всю информацию о датасете, которые важны. Дубликаты, которые несут практическую пользу и рекомендации по ним, пропуски также с рекомендациями  \n",
    "и остальные моменты по данным и рекомендации. Тут важно указывать именно найденные аномалии, которые имеют практическую пользу, которые нужно исправить и прочее.  \n",
    "Пишем, что были найдены выбросы, они были связаны возможно с тем то и тем то. \n",
    "- и в конце обязательно call to action \n",
    "написать что необходимо сделать с этими результатами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Советы по оформлению общего выывод\n",
    "- не нужно вставлять таблицы и графики в вывод. \n",
    "В выводе пишем словами самое важное и практически полезное, что мы получили, причем в порядке убывания важности.  \n",
    "И когда мы пишем, что увидели то-то, то приводим гиперссылку на график или результат ячейки, где это получено.  \n",
    "Так будет компактный вывод и при необходимости человек сможет быстро перейти и посмотреть график или таблицу  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удалось подтвердить гипотезу** о влиянии различных характеристик клиента на факт погашения кредита в срок. Каждый из рассмотренных параметров оказывает влияние на надёжность заёмщика. Рассмотренные факторы по-разному влияют на надёжность заёмщиков. Например, семейное положение оказалось более значимым фактором, чем уровень дохода.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-penny",
   "metadata": {},
   "source": [
    "- В ходе анализа исходного набора данных было проведено (были устранены пропуски в двух колонках с числовыми значениями - 'total_income' и 'days_employed').  \n",
    "- После __устранения явных и скрытых дупликатов__ и удаления оставшихся после обогащения пропусков объем датасета сократился на 0.05%\n",
    "- Были устранены __выбросы__ в колонках 'days_employed' и 'children': в первом случае выбросы возникли в результате системной ошибки (данные были внесены в часах, а не в днях); во втором случае ошибка, вероятнее всего была допущена людьми, вносившими данные в систему\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-strand",
   "metadata": {},
   "source": [
    "**Необходимо**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-worker",
   "metadata": {},
   "source": [
    "1. Запросить в отделе по работе с клиентами информацию о возможности брать кредит без подтверждения дохода. \n",
    "\n",
    "2. Сообщить коллегам, занимающимся выгрузкой о наличие дубликатов, если вопрос не разрешится, запросить индентификационный номер клиента к датасету.\n",
    "\n",
    "3. Прописать в задаче на поставку данных формат данных (пол только F и M, положительные значения). Приложить информацию о найденных аномалиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала раздел графиков  \n",
    "На основе графиков формируются гипотезы (например, у нас у мужчин зп больше)\n",
    "И после раздела графиков идет раздел проверки гипотез. Тут мы првоеряем разные гипотезы новые и те, что увидели на графиках.  \n",
    "Это правильная последовательность сначала изучили графики и потом на основе их сформировали гипоетзы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед разделом про графики идет раздел с корреляцией и поиском главных компонет случайного леса.  \n",
    "Мы выбиарем переменную, для которой мы далее хотим посмотреть разыне зависимости и указываем ее целевой для сучайного леса  \n",
    "И смотрим какие фичи сильнее влияют.  \n",
    "И теперь можем построить графики с целевой перменно и этими главными фичами и в выводе можно указать про то что это важные компоненты случаного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в разделе категоризации нужно использовать метод понижения размерности до 3  \n",
    "и построить 3 д график  \n",
    "По этому графику посмотреть есть ли у нас возможные кластеры  \n",
    "Если есть, то выделить их  \n",
    "Причем для понижения размерности можно брать все столбцы, а можно только часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
